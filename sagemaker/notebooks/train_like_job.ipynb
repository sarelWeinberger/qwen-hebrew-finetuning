{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ce8ea7-f2fd-4d8d-8549-e67515f95728",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wandb datasets deepspeed\n",
    "#!pip install transformers\n",
    "#!pip install accelerate>=0.26.0\n",
    "\n",
    "# אחרי העדכון, עשה restart kernel:\n",
    "#import IPython\n",
    "#IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd66f1e8-1b56-4a30-8aba-87cc363053db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-10 11:05:19,776] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-10 11:05:21,350] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n",
      "✅ All imports successful\n",
      "PyTorch version: 2.2.2\n",
      "CUDA available: True\n",
      "GPU count: 8\n",
      "  GPU 0: Tesla V100-SXM2-16GB\n",
      "  GPU 1: Tesla V100-SXM2-16GB\n",
      "  GPU 2: Tesla V100-SXM2-16GB\n",
      "  GPU 3: Tesla V100-SXM2-16GB\n",
      "  GPU 4: Tesla V100-SXM2-16GB\n",
      "  GPU 5: Tesla V100-SXM2-16GB\n",
      "  GPU 6: Tesla V100-SXM2-16GB\n",
      "  GPU 7: Tesla V100-SXM2-16GB\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import wandb\n",
    "import time\n",
    "import logging\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    set_seed,\n",
    "    TrainerCallback\n",
    ")\n",
    "from datasets import load_from_disk, load_dataset, Dataset\n",
    "import deepspeed\n",
    "from datetime import datetime\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"✅ All imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e8205d-fe47-4031-ac96-7e2f0140b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SageMaker environment variables set:\n",
      "  SM_MODEL_DIR = /tmp/ml/model\n",
      "  SM_OUTPUT_DATA_DIR = /tmp/ml/output/data\n",
      "  SM_CHANNEL_TRAINING = /tmp/ml/input/data/training\n",
      "  SM_NUM_GPUS = 8\n",
      "  SM_CURRENT_HOST = algo-1\n",
      "  SM_HOSTS = [\"algo-1\"]\n",
      "  SM_CURRENT_INSTANCE_TYPE = ml.p4de.24xlarge\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Mock SageMaker Environment Variables\n",
    "# משתני סביבה שמדמים את SageMaker\n",
    "os.environ.update({\n",
    "    'SM_MODEL_DIR': '/tmp/ml/model',\n",
    "    'SM_OUTPUT_DATA_DIR': '/tmp/ml/output/data',\n",
    "    'SM_CHANNEL_TRAINING': '/tmp/ml/input/data/training',\n",
    "    'SM_NUM_GPUS': str(torch.cuda.device_count()),\n",
    "    'SM_CURRENT_HOST': 'algo-1',\n",
    "    'SM_HOSTS': '[\"algo-1\"]',\n",
    "    'SM_CURRENT_INSTANCE_TYPE': 'ml.p4de.24xlarge'\n",
    "})\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('/tmp/ml/model', exist_ok=True)\n",
    "os.makedirs('/tmp/ml/output/data', exist_ok=True)\n",
    "os.makedirs('/tmp/ml/input/data/training', exist_ok=True)\n",
    "\n",
    "print(\"✅ SageMaker environment variables set:\")\n",
    "for key, value in os.environ.items():\n",
    "    if key.startswith('SM_'):\n",
    "        print(f\"  {key} = {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf6d9c9-d088-4968-94f9-a7f5d1db8aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration:\n",
      "  Instance Type: ml.p4de.24xlarge\n",
      "  Model: microsoft/DialoGPT-small\n",
      "  Epochs: 1\n",
      "  Max Steps: 5\n",
      "  Sequence Length: 512\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Configuration Variables (adjust these!)\n",
    "# פרמטרים של האימון - ערוך אלה לפי הצורך\n",
    "INSTANCE_TYPE = 'ml.p4de.24xlarge'\n",
    "MODEL_NAME = 'microsoft/DialoGPT-small'  # מודל קטן לדיבוג מהיר\n",
    "EPOCHS = 1\n",
    "MAX_STEPS = 5  # מספר צעדים קטן לדיבוג\n",
    "SEED = 42\n",
    "MAX_SEQ_LENGTH = 512  # קצר יותר לדיבוג\n",
    "WANDB_PROJECT = 'local-debug-test'\n",
    "WANDB_ENTITY = None\n",
    "WANDB_RUN_NAME = f'local-debug-{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "print(\"✅ Configuration:\")\n",
    "print(f\"  Instance Type: {INSTANCE_TYPE}\")\n",
    "print(f\"  Model: {MODEL_NAME}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Max Steps: {MAX_STEPS}\")\n",
    "print(f\"  Sequence Length: {MAX_SEQ_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b0002e-a4bb-4a91-9713-8aa8d3456625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Instance config loaded:\n",
      "{\n",
      "  \"batch_size_per_gpu\": 4,\n",
      "  \"gradient_accumulation_steps\": 1,\n",
      "  \"deepspeed_config\": \"configs/deepspeed/p4de_deepspeed_config.json\",\n",
      "  \"gpu_count\": 8,\n",
      "  \"gpu_type\": \"A100\",\n",
      "  \"gpu_memory\": \"80GB\",\n",
      "  \"estimated_hourly_cost\": 40.96\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load Instance Configuration\n",
    "def load_instance_config(instance_type):\n",
    "    \"\"\"Load instance-specific configuration - exactly from train.py\"\"\"\n",
    "    default_configs = {\n",
    "        'ml.p4d.24xlarge': {\n",
    "            \"batch_size_per_gpu\": 2,\n",
    "            \"gradient_accumulation_steps\": 1,\n",
    "            \"deepspeed_config\": \"configs/deepspeed/p4d_deepspeed_config.json\",\n",
    "            \"gpu_count\": 8,\n",
    "            \"gpu_type\": \"A100\",\n",
    "            \"gpu_memory\": \"40GB\",\n",
    "            \"estimated_hourly_cost\": 32.77\n",
    "        },\n",
    "        'ml.p4de.24xlarge': {\n",
    "            \"batch_size_per_gpu\": 4,\n",
    "            \"gradient_accumulation_steps\": 1,\n",
    "            \"deepspeed_config\": \"configs/deepspeed/p4de_deepspeed_config.json\",\n",
    "            \"gpu_count\": 8,\n",
    "            \"gpu_type\": \"A100\",\n",
    "            \"gpu_memory\": \"80GB\",\n",
    "            \"estimated_hourly_cost\": 40.96\n",
    "        },\n",
    "        'ml.p5.48xlarge': {\n",
    "            \"batch_size_per_gpu\": 6,\n",
    "            \"gradient_accumulation_steps\": 1,\n",
    "            \"deepspeed_config\": \"configs/deepspeed/p5_deepspeed_config.json\",\n",
    "            \"gpu_count\": 8,\n",
    "            \"gpu_type\": \"H100\",\n",
    "            \"gpu_memory\": \"80GB\",\n",
    "            \"estimated_hourly_cost\": 98.32\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if instance_type in default_configs:\n",
    "        return default_configs[instance_type]\n",
    "    else:\n",
    "        return default_configs['ml.p4d.24xlarge']\n",
    "\n",
    "# Load instance config\n",
    "instance_config = load_instance_config(INSTANCE_TYPE)\n",
    "print(\"✅ Instance config loaded:\")\n",
    "print(json.dumps(instance_config, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ebb137e-7330-4c13-aea7-f9c4c6662f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create DeepSpeed Configuration (FINAL VERSION)\n",
    "def create_deepspeed_config():\n",
    "    \"\"\"Create minimal DeepSpeed config\"\"\"\n",
    "    config = {\n",
    "        \"fp16\": {\"enabled\": True},\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 2,\n",
    "            \"overlap_comm\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\": 500000000\n",
    "        },\n",
    "        \"train_micro_batch_size_per_gpu\": 2,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"gradient_clipping\": 1.0,\n",
    "        \"wall_clock_breakdown\": False  # ← השבת timers\n",
    "    }\n",
    "    \n",
    "    os.makedirs(\"./configs/deepspeed\", exist_ok=True)\n",
    "    config_path = \"./configs/deepspeed/local_deepspeed_config.json\"\n",
    "    \n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    return config_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61d4c9a2-88d3-4e83-af11-114251a7cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdnrevital\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ec2-user/SageMaker/wandb/run-20250710_110521-yq82mn9t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dnrevital/local-debug-test/runs/yq82mn9t' target=\"_blank\">local-debug-20250710_110521</a></strong> to <a href='https://wandb.ai/dnrevital/local-debug-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dnrevital/local-debug-test' target=\"_blank\">https://wandb.ai/dnrevital/local-debug-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dnrevital/local-debug-test/runs/yq82mn9t' target=\"_blank\">https://wandb.ai/dnrevital/local-debug-test/runs/yq82mn9t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ W&B initialized: local-debug-20250710_110521\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Setup W&B\n",
    "# Initialize Weights & Biases\n",
    "\n",
    "wandb.init(\n",
    "    project=WANDB_PROJECT,\n",
    "    entity=WANDB_ENTITY,\n",
    "    name=WANDB_RUN_NAME,\n",
    "    config={\n",
    "        \"instance_type\": INSTANCE_TYPE,\n",
    "        \"gpu_count\": instance_config.get(\"gpu_count\", 8),\n",
    "        \"gpu_type\": instance_config.get(\"gpu_type\", \"A100\"),\n",
    "        \"gpu_memory\": instance_config.get(\"gpu_memory\", \"40GB\"),\n",
    "        \"estimated_hourly_cost\": instance_config.get('estimated_hourly_cost', 32.77),\n",
    "        \"model_name\": MODEL_NAME,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"max_seq_length\": MAX_SEQ_LENGTH,\n",
    "        \"seed\": SEED,\n",
    "        \"batch_size_per_gpu\": instance_config.get(\"batch_size_per_gpu\", 2),\n",
    "        \"gradient_accumulation_steps\": instance_config.get(\"gradient_accumulation_steps\", 1),\n",
    "        \"sagemaker_job\": False,  # Local run\n",
    "        \"num_gpus\": torch.cuda.device_count(),\n",
    "        \"benchmark_mode\": True,\n",
    "        \"start_time\": datetime.now().isoformat()\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✅ W&B initialized: {WANDB_RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf7c638-3319-41e1-89c9-7f8b17087a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created dummy dataset with 50 samples\n",
      "Sample text: זהו טקסט דוגמא מספר 0. זהו טקסט דוגמא מספר 0. זהו טקסט דוגמא מספר 0. זהו טקסט דוגמא מספר 0. זהו טקסט...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Create Dummy Dataset\n",
    "def create_dummy_dataset(num_samples=100):\n",
    "    \"\"\"Create dummy dataset for testing\"\"\"\n",
    "    # Create simple Hebrew-like text samples\n",
    "    texts = [\n",
    "        f\"זהו טקסט דוגמא מספר {i}. \" * 20  # Repeat to get decent length\n",
    "        for i in range(num_samples)\n",
    "    ]\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = Dataset.from_dict({\"text\": texts})\n",
    "    \n",
    "    # Also save to the SageMaker training directory\n",
    "    data_dir = '/tmp/ml/input/data/training'\n",
    "    with open(f'{data_dir}/train.jsonl', 'w', encoding='utf-8') as f:\n",
    "        for text in texts:\n",
    "            f.write(json.dumps({\"text\": text}, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Create dummy dataset\n",
    "dummy_dataset = create_dummy_dataset(50)  # Small for quick testing\n",
    "print(f\"✅ Created dummy dataset with {len(dummy_dataset)} samples\")\n",
    "print(f\"Sample text: {dummy_dataset[0]['text'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73faf4ba-17a8-45ac-b642-dada8b66d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: microsoft/DialoGPT-small\n",
      "Loading model: microsoft/DialoGPT-small\n",
      "✅ Model moved to CUDA device 0. Available GPUs: 8\n",
      "✅ Gradient checkpointing enabled\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Load Model and Tokenizer\n",
    "set_seed(SEED)\n",
    "\n",
    "print(f\"Loading tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    trust_remote_code=True,\n",
    "    use_cache=False,\n",
    "    low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "# Move model to GPU exactly as in train.py\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda:0\")  # Move to specific GPU\n",
    "    print(f\"✅ Model moved to CUDA device 0. Available GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"ℹ️ CUDA not available, using CPU\")\n",
    "\n",
    "# Enable gradient checkpointing\n",
    "model.gradient_checkpointing_enable()\n",
    "print(\"✅ Gradient checkpointing enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c818d16-42af-42ca-836d-563728a4a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "250506ebeef64696892c4e45bcb8f751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset tokenized. Samples: 50\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Prepare Dataset\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"Tokenization function exactly from train.py\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_SEQ_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dummy_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=2,  # Less processes for local debugging\n",
    "    remove_columns=dummy_dataset.column_names\n",
    ")\n",
    "\n",
    "print(f\"✅ Dataset tokenized. Samples: {len(tokenized_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3add3c-ae03-49be-abdc-fe9166a3f23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data collator created\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Create Data Collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "print(\"✅ Data collator created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b79b5e18-5f83-4133-a4c3-b878d0c36b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics callback created\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: SageMaker Metrics Callback\n",
    "class SageMakerMetricsCallback(TrainerCallback):\n",
    "    \"\"\"Custom callback - exactly from train.py\"\"\"\n",
    "    \n",
    "    def __init__(self, instance_type, max_seq_length=2048):\n",
    "        super().__init__()\n",
    "        self.instance_type = instance_type\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.total_tokens = 0\n",
    "        self.steps = 0\n",
    "        self.start_time = time.time()\n",
    "        self.step_times = []\n",
    "        \n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"Track performance metrics for each step.\"\"\"\n",
    "        current_time = time.time()\n",
    "        step_time = current_time - getattr(self, 'last_step_time', current_time)\n",
    "        self.last_step_time = current_time\n",
    "        self.step_times.append(step_time)\n",
    "        \n",
    "        # Calculate tokens processed in this step\n",
    "        total_batch_size = args.per_device_train_batch_size * args.world_size\n",
    "        if args.gradient_accumulation_steps > 0:\n",
    "            total_batch_size *= args.gradient_accumulation_steps\n",
    "            \n",
    "        step_tokens = total_batch_size * self.max_seq_length\n",
    "        self.total_tokens += step_tokens\n",
    "        self.steps += 1\n",
    "        \n",
    "        # Calculate throughput\n",
    "        if len(self.step_times) > 0:\n",
    "            avg_step_time = sum(self.step_times[-10:]) / min(len(self.step_times), 10)\n",
    "            tokens_per_second = step_tokens / avg_step_time if avg_step_time > 0 else 0\n",
    "        else:\n",
    "            tokens_per_second = 0\n",
    "        \n",
    "        # Log metrics to W&B\n",
    "        metrics = {\n",
    "            \"training/tokens\": self.total_tokens,\n",
    "            \"training/step_num\": self.steps,\n",
    "            \"training/tokens_per_second\": tokens_per_second,\n",
    "            \"training/step_time\": step_time,\n",
    "            \"training/instance_type\": self.instance_type,\n",
    "            \"training/global_step\": state.global_step\n",
    "        }\n",
    "        \n",
    "        # Add GPU metrics if available\n",
    "        if torch.cuda.is_available():\n",
    "            for i in range(torch.cuda.device_count()):\n",
    "                metrics[f\"gpu_{i}/memory_allocated_gb\"] = torch.cuda.memory_allocated(i) / (1024**3)\n",
    "                metrics[f\"gpu_{i}/memory_reserved_gb\"] = torch.cuda.memory_reserved(i) / (1024**3)\n",
    "        \n",
    "        wandb.log(metrics, step=state.global_step)\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        \"\"\"Log training metrics to W&B.\"\"\"\n",
    "        if logs is None:\n",
    "            return\n",
    "        \n",
    "        # Log loss and other training metrics\n",
    "        wandb_logs = {}\n",
    "        for key, value in logs.items():\n",
    "            if key.startswith(('train_', 'eval_')):\n",
    "                wandb_logs[f\"training/{key}\"] = value\n",
    "            elif key == 'loss':\n",
    "                wandb_logs[\"training/loss\"] = value\n",
    "                wandb_logs[\"training/perplexity\"] = torch.exp(torch.tensor(value)).item()\n",
    "        \n",
    "        if wandb_logs:\n",
    "            wandb.log(wandb_logs, step=state.global_step)\n",
    "        \n",
    "        # Log final statistics\n",
    "        if \"train_runtime\" in logs:\n",
    "            total_time = time.time() - self.start_time\n",
    "            wandb.log({\n",
    "                \"training/total_tokens\": self.total_tokens,\n",
    "                \"training/total_time_hours\": total_time / 3600,\n",
    "                \"training/avg_tokens_per_second\": self.total_tokens / total_time,\n",
    "                \"training/final_step\": self.steps\n",
    "            }, step=state.global_step)\n",
    "\n",
    "# Initialize callback\n",
    "metrics_callback = SageMakerMetricsCallback(\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    max_seq_length=MAX_SEQ_LENGTH\n",
    ")\n",
    "print(\"✅ Metrics callback created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ca7557-0135-4ce9-9fdf-f2d7efb06968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created DeepSpeed config: ./configs/deepspeed/local_deepspeed_config.json\n",
      "✅ Training arguments created\n",
      "Warmup steps: 100\n",
      "DeepSpeed config: ./configs/deepspeed/local_deepspeed_config.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Create Training Arguments (FIXED)\n",
    "\n",
    "# ודא שיש DeepSpeed config\n",
    "if 'deepspeed_config_path' not in globals():\n",
    "    # אם אין, צור אותו עכשיו\n",
    "    os.makedirs(\"./configs/deepspeed\", exist_ok=True)\n",
    "    deepspeed_config_path = \"./configs/deepspeed/local_deepspeed_config.json\"\n",
    "    \n",
    "    config = {\n",
    "        \"fp16\": {\"enabled\": True},\n",
    "        \"zero_optimization\": {\n",
    "            \"stage\": 2,\n",
    "            \"overlap_comm\": True,\n",
    "            \"contiguous_gradients\": True,\n",
    "            \"reduce_bucket_size\": 500000000\n",
    "        },\n",
    "        \"train_micro_batch_size_per_gpu\": 2,\n",
    "        \"gradient_accumulation_steps\": 1,\n",
    "        \"gradient_clipping\": 1.0,\n",
    "        \"wall_clock_breakdown\": False\n",
    "    }\n",
    "    \n",
    "    with open(deepspeed_config_path, 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Created DeepSpeed config: {deepspeed_config_path}\")\n",
    "\n",
    "training_args_dict = {\n",
    "    \"output_dir\": '/tmp/ml/model',\n",
    "    \"fp16\": True,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"num_train_epochs\": EPOCHS,\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 3,\n",
    "    \"logging_steps\": 1,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"warmup_ratio\": 0.03,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"deepspeed\": deepspeed_config_path,\n",
    "    \"report_to\": [],\n",
    "    \"remove_unused_columns\": False,\n",
    "    \"dataloader_num_workers\": 0,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \"ddp_backend\": None,  # ← הסר NCCL לlocal\n",
    "    \"dataloader_pin_memory\": False,\n",
    "    \"ddp_find_unused_parameters\": False,\n",
    "}\n",
    "\n",
    "# Add max_steps if specified\n",
    "if MAX_STEPS and MAX_STEPS > 0:\n",
    "    training_args_dict[\"max_steps\"] = MAX_STEPS\n",
    "\n",
    "training_args = TrainingArguments(**training_args_dict)\n",
    "print(\"✅ Training arguments created\")\n",
    "print(f\"Warmup steps: {training_args.warmup_steps}\")\n",
    "print(f\"DeepSpeed config: {training_args.deepspeed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e15936c-bdb0-42b6-9cc4-e0dae5c79976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating trainer...\n",
      "✅ Trainer created successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21253/3683390395.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Create Trainer\n",
    "print(\"Creating trainer...\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=None,  # No eval for debugging\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "print(\"✅ Trainer created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ae0aa0-744c-4332-a470-5efaf0ec40d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Cell 13.5: Create Trainer (NEW CELL - אחרי Cell 13)\\nprint(\"Creating trainer...\")\\n\\ntrainer = Trainer(\\n    model=model,\\n    args=training_args,\\n    train_dataset=tokenized_dataset,\\n    eval_dataset=None,\\n    data_collator=data_collator,\\n    tokenizer=tokenizer,\\n    callbacks=[metrics_callback]\\n)\\n\\nprint(\"✅ Trainer created successfully\")\\n\\n# 🔧 תקן מיד אחרי יצירת Trainer\\nprint(\"=== Immediate DeepSpeed Fix ===\")\\n\\nif hasattr(trainer.model, \\'backward\\'):  # זה DeepSpeed engine\\n    print(f\"Trainer model is DeepSpeed engine: {type(trainer.model)}\")\\n    \\n    # יצור wrapper חדש\\n    class DeepSpeedEngineWrapper:\\n        def __init__(self, engine):\\n            self.engine = engine\\n            self._engine = engine\\n            \\n        def __getattr__(self, name):\\n            return getattr(self._engine, name)\\n            \\n        def destroy(self):\\n            pass\\n    \\n    # החלף את accelerator engine\\n    wrapper = DeepSpeedEngineWrapper(trainer.model)\\n    trainer.accelerator.deepspeed_engine_wrapped = wrapper\\n    \\n    print(f\"✅ Fixed accelerator: {trainer.accelerator.deepspeed_engine_wrapped}\")\\n    print(f\"✅ Wrapper engine: {trainer.accelerator.deepspeed_engine_wrapped.engine}\")\\nelse:\\n    print(\"❌ Trainer model is not DeepSpeed engine\")\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Cell 13.5: Create Trainer (NEW CELL - אחרי Cell 13)\n",
    "print(\"Creating trainer...\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=None,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "print(\"✅ Trainer created successfully\")\n",
    "\n",
    "# 🔧 תקן מיד אחרי יצירת Trainer\n",
    "print(\"=== Immediate DeepSpeed Fix ===\")\n",
    "\n",
    "if hasattr(trainer.model, 'backward'):  # זה DeepSpeed engine\n",
    "    print(f\"Trainer model is DeepSpeed engine: {type(trainer.model)}\")\n",
    "    \n",
    "    # יצור wrapper חדש\n",
    "    class DeepSpeedEngineWrapper:\n",
    "        def __init__(self, engine):\n",
    "            self.engine = engine\n",
    "            self._engine = engine\n",
    "            \n",
    "        def __getattr__(self, name):\n",
    "            return getattr(self._engine, name)\n",
    "            \n",
    "        def destroy(self):\n",
    "            pass\n",
    "    \n",
    "    # החלף את accelerator engine\n",
    "    wrapper = DeepSpeedEngineWrapper(trainer.model)\n",
    "    trainer.accelerator.deepspeed_engine_wrapped = wrapper\n",
    "    \n",
    "    print(f\"✅ Fixed accelerator: {trainer.accelerator.deepspeed_engine_wrapped}\")\n",
    "    print(f\"✅ Wrapper engine: {trainer.accelerator.deepspeed_engine_wrapped.engine}\")\n",
    "else:\n",
    "    print(\"❌ Trainer model is not DeepSpeed engine\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5eb2b9b-099e-4768-842c-560099b34181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Cell 14: Debug Trainer and DeepSpeed\\nprint(\"=== Trainer Debug Info ===\")\\n\\n# Check if trainer has accelerator\\nif hasattr(trainer, \\'accelerator\\'):\\n    print(f\"✅ Trainer has accelerator: {trainer.accelerator}\")\\n    print(f\"Accelerator device: {trainer.accelerator.device}\")\\n    print(f\"Distributed type: {trainer.accelerator.distributed_type}\")\\n    \\n    # Check DeepSpeed engine\\n    if hasattr(trainer.accelerator, \\'deepspeed_engine_wrapped\\'):\\n        engine = trainer.accelerator.deepspeed_engine_wrapped\\n        if engine is not None:\\n            print(f\"✅ DeepSpeed engine initialized: {type(engine)}\")\\n        else:\\n            print(\"❌ DeepSpeed engine is None!\")\\n    else:\\n        print(\"❌ No deepspeed_engine_wrapped attribute\")\\nelse:\\n    print(\"❌ Trainer has no accelerator attribute\")\\n\\n# Check distributed status\\nif torch.distributed.is_available() and torch.distributed.is_initialized():\\n    print(f\"✅ Distributed initialized - rank: {torch.distributed.get_rank()}\")\\nelse:\\n    print(\"ℹ️ Distributed not initialized (might be OK for single node)\")\\n\\nprint(\"=\" * 50)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Cell 14: Debug Trainer and DeepSpeed\n",
    "print(\"=== Trainer Debug Info ===\")\n",
    "\n",
    "# Check if trainer has accelerator\n",
    "if hasattr(trainer, 'accelerator'):\n",
    "    print(f\"✅ Trainer has accelerator: {trainer.accelerator}\")\n",
    "    print(f\"Accelerator device: {trainer.accelerator.device}\")\n",
    "    print(f\"Distributed type: {trainer.accelerator.distributed_type}\")\n",
    "    \n",
    "    # Check DeepSpeed engine\n",
    "    if hasattr(trainer.accelerator, 'deepspeed_engine_wrapped'):\n",
    "        engine = trainer.accelerator.deepspeed_engine_wrapped\n",
    "        if engine is not None:\n",
    "            print(f\"✅ DeepSpeed engine initialized: {type(engine)}\")\n",
    "        else:\n",
    "            print(\"❌ DeepSpeed engine is None!\")\n",
    "    else:\n",
    "        print(\"❌ No deepspeed_engine_wrapped attribute\")\n",
    "else:\n",
    "    print(\"❌ Trainer has no accelerator attribute\")\n",
    "\n",
    "# Check distributed status\n",
    "if torch.distributed.is_available() and torch.distributed.is_initialized():\n",
    "    print(f\"✅ Distributed initialized - rank: {torch.distributed.get_rank()}\")\n",
    "else:\n",
    "    print(\"ℹ️ Distributed not initialized (might be OK for single node)\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c19612f-fa9b-4a9c-a2af-761adbf245b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Cell 15: Test Single Training Step (FIXED)\\nprint(\"=== Testing Single Training Step ===\")\\n\\ntry:\\n    # Get a sample batch\\n    train_dataloader = trainer.get_train_dataloader()\\n    sample_batch = next(iter(train_dataloader))\\n    \\n    print(f\"✅ Got sample batch with keys: {sample_batch.keys()}\")\\n    print(f\"Batch size: {sample_batch[\\'input_ids\\'].shape}\")\\n    \\n    # Test forward pass\\n    model.train()\\n    with torch.no_grad():\\n        outputs = trainer.model(**sample_batch)  # Use trainer.model (DeepSpeed engine)\\n        print(f\"✅ Forward pass successful, loss: {outputs.loss.item():.4f}\")\\n    \\n    # Test backward pass - FIXED!\\n    print(\"Testing backward pass...\")\\n    outputs = trainer.model(**sample_batch)\\n    loss = outputs.loss\\n    \\n    # 🔧 FIX: Call DeepSpeed backward directly, not through accelerator\\n    print(\"Calling DeepSpeed backward directly...\")\\n    trainer.model.backward(loss)  # DeepSpeed engine backward\\n    trainer.model.step()          # DeepSpeed engine step\\n    \\n    print(\"✅ Backward pass successful!\")\\n    \\nexcept Exception as e:\\n    print(f\"❌ Error in training step: {e}\")\\n    import traceback\\n    traceback.print_exc()\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Cell 15: Test Single Training Step (FIXED)\n",
    "print(\"=== Testing Single Training Step ===\")\n",
    "\n",
    "try:\n",
    "    # Get a sample batch\n",
    "    train_dataloader = trainer.get_train_dataloader()\n",
    "    sample_batch = next(iter(train_dataloader))\n",
    "    \n",
    "    print(f\"✅ Got sample batch with keys: {sample_batch.keys()}\")\n",
    "    print(f\"Batch size: {sample_batch['input_ids'].shape}\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    model.train()\n",
    "    with torch.no_grad():\n",
    "        outputs = trainer.model(**sample_batch)  # Use trainer.model (DeepSpeed engine)\n",
    "        print(f\"✅ Forward pass successful, loss: {outputs.loss.item():.4f}\")\n",
    "    \n",
    "    # Test backward pass - FIXED!\n",
    "    print(\"Testing backward pass...\")\n",
    "    outputs = trainer.model(**sample_batch)\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    # 🔧 FIX: Call DeepSpeed backward directly, not through accelerator\n",
    "    print(\"Calling DeepSpeed backward directly...\")\n",
    "    trainer.model.backward(loss)  # DeepSpeed engine backward\n",
    "    trainer.model.step()          # DeepSpeed engine step\n",
    "    \n",
    "    print(\"✅ Backward pass successful!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in training step: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08240d0f-fb9f-4424-88b9-c6bf5f291034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Manual DeepSpeed Training ===\n",
      "Current model type: <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>\n",
      "DeepSpeed config exists: True\n",
      "Config keys: ['fp16', 'zero_optimization', 'train_micro_batch_size_per_gpu', 'gradient_accumulation_steps', 'gradient_clipping', 'wall_clock_breakdown']\n",
      "Initializing DeepSpeed manually...\n",
      "[2025-07-10 11:05:24,177] [INFO] [logging.py:107:log_dist] [Rank -1] DeepSpeed info: version=0.17.2, git-hash=unknown, git-branch=unknown\n",
      "[2025-07-10 11:05:24,178] [INFO] [comm.py:676:init_distributed] cdb=None\n",
      "[2025-07-10 11:05:24,179] [INFO] [comm.py:691:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2025-07-10 11:05:24,369] [INFO] [comm.py:746:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.16.160.247, master_port=29500\n",
      "[2025-07-10 11:05:24,371] [INFO] [comm.py:707:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-07-10 11:05:24,375] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 1\n",
      "[2025-07-10 11:05:24,384] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********\n",
      "\t self.dp_world_size=1\n",
      "\t self.mp_world_size=1\n",
      "\t self.seq_dp_world_size=1\n",
      "\t self.sequence_parallel_size=1\n",
      "***********************************************\n",
      "[2025-07-10 11:05:24,633] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2025-07-10 11:05:24,635] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2025-07-10 11:05:24,636] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer\n",
      "[2025-07-10 11:05:24,642] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW\n",
      "[2025-07-10 11:05:24,643] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>\n",
      "[2025-07-10 11:05:24,644] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2025-07-10 11:05:24,645] [INFO] [stage_1_and_2.py:172:__init__] Reduce bucket size 500000000\n",
      "[2025-07-10 11:05:24,646] [INFO] [stage_1_and_2.py:173:__init__] Allgather bucket size 500000000\n",
      "[2025-07-10 11:05:24,647] [INFO] [stage_1_and_2.py:174:__init__] CPU Offload: False\n",
      "[2025-07-10 11:05:24,647] [INFO] [stage_1_and_2.py:175:__init__] Round robin gradient partitioning: False\n",
      "[2025-07-10 11:05:25,407] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states\n",
      "[2025-07-10 11:05:25,409] [INFO] [utils.py:782:see_memory_usage] MA 0.71 GB         Max_MA 0.94 GB         CA 0.94 GB         Max_CA 1 GB \n",
      "[2025-07-10 11:05:25,411] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.61 GB, percent = 1.4%\n",
      "[2025-07-10 11:05:25,678] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states\n",
      "[2025-07-10 11:05:25,680] [INFO] [utils.py:782:see_memory_usage] MA 0.71 GB         Max_MA 1.17 GB         CA 1.41 GB         Max_CA 1 GB \n",
      "[2025-07-10 11:05:25,681] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.61 GB, percent = 1.4%\n",
      "[2025-07-10 11:05:25,682] [INFO] [stage_1_and_2.py:599:__init__] optimizer state initialized\n",
      "[2025-07-10 11:05:25,940] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2025-07-10 11:05:25,942] [INFO] [utils.py:782:see_memory_usage] MA 0.71 GB         Max_MA 0.71 GB         CA 1.41 GB         Max_CA 1 GB \n",
      "[2025-07-10 11:05:25,943] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 6.61 GB, percent = 1.4%\n",
      "[2025-07-10 11:05:25,948] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer\n",
      "[2025-07-10 11:05:25,949] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None\n",
      "[2025-07-10 11:05:25,950] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2025-07-10 11:05:25,951] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[1e-05], mom=[(0.9, 0.999)]\n",
      "[2025-07-10 11:05:25,952] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True\n",
      "[2025-07-10 11:05:25,953] [INFO] [config.py:954:print] DeepSpeedEngine configuration:\n",
      "[2025-07-10 11:05:25,955] [INFO] [config.py:958:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2025-07-10 11:05:25,956] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}\n",
      "[2025-07-10 11:05:25,957] [INFO] [config.py:958:print]   amp_enabled .................. False\n",
      "[2025-07-10 11:05:25,957] [INFO] [config.py:958:print]   amp_params ................... False\n",
      "[2025-07-10 11:05:25,958] [INFO] [config.py:958:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2025-07-10 11:05:25,959] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=False immediate_grad_update=False check_grad_overflow=False\n",
      "[2025-07-10 11:05:25,960] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}\n",
      "[2025-07-10 11:05:25,960] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2025-07-10 11:05:25,962] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True\n",
      "[2025-07-10 11:05:25,963] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False\n",
      "[2025-07-10 11:05:25,964] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f7ec53a4b50>\n",
      "[2025-07-10 11:05:25,964] [INFO] [config.py:958:print]   communication_data_type ...... None\n",
      "[2025-07-10 11:05:25,965] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False\n",
      "[2025-07-10 11:05:25,967] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2025-07-10 11:05:25,967] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False\n",
      "[2025-07-10 11:05:25,968] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False\n",
      "[2025-07-10 11:05:25,969] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2025-07-10 11:05:25,970] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False\n",
      "[2025-07-10 11:05:25,971] [INFO] [config.py:958:print]   dataloader_drop_last ......... False\n",
      "[2025-07-10 11:05:25,971] [INFO] [config.py:958:print]   disable_allgather ............ False\n",
      "[2025-07-10 11:05:25,972] [INFO] [config.py:958:print]   dump_state ................... False\n",
      "[2025-07-10 11:05:25,973] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False\n",
      "[2025-07-10 11:05:25,974] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2025-07-10 11:05:25,975] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2025-07-10 11:05:25,975] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0\n",
      "[2025-07-10 11:05:25,977] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100\n",
      "[2025-07-10 11:05:25,977] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06\n",
      "[2025-07-10 11:05:25,978] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01\n",
      "[2025-07-10 11:05:25,979] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False\n",
      "[2025-07-10 11:05:25,980] [INFO] [config.py:958:print]   elasticity_enabled ........... False\n",
      "[2025-07-10 11:05:25,981] [INFO] [config.py:958:print]   float16_config ............... enabled=True auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False\n",
      "[2025-07-10 11:05:25,981] [INFO] [config.py:958:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2025-07-10 11:05:25,982] [INFO] [config.py:958:print]   global_rank .................. 0\n",
      "[2025-07-10 11:05:25,983] [INFO] [config.py:958:print]   grad_accum_dtype ............. None\n",
      "[2025-07-10 11:05:25,984] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 1\n",
      "[2025-07-10 11:05:25,985] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0\n",
      "[2025-07-10 11:05:25,986] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0\n",
      "[2025-07-10 11:05:25,987] [INFO] [config.py:958:print]   graph_harvesting ............. False\n",
      "[2025-07-10 11:05:25,988] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2025-07-10 11:05:25,989] [INFO] [config.py:958:print]   load_universal_checkpoint .... False\n",
      "[2025-07-10 11:05:25,989] [INFO] [config.py:958:print]   memory_breakdown ............. False\n",
      "[2025-07-10 11:05:25,990] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False\n",
      "[2025-07-10 11:05:25,991] [INFO] [config.py:958:print]   mics_shard_size .............. -1\n",
      "[2025-07-10 11:05:25,992] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')\n",
      "[2025-07-10 11:05:25,993] [INFO] [config.py:958:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2025-07-10 11:05:25,994] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False\n",
      "[2025-07-10 11:05:25,995] [INFO] [config.py:958:print]   optimizer_name ............... None\n",
      "[2025-07-10 11:05:25,995] [INFO] [config.py:958:print]   optimizer_params ............. None\n",
      "[2025-07-10 11:05:25,996] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}\n",
      "[2025-07-10 11:05:25,997] [INFO] [config.py:958:print]   pld_enabled .................. False\n",
      "[2025-07-10 11:05:25,998] [INFO] [config.py:958:print]   pld_params ................... False\n",
      "[2025-07-10 11:05:25,999] [INFO] [config.py:958:print]   prescale_gradients ........... False\n",
      "[2025-07-10 11:05:26,000] [INFO] [config.py:958:print]   scheduler_name ............... None\n",
      "[2025-07-10 11:05:26,000] [INFO] [config.py:958:print]   scheduler_params ............. None\n",
      "[2025-07-10 11:05:26,001] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32\n",
      "[2025-07-10 11:05:26,002] [INFO] [config.py:958:print]   sparse_attention ............. None\n",
      "[2025-07-10 11:05:26,003] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False\n",
      "[2025-07-10 11:05:26,004] [INFO] [config.py:958:print]   steps_per_print .............. None\n",
      "[2025-07-10 11:05:26,005] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False\n",
      "[2025-07-10 11:05:26,006] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True\n",
      "[2025-07-10 11:05:26,006] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None\n",
      "[2025-07-10 11:05:26,008] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False\n",
      "[2025-07-10 11:05:26,008] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None\n",
      "[2025-07-10 11:05:26,009] [INFO] [config.py:958:print]   train_batch_size ............. 2\n",
      "[2025-07-10 11:05:26,010] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  2\n",
      "[2025-07-10 11:05:26,011] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False\n",
      "[2025-07-10 11:05:26,012] [INFO] [config.py:958:print]   use_node_local_storage ....... False\n",
      "[2025-07-10 11:05:26,012] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False\n",
      "[2025-07-10 11:05:26,014] [INFO] [config.py:958:print]   weight_quantization_config ... None\n",
      "[2025-07-10 11:05:26,015] [INFO] [config.py:958:print]   world_size ................... 1\n",
      "[2025-07-10 11:05:26,015] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  False\n",
      "[2025-07-10 11:05:26,016] [INFO] [config.py:958:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False\n",
      "[2025-07-10 11:05:26,017] [INFO] [config.py:958:print]   zero_enabled ................. True\n",
      "[2025-07-10 11:05:26,018] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2025-07-10 11:05:26,019] [INFO] [config.py:958:print]   zero_optimization_stage ...... 2\n",
      "[2025-07-10 11:05:26,019] [INFO] [config.py:944:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"reduce_bucket_size\": 5.000000e+08\n",
      "    }, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "✅ DeepSpeed engine created: <class 'deepspeed.runtime.engine.DeepSpeedEngine'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-10 11:05:26,542] [INFO] [loss_scaler.py:191:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, but hysteresis is 2. Reducing hysteresis to 1\n",
      "Step 0: Loss = 40.6140\n",
      "[2025-07-10 11:05:26,805] [INFO] [loss_scaler.py:184:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 65536, reducing to 32768\n",
      "Step 1: Loss = 40.8954\n",
      "[2025-07-10 11:05:27,057] [INFO] [loss_scaler.py:184:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 32768, reducing to 16384\n",
      "Step 2: Loss = 40.8762\n",
      "[2025-07-10 11:05:27,152] [INFO] [loss_scaler.py:184:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16384, reducing to 8192\n",
      "Step 3: Loss = 40.6896\n",
      "✅ Manual DeepSpeed training completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 16: Manual DeepSpeed Training\n",
    "print(\"=== Manual DeepSpeed Training ===\")\n",
    "\n",
    "# בדוק מצב נוכחי\n",
    "print(f\"Current model type: {type(trainer.model)}\")\n",
    "print(f\"DeepSpeed config exists: {os.path.exists(deepspeed_config_path)}\")\n",
    "\n",
    "if os.path.exists(deepspeed_config_path):\n",
    "    with open(deepspeed_config_path, 'r') as f:\n",
    "        ds_config = json.load(f)\n",
    "    print(f\"Config keys: {list(ds_config.keys())}\")\n",
    "    \n",
    "    # אתחל DeepSpeed ידנית\n",
    "    print(\"Initializing DeepSpeed manually...\")\n",
    "    \n",
    "    try:\n",
    "        import deepspeed\n",
    "        from torch.optim import AdamW\n",
    "        \n",
    "        # צור optimizer\n",
    "        optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "        \n",
    "        # אתחל DeepSpeed\n",
    "        model_engine, optimizer, _, lr_scheduler = deepspeed.initialize(\n",
    "            model=model,  # המודל המקורי\n",
    "            optimizer=optimizer,\n",
    "            config=ds_config\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ DeepSpeed engine created: {type(model_engine)}\")\n",
    "        \n",
    "        # Manual training loop\n",
    "        train_dataloader = trainer.get_train_dataloader()\n",
    "        \n",
    "        model_engine.train()\n",
    "        for epoch in range(EPOCHS):\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                if MAX_STEPS and step >= MAX_STEPS:\n",
    "                    break\n",
    "                \n",
    "                # Forward\n",
    "                outputs = model_engine(**batch)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward & Step\n",
    "                model_engine.backward(loss)\n",
    "                model_engine.step()\n",
    "                \n",
    "                print(f\"Step {step}: Loss = {loss.item():.4f}\")\n",
    "                \n",
    "                # Log to W&B\n",
    "                if 'WANDB_API_KEY' in os.environ:\n",
    "                    wandb.log({\"loss\": loss.item(), \"step\": step})\n",
    "        \n",
    "        print(\"✅ Manual DeepSpeed training completed!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Manual DeepSpeed failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback to regular PyTorch\n",
    "        print(\"Falling back to regular PyTorch training...\")\n",
    "        \n",
    "        optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "        \n",
    "        model.train()\n",
    "        train_dataloader = trainer.get_train_dataloader()\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                if MAX_STEPS and step >= MAX_STEPS:\n",
    "                    break\n",
    "                \n",
    "                # Forward\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                print(f\"Step {step}: Loss = {loss.item():.4f}\")\n",
    "                \n",
    "                if 'WANDB_API_KEY' in os.environ:\n",
    "                    wandb.log({\"loss\": loss.item(), \"step\": step})\n",
    "        \n",
    "        print(\"✅ Regular PyTorch training completed!\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No DeepSpeed config found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc229d65-6864-4dc4-b28a-d031d69e9ecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_successful' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cell 17: Save Model (if successful)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtraining_successful\u001b[49m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/ml/model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_successful' is not defined"
     ]
    }
   ],
   "source": [
    "# Cell 17: Save Model (if successful)\n",
    "if training_successful:\n",
    "    print(\"Saving model...\")\n",
    "    trainer.save_model('/tmp/ml/model')\n",
    "    tokenizer.save_pretrained('/tmp/ml/model')\n",
    "    \n",
    "    # Save training metrics\n",
    "    metrics_file = '/tmp/ml/output/data/training_metrics.json'\n",
    "    \n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump({\n",
    "            \"instance_type\": INSTANCE_TYPE,\n",
    "            \"total_time_hours\": total_time / 3600,\n",
    "            \"total_tokens\": metrics_callback.total_tokens,\n",
    "            \"avg_tokens_per_second\": metrics_callback.total_tokens / total_time if total_time > 0 else 0,\n",
    "            \"estimated_cost\": instance_config.get('estimated_hourly_cost', 32.77) * (total_time / 3600),\n",
    "            \"training_successful\": training_successful\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"✅ Model and metrics saved\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Training failed - no model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346a0df2-6d00-4a6a-a2cd-11fabd885e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Cleanup and Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Instance Type: {INSTANCE_TYPE}\")\n",
    "print(f\"Training Successful: {training_successful}\")\n",
    "print(f\"Total Time: {total_time:.2f} seconds\")\n",
    "print(f\"Total Steps: {metrics_callback.steps}\")\n",
    "print(f\"Total Tokens: {metrics_callback.total_tokens:,}\")\n",
    "\n",
    "if training_successful:\n",
    "    print(\"✅ Training completed successfully!\")\n",
    "    print(\"Model saved to: /tmp/ml/model\")\n",
    "    print(\"Metrics saved to: /tmp/ml/output/data/training_metrics.json\")\n",
    "else:\n",
    "    print(\"❌ Training failed - check error messages above\")\n",
    "\n",
    "# Finish W&B\n",
    "wandb.finish()\n",
    "print(\"✅ W&B run finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
