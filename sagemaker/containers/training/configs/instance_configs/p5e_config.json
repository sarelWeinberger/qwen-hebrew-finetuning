{
  "instance_type": "ml.p5e.48xlarge",
  "gpu_count": 8,
  "gpu_type": "H100",
  "gpu_memory": "80GB",
  "total_gpu_memory": "640GB",
  "cpu_count": 192,
  "ram": "2048GB",
  "network": "3200 Gbps",
  "storage": "8x7.6TB NVMe SSD",
  "batch_size_per_gpu": 8,
  "gradient_accumulation_steps": 1,
  "deepspeed_config": "configs/deepspeed/p5e_deepspeed_config.json",
  "training_config": "configs/training_configs/p5e_training_config.json",
  "estimated_hourly_cost": 98.32,
  "optimization_notes": "H100 with high-performance NVMe storage for maximum throughput and efficient checkpointing",
  "recommended_use_cases": [
    "Maximum performance training with storage optimization",
    "Large datasets with frequent checkpointing",
    "High-throughput production workloads",
    "Time-critical training with data-intensive operations"
  ],
  "performance_characteristics": {
    "memory_efficiency": "excellent",
    "compute_efficiency": "maximum",
    "cost_efficiency": "premium",
    "network_efficiency": "excellent",
    "storage_efficiency": "maximum"
  },
  "training_parameters": {
    "learning_rate": 1e-5,
    "weight_decay": 0.01,
    "warmup_ratio": 0.03,
    "max_grad_norm": 1.0,
    "fp16": true,
    "gradient_checkpointing": false
  },
  "h100_optimizations": {
    "transformer_engine": true,
    "flash_attention": true,
    "tensor_parallelism": true,
    "pipeline_parallelism": false,
    "nvme_checkpointing": true
  },
  "nvme_optimization": {
    "checkpoint_to_nvme": true,
    "optimizer_state_nvme": true,
    "temp_data_nvme": true,
    "nvme_path": "/tmp/nvme_cache",
    "async_checkpointing": true
  },
  "expected_performance": {
    "relative_speed": 1.1,
    "tokens_per_second_estimate": 8800,
    "memory_utilization_target": 0.90,
    "storage_throughput_gbps": 60
  }
}