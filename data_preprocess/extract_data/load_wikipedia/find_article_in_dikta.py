#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import boto3
import pandas as pd
import json
from pathlib import Path
import re


def list_dikta_files(bucket_name, prefix):
    """
    ××•×¦× ××ª ×›×œ ×§×‘×¦×™ ×“×™×§×˜×”-×•×™×§×™×¤×“×™×” ×‘-S3
    """
    print(f"ğŸ” ××—×¤×© ×§×‘×¦×™ ×“×™×§×˜×” ×‘-S3: {bucket_name}/{prefix}")
    print("=" * 60)

    s3 = boto3.client('s3')

    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)

        if 'Contents' not in response:
            print("âŒ ×œ× × ××¦××• ×§×‘×¦×™×")
            return []

        dikta_files = []
        for obj in response['Contents']:
            filename = obj['Key']
            # ×”×§×™×“×•××ª ×›×‘×¨ ××›×™×œ×” ××ª AllOfNewHebrewWikipediaWithArticles
            if filename.startswith(prefix):
                size_mb = obj['Size'] / (1024 * 1024)
                dikta_files.append({
                    'filename': filename,
                    'size_mb': round(size_mb, 2),
                    'last_modified': obj['LastModified']
                })

        print(f"âœ… × ××¦××• {len(dikta_files)} ×§×‘×¦×™ ×“×™×§×˜×”-×•×™×§×™×¤×“×™×”:")
        for i, file_info in enumerate(dikta_files, 1):
            print(f"   {i}. {file_info['filename']}")
            print(f"      ×’×•×“×œ: {file_info['size_mb']} MB")
            print(f"      ×¢×“×›×•×Ÿ ××—×¨×•×Ÿ: {file_info['last_modified']}")
            print()

        return dikta_files

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×’×™×©×” ×œ-S3: {e}")
        return []


def search_article_in_file(bucket_name, filename, article_title):
    """
    ××—×¤×© ×¢×¨×š ×¡×¤×¦×™×¤×™ ×‘×§×•×‘×¥ ×“×™×§×˜×”
    """
    print(f"ğŸ” ××—×¤×© '{article_title}' ×‘×§×•×‘×¥: {filename}")

    # ×”×’×“×¨×ª ×ª×™×§×™×™×ª ×”×”×•×¨×“×”
    download_dir = Path("")
    download_dir.mkdir(exist_ok=True)

    local_filename = download_dir / Path(filename).name

    # ×‘×“×™×§×” ×× ×”×§×•×‘×¥ ×›×‘×¨ ×§×™×™× ××§×•××™×ª
    if local_filename.exists():
        print(f"âœ… ×”×§×•×‘×¥ ×›×‘×¨ ×§×™×™× ××§×•××™×ª: {local_filename}")
        file_size_mb = local_filename.stat().st_size / (1024 * 1024)
        print(f"ğŸ“Š ×’×•×“×œ ×”×§×•×‘×¥: {file_size_mb:.2f} MB")
    else:
        # ×”×•×¨×“×ª ×”×§×•×‘×¥ ×-S3
        print(f"â¬‡ï¸ ××•×¨×™×“ ×§×•×‘×¥ ×-S3...")
        s3 = boto3.client('s3')
        try:
            s3.download_file(bucket_name, filename, str(local_filename))
            file_size_mb = local_filename.stat().st_size / (1024 * 1024)
            print(f"âœ… ×”×§×•×‘×¥ ×”×•×¨×“: {local_filename} ({file_size_mb:.2f} MB)")
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×”×•×¨×“×ª ×”×§×•×‘×¥: {e}")
            return None

    try:
        # ×§×¨×™××ª ×”×§×•×‘×¥ (× × ×™×— ×©×–×” CSV)
        print(f"ğŸ“– ×§×•×¨× ×§×•×‘×¥...")
        if str(local_filename).endswith('.csv'):
            df = pd.read_csv(local_filename)
            print(f"ğŸ“Š × ×˜×¢×Ÿ CSV ×¢× {len(df)} ×©×•×¨×•×ª")
            print(f"ğŸ“‹ ×¢××•×“×•×ª: {list(df.columns)}")

            # ×—×™×¤×•×© ×”×¢×¨×š
            article_found = search_in_dataframe(df, article_title)
            return article_found

        elif str(local_filename).endswith('.json') or str(local_filename).endswith('.jsonl'):
            return search_in_json_file(str(local_filename), article_title)

        else:
            print(f"â“ ×¤×•×¨××˜ ×§×•×‘×¥ ×œ× ××–×•×”×”: {filename}")
            return None

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×§×•×‘×¥ {filename}: {e}")
        return None


def search_in_dataframe(df, article_title):
    """
    ××—×¤×© ×¢×¨×š ×‘-DataFrame ×¢×œ ×‘×¡×™×¡ ×”××™×œ×™× ×”×¨××©×•× ×•×ª ×‘×˜×•×¨ text
    """
    print(f"ğŸ” ××—×¤×© '{article_title}' ×‘×˜×•×¨ text...")
    print(f"ğŸ“Š ×”×§×•×‘×¥ ××›×™×œ {len(df)} ×©×•×¨×•×ª")

    # ×•×•×“× ×©×™×© ×˜×•×¨ text
    if 'text' not in df.columns:
        print(f"âŒ ×œ× × ××¦× ×˜×•×¨ 'text'. ×˜×•×¨×™× ×–××™× ×™×: {list(df.columns)}")
        return None

    print(f"ğŸ“‹ ×˜×•×¨×™× ×‘×§×•×‘×¥: {list(df.columns)}")

    # ×—×™×¤×•×© ×‘×˜×•×¨ text
    found_articles = []

    for idx, row in df.iterrows():
        text_content = str(row['text']).strip()

        # ×‘×“×™×§×” ××“×•×™×§×ª ×©×”×˜×§×¡×˜ ××ª×—×™×œ ×¢× ×©× ×”×¢×¨×š ×›××™×œ×” ×©×œ××”
        if is_exact_title_match(text_content, article_title):
            found_articles.append((idx, text_content))
            print(f"âœ… × ××¦×! ×©×•×¨×” {idx}")
            print(f"ğŸ“„ ×ª×—×™×œ×ª ×”×˜×§×¡×˜: {text_content[:100]}...")

    if found_articles:
        # ×§×— ××ª ×”×¨××©×•×Ÿ ×©× ××¦×
        idx, content = found_articles[0]

        print(f"\nğŸ“ ×ª×•×›×Ÿ ×”×¢×¨×š ××œ×:")
        print("=" * 60)
        print(content)
        print("=" * 60)

        # ×©××™×¨×ª ×”×ª×•×›×Ÿ ×œ×§×•×‘×¥
        output_filename = f"{article_title.replace(' ', '_')}_dikta.txt"
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ’¾ ×ª×•×›×Ÿ × ×©××¨ ×œ×§×•×‘×¥: {output_filename}")

        # ×”×¦×’×ª ××™×“×¢ × ×•×¡×£ ×¢×œ ×”×©×•×¨×”
        if 'word_count' in df.columns:
            print(f"ğŸ“Š ××¡×¤×¨ ××™×œ×™×: {row['word_count']}")
        if 'character_count' in df.columns:
            print(f"ğŸ“Š ××¡×¤×¨ ×ª×•×•×™×: {row['character_count']}")
        if 'id' in df.columns:
            print(f"ğŸ†” ID: {row['id']}")

        return content
    else:
        print(f"âŒ ×œ× × ××¦× ×¢×¨×š ×©××ª×—×™×œ ×‘-'{article_title}' ×›××™×œ×” ×©×œ××”")

        # ×‘×“×™×§×” ×× ×™×© ×¢×¨×›×™× ×“×•××™×
        print(f"ğŸ” ××—×¤×© ×¢×¨×›×™× ×“×•××™×...")
        similar_articles = []

        for idx, row in df.iterrows():
            text_content = str(row['text'])
            first_line = text_content.split('\n')[0].strip()

            # ×‘×“×™×§×” ×× ×™×© ××™×œ×™× ×“×•××•×ª (×œ× ××“×•×™×§×ª)
            if article_title.lower() in first_line.lower():
                similar_articles.append((idx, first_line))
                if len(similar_articles) >= 5:  # ××§×¡×™××•× 5 ×“×•×’×××•×ª
                    break

        if similar_articles:
            print(f"ğŸ’¡ × ××¦××• ×¢×¨×›×™× ×“×•××™×:")
            for idx, first_line in similar_articles:
                print(f"   ×©×•×¨×” {idx}: {first_line[:80]}...")
        else:
            print(f"ğŸ’¡ ×œ× × ××¦××• ×¢×¨×›×™× ×“×•××™×")

        return None


def is_exact_title_match(text_content, article_title):
    """
    ×‘×•×“×§ ×× ×”×˜×§×¡×˜ ××ª×—×™×œ ×‘×“×™×•×§ ×¢× ×›×•×ª×¨×ª ×”×¢×¨×š ×›××™×œ×” ×©×œ××”
    """
    import re

    # × ×§×” ×¨×•×•×—×™× ××™×•×ª×¨×™×
    text_content = text_content.strip()
    article_title = article_title.strip()

    # ×‘×“×™×§×” ×¤×©×•×˜×” - ×”×× ×”×˜×§×¡×˜ ××ª×—×™×œ ×¢× ×”×›×•×ª×¨×ª
    if not text_content.startswith(article_title):
        return False

    # ×‘×“×™×§×” ×©××—×¨×™ ×”×›×•×ª×¨×ª ×™×© ×¡×™××Ÿ ×¢×¦×™×¨×” ××• ×¨×•×•×—
    if len(text_content) == len(article_title):
        # ×”×˜×§×¡×˜ ×–×”×” ×œ×›×•×ª×¨×ª ×‘×“×™×•×§
        return True

    # ×”×ª×• ×”×‘× ××—×¨×™ ×”×›×•×ª×¨×ª
    next_char = text_content[len(article_title)]

    # ×¨×©×™××ª ×ª×•×•×™× ×©××•×ª×¨×™× ××—×¨×™ ×›×•×ª×¨×ª ×¢×¨×š
    allowed_chars = [
        ' ',  # ×¨×•×•×—
        '\t',  # ×˜××‘
        '\n',  # ×©×•×¨×” ×—×“×©×”
        '.',  # × ×§×•×“×”
        ',',  # ×¤×¡×™×§
        ':',  # × ×§×•×“×•×ª×™×™×
        ';',  # ×¤×¡×™×§ ×¢×œ×™×•×Ÿ
        '!',  # ×§×¨×™××”
        '?',  # ×©××œ×”
        '(',  # ×¡×•×’×¨×™×™×
        '[',  # ×¡×•×’×¨×™×™× ××¨×•×‘×¢×™×
        '-',  # ××§×£
        'â€“',  # ××§×£ ××¨×•×š
        'â€”',  # ××§×£ ××¨×•×š ×™×•×ª×¨
        "'",  # ×’×¨×© - ×œ×¦×™×•×Ÿ ×¦×œ×™×œ×™× ×–×¨×™× ×‘×¢×‘×¨×™×ª (×’', ×–', ×¦')
    ]

    if next_char in allowed_chars:
        return True

    # ×‘×“×™×§×” × ×•×¡×¤×ª ×¢× regex ×œ×•×•×“× ×©×–×• ××™×œ×” ×©×œ××”
    pattern = r'^' + re.escape(article_title) + r'(?=\s|[^\w]|$)'
    if re.match(pattern, text_content, re.UNICODE):
        return True

    return False


def search_in_json_file(filename, article_title):
    """
    ××—×¤×© ×¢×¨×š ×‘×§×•×‘×¥ JSON
    """
    print(f"ğŸ” ××—×¤×© '{article_title}' ×‘×§×•×‘×¥ JSON: {filename}")

    try:
        # × ×¡×” JSON ×¨×’×™×œ
        with open(filename, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # ×—×™×¤×•×© ×¨×§×•×¨×¡×™×‘×™
        result = search_in_json_recursive(data, article_title)
        if result:
            print(f"âœ… × ××¦× ×¢×¨×š!")
            print(result[:500])
            return result

    except:
        # ×× × ×›×©×œ, × ×¡×” JSONL (JSON Lines)
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f):
                    if line.strip():
                        try:
                            obj = json.loads(line)
                            result = search_in_json_recursive(obj, article_title)
                            if result:
                                print(f"âœ… × ××¦× ×‘×©×•×¨×” {line_num}!")
                                return result
                        except:
                            continue
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×§×¨×™××ª JSON: {e}")

    return None


def search_in_json_recursive(obj, search_term):
    """
    ×—×™×¤×•×© ×¨×§×•×¨×¡×™×‘×™ ×‘-JSON
    """
    if isinstance(obj, dict):
        for key, value in obj.items():
            if isinstance(value, str) and search_term in value:
                return value
            elif isinstance(value, (dict, list)):
                result = search_in_json_recursive(value, search_term)
                if result:
                    return result
    elif isinstance(obj, list):
        for item in obj:
            result = search_in_json_recursive(item, search_term)
            if result:
                return result

    return None


def main():
    """
    ×”×¤×¢×œ×” ×¨××©×™×ª
    """
    print("ğŸ¯ ××•×¦× ×¢×¨×š ×•×™×§×™×¤×“×™×” ××§×‘×¦×™ ×“×™×§×˜×”")
    print("=" * 60)

    # ×”×’×“×¨×•×ª
    bucket_name = 'israllm-datasets'
    prefix = 'csv-dataset/AllOfNewHebrewWikipediaWithArticles'
    article_title = '×¨××ª ×’×Ÿ'

    print(f"ğŸ” ××—×¤×© ×¢×¨×š: '{article_title}'")
    print(f"ğŸ“‚ ×‘-S3: {bucket_name}/{prefix}")
    print()

    # ×©×œ×‘ 1: ××¦×™××ª ×§×‘×¦×™ ×“×™×§×˜×”
    dikta_files = list_dikta_files(bucket_name, prefix)

    if not dikta_files:
        print("âŒ ×œ× × ××¦××• ×§×‘×¦×™ ×“×™×§×˜×”")
        return

    # ×©×œ×‘ 2: ×—×™×¤×•×© ×‘×›×œ ×§×•×‘×¥
    for file_info in dikta_files:
        filename = file_info['filename']
        print(f"\n{'=' * 60}")

        result = search_article_in_file(bucket_name, filename, article_title)

        if result:
            print(f"ğŸ‰ × ××¦× ×”×¢×¨×š '{article_title}' ×‘×§×•×‘×¥: {filename}")
            break
    else:
        print(f"\nâŒ ×”×¢×¨×š '{article_title}' ×œ× × ××¦× ×‘××£ ×§×•×‘×¥ ×“×™×§×˜×”")
        print("ğŸ’¡ × ×¡×” ×¢×¨×›×™× ××—×¨×™× ××• ×‘×“×•×§ ××ª ×©××•×ª ×”×§×‘×¦×™×")


if __name__ == "__main__":
    main()