{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d231fbaf-356f-4b4d-a413-76f45d20e774",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b687b6-caa5-4153-84cd-39b3a12fc895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.parse_labeling import parse_labeled_file, parse_from_gradio, parse_mqm, map_rating_to_model\n",
    "from src.parse_labeling import MQM_metrics, rating_gold_metrics, parse_single_file_gradio\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "raw",
   "id": "349c34d0-ac19-4fd0-aa1d-de668289ce14",
   "metadata": {},
   "source": [
    "# df = pd.read_csv('labeled_files/copa_TRAIN_gradio.csv')\n",
    "# df = pd.read_csv('labeled_files/copa_TEST_gradio.csv')\n",
    "# df = pd.read_csv('labeled_files/mmlu_main_sub_TEST_labeled_gradio.csv')\n",
    "# df = pd.read_csv('labeled_files/mmlu_main_sub_TEST_2_labeled_gradio.csv')\n",
    "df = pd.read_csv('labeled_files/mmlu_prob_TEST_2_gradio.csv')\n",
    "# df = pd.read_csv('labeled_files/hellaswag_TEST_gradio.csv').head(710)\n",
    "df = df.fillna('')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d47eb984-00bb-492a-99b8-c598fbecbee1",
   "metadata": {},
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab66830-fa83-4d4f-8ba5-b9041f01d125",
   "metadata": {},
   "source": [
    "# Gemini-Claude Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d29e9d-91f1-4be3-b83e-3906f62ee58a",
   "metadata": {},
   "source": [
    "## with Israel's labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821bbf7-4c9e-4b98-9bc6-29c4a9b88809",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13eb0c3-9daa-475d-938e-0a1a7ba59beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_names(df, map_names):\n",
    "    df['model 1'] = df['model 1'].apply(lambda x: map_names[x])\n",
    "    df['model 2'] = df['model 2'].apply(lambda x: map_names[x])\n",
    "    df['rating model'] = df['rating model'].apply(lambda x: map_names[x])\n",
    "    return df\n",
    "\n",
    "# Claude\n",
    "change_names_model_claude = {\n",
    "    'claude_4_opus_v7_thinking': 'claude 4 sonnet',\n",
    "    'claude_3-7_v7_thinking': 'claude 3.7 sonnet',\n",
    "    'BOTH': 'BOTH',\n",
    "    'SKIP': 'SKIP',\n",
    "    '': '',\n",
    "}\n",
    "\n",
    "# ARC-AI2 & GSM8K\n",
    "change_names_model_arc_gsm = {\n",
    "    'claude_v2_refine': 'claude 3.7 sonnet',\n",
    "    'gemini_pro_think_v2': 'gemini pro 2.5',\n",
    "    'BOTH': 'BOTH',\n",
    "    'SKIP': 'SKIP',\n",
    "    '': '',\n",
    "}\n",
    "\n",
    "# MMLU\n",
    "change_names_model_mmlu = {\n",
    "    'claude_thinking_v2': 'claude 3.7 sonnet',\n",
    "    'claude_v1_refine': 'claude 3.7 sonnet',\n",
    "    'gemini_pro_think_v1': 'gemini pro 2.5',\n",
    "    'BOTH': 'BOTH',\n",
    "    'SKIP': 'SKIP',\n",
    "    '': '',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648fc16-95cf-470d-8c10-117a7b919a41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CLAUDE\n",
    "labels = 'labeled_files/claude_vers_labeled_gradio.csv'\n",
    "csv_name = 'manual_compare/claude_vers_comparison_FULL.csv'\n",
    "claude_label_df, claude_or_df = parse_from_gradio(labels, csv_name)\n",
    "claude_or_df = change_names(claude_or_df, change_names_model_claude)\n",
    "\n",
    "# ARC_AI2\n",
    "labels = 'labeled_files/arc_ai_labeled_gradio.csv'\n",
    "csv_name = 'manual_compare/arc_ai2_train_top_200_FULL.csv'\n",
    "arc_label_df, arc_or_df = parse_from_gradio(labels, csv_name)\n",
    "arc_or_df = change_names(arc_or_df, change_names_model_arc_gsm)\n",
    "\n",
    "# GSM8K\n",
    "labels = 'labeled_files/gsm8k_labeled_gradio.csv'\n",
    "csv_name = 'manual_compare/gsm8k_169_FULL.csv'\n",
    "gsm_label_df, gsm_or_df = parse_from_gradio(labels, csv_name)\n",
    "gsm_or_df = change_names(gsm_or_df, change_names_model_arc_gsm)\n",
    "\n",
    "# Read MMLU with single file\n",
    "mmlu_labels_name = 'labeled_files/mmlu_test_labeled_gradio.csv'\n",
    "mmlu_or_df = parse_single_file_gradio(mmlu_labels_name)\n",
    "mmlu_label_df = mmlu_or_df\n",
    "mmlu_or_df = change_names(mmlu_or_df, change_names_model_mmlu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afb52b-25eb-4082-97a7-a6b19ed3d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_label_df = mmlu_label_df[mmlu_or_df['rating'] != '']\n",
    "mmlu_or_df = mmlu_or_df[mmlu_or_df['rating'] != '']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb5db79f-0857-49e7-9412-da06ad3e707c",
   "metadata": {},
   "source": [
    "or_df['rating model'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e501373-25e8-4d4b-9503-8051da1cc54e",
   "metadata": {},
   "source": [
    "or_df['indx'] = np.array(range(60)) // 20\n",
    "change = {\n",
    "    0: 'ARC-AI2',\n",
    "    1: 'GSM8K',\n",
    "    2: 'MMLU',\n",
    "}\n",
    "or_df['indx'] = or_df['indx'].apply(lambda x: change[x])\n",
    "\n",
    "or_df.groupby('indx')['rating model'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5ef6f-885c-4f87-b634-4fc99d1cc1f5",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0448c5-f731-4748-90e1-de51652451e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_or_df['rating model'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb1578-1c5f-4ba0-97fa-dcaacb3311ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10)) #, constrained_layout=True)\n",
    "\n",
    "rating_gold_metrics(arc_or_df, f'ARC_AI2 {arc_or_df.shape[0] - (arc_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', ax=axs[0, 0])\n",
    "rating_gold_metrics(gsm_or_df, f'GSM8K {gsm_or_df.shape[0] - (gsm_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', ax=axs[0, 1])\n",
    "rating_gold_metrics(mmlu_or_df, f'MMLU {mmlu_or_df.shape[0] - (mmlu_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', ax=axs[1, 0])\n",
    "rating_gold_metrics(claude_or_df, f'Claude versions {claude_or_df.shape[0] - (claude_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', False, ax=axs[1, 1])\n",
    "\n",
    "fig.subplots_adjust(hspace=0.25, wspace=0.25)\n",
    "fig.suptitle('Comparison between models', y=0.98, fontsize=15)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        axs[i, j].set_xlabel(axs[i, j].get_xlabel(), fontsize=13)\n",
    "        axs[i, j].set_ylabel(axs[i, j].get_ylabel(), fontsize=13)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('plots/Rating comparison.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752ba9c5-08a4-4d77-aa67-b86f6c40634f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mqm_res, mqm_score = parse_mqm(arc_or_df[arc_or_df['rating model'] != 'SKIP'], arc_label_df[arc_or_df['rating model'] != 'SKIP'])\n",
    "MQM_metrics(mqm_res, mqm_score, f'ARC-AI2 {arc_or_df.shape[0] - (arc_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', 'arc_ai2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee154a9-b94e-40c7-91ac-8669e3e15670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mqm_res, mqm_score = parse_mqm(gsm_or_df[gsm_or_df['rating model'] != 'SKIP'], gsm_label_df[gsm_or_df['rating model'] != 'SKIP'])\n",
    "MQM_metrics(mqm_res, mqm_score, f'GSM8K {gsm_or_df.shape[0] - (gsm_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', 'gsm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a26885-931c-4aae-ba8c-40997f50ae78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mqm_res, mqm_score = parse_mqm(mmlu_or_df[mmlu_or_df['rating model'] != 'SKIP'], mmlu_label_df[mmlu_or_df['rating model'] != 'SKIP'])\n",
    "MQM_metrics(mqm_res, mqm_score, f'MMLU {mmlu_or_df.shape[0] - (mmlu_or_df[\"rating model\"] == \"SKIP\").sum()} samples - ', 'mmlu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9078d1-ccf7-4eb3-8ee4-db89ddbad492",
   "metadata": {},
   "source": [
    "## Israel-Guy Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d49ccb-3511-4852-b56c-d22c5cb7390a",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45487f0-7131-4e1f-97ce-9e22c03eedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_df_1 = pd.read_csv('labeled_files/overlap_israel.csv')\n",
    "overlap_df_2 = pd.read_csv('labeled_files/overlap_gradio.csv')\n",
    "\n",
    "overlap_df_1 = overlap_df_1.fillna('')\n",
    "overlap_df_2 = overlap_df_2.fillna('')\n",
    "\n",
    "# Fixing\n",
    "overlap_df_1.loc[85, 'rating'] = 'SKIP'\n",
    "\n",
    "assert (overlap_df_1['text_column'] == overlap_df_2['text_column']).all(), \"mismatch between the overlaping dataframes - English\"\n",
    "assert (overlap_df_1['new_text_column'] == overlap_df_2['new_text_column']).all(), \"mismatch between the overlaping dataframes - Hebrew\"\n",
    "\n",
    "overlap_df_1.shape, overlap_df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044eef6-eacc-48d2-b658-03e9dd6156d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_or = pd.read_csv('manual_compare/arc_ai2_train_top_200_FULL.csv').iloc[10:40]\n",
    "arc_or.index = range(30)\n",
    "gsm_or = pd.read_csv('manual_compare/gsm8k_169_FULL.csv').iloc[10:40]\n",
    "gsm_or.index = range(30, 60)\n",
    "mmlu_or = pd.read_csv('manual_compare/mmlu_test_each_90_FULL.csv').iloc[10:40]\n",
    "mmlu_or.index = range(60, 90)\n",
    "\n",
    "assert (arc_or['original'] == overlap_df_1.iloc[:30]['text_column']).all(), \"problem with arc\"\n",
    "assert (gsm_or['original'] == overlap_df_1.iloc[30:60]['text_column']).all(), \"problem with gsm\"\n",
    "assert (mmlu_or['original'] == overlap_df_1.iloc[60:]['text_column']).all(),  \"problem with mmlu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900eff4e-b71b-4af2-b11e-8a62ede617f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# names mapping\n",
    "change_names_overlap = {\n",
    "    'claude_v2_refine': 'claude',\n",
    "    'claude_thinking_v2': 'claude',\n",
    "    'claude_v1_refine': 'claude',\n",
    "    'gemini_pro_think_v2': 'gemini',\n",
    "    'gemini_pro_think_v1': 'gemini',\n",
    "    'BOTH': 'BOTH',\n",
    "    'SKIP': 'SKIP',\n",
    "    '': '',\n",
    "}\n",
    "\n",
    "# Add models\n",
    "# loc includes the final number (not like 'range' or 'iloc'....)\n",
    "for df in [overlap_df_1, overlap_df_2]:\n",
    "    df.loc[:29, 'rating'] = df.iloc[:30].apply(lambda x: map_rating_to_model(x, arc_or), axis=1)\n",
    "    df.loc[30:59, 'rating'] = df.iloc[30:60].apply(lambda x: map_rating_to_model(x, gsm_or), axis=1)\n",
    "    df.loc[60:, 'rating'] = df.iloc[60:].apply(lambda x: map_rating_to_model(x, mmlu_or), axis=1)\n",
    "\n",
    "    df['rating'] = df['rating'].map(change_names_overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183818de-a85c-4306-9fbd-aa484f83cba6",
   "metadata": {},
   "source": [
    "### Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409c3a9-713e-4f51-beb4-83a1f2a9b76b",
   "metadata": {},
   "source": [
    "#### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "raw",
   "id": "986aeac0-c791-40cf-85a5-9f2338df716c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "overlap_df_1['rating'].iloc[span[0]:span[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf02384-ccdd-4beb-9842-fb236da9d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = ['All Benchmarks', 'ARC-AI2', 'GSM8K', 'MMLU']\n",
    "span_lst = [(0, 90), (0, 30), (30, 60), (60, 90)]\n",
    "\n",
    "for i, j, span, title in zip([0, 0, 1, 1], [0, 1, 0, 1], span_lst, titles_lst):\n",
    "    print(title)\n",
    "    cm = confusion_matrix(overlap_df_1['rating'].iloc[span[0]:span[1]], overlap_df_2['rating'].iloc[span[0]:span[1]], labels=['gemini', 'claude', 'BOTH'])\n",
    "    p0 = cm.trace() / cm.sum()\n",
    "    pe = ((cm.sum(axis=0) / cm.sum()) * (cm.sum(axis=1) / cm.sum())).sum()\n",
    "    kappa = (p0 - pe) / (1 - pe)\n",
    "    # print(f'{p0:.2f}, {pe:.2f}, {kappa:.2f}')\n",
    "    print(f'{kappa:.2f}')\n",
    "    # display(cm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967ed09-41a7-41e7-ba67-6fe4cbd5404c",
   "metadata": {},
   "source": [
    "#### Rating (better model) agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c1e01-4787-4985-b3e4-146191725a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = ['All Benchmarks - 90 samples', 'ARC-AI2', 'GSM8K', 'MMLU']\n",
    "span_lst = [(0, 90), (0, 30), (30, 60), (60, 90)]\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for i, j, span, title in zip([0, 0, 1, 1], [0, 1, 0, 1], span_lst, titles_lst):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        overlap_df_1['rating'].iloc[span[0]:span[1]],\n",
    "        overlap_df_2['rating'].iloc[span[0]:span[1]],\n",
    "        ax=axs[i, j],\n",
    "        colorbar=False,\n",
    "        text_kw={'size': 15},\n",
    "        labels=['gemini', 'claude', 'BOTH', 'SKIP'],\n",
    "        # normalize='all',\n",
    "        # values_format='.1%'\n",
    "    )\n",
    "    axs[i, j].set_ylabel('First labeler', fontsize=13)\n",
    "    axs[i, j].set_xlabel('Second labeler', fontsize=13)\n",
    "    axs[i, j].set_title(f'{title}', fontsize=13)\n",
    "    \n",
    "fig.suptitle(f'Rating agreement - 30 samples each', fontsize=16)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'plots/overlap_rating_cm_count.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9782d5e-7c30-4c03-aa47-ad63c16b7331",
   "metadata": {},
   "source": [
    "#### Gemini gold-fixing agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109c436-8bf9-4a01-91f9-f201a222de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add Copa overlap samples\n",
    "# TODO Add HellaSwag overlap samples\n",
    "copa_1_indcs = list(range(500, 530)) + list(range(0, 15)) + list(range(250, 265))\n",
    "copa_2_indcs = list(range(0, 15)) + list(range(250, 265)) + list(range(500, 530))\n",
    "\n",
    "labeler_1_lst = [\n",
    "    pd.read_csv('labeled_files/arc_ai_TEST_labeled_gradio.csv').tail(50).reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/gsm_TEST_labeled_gradio.csv').tail(50).reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/mmlu_main_sub_TEST_labeled_gradio.csv').iloc[:500:15].reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/copa_TRAIN_gradio.csv').iloc[copa_1_indcs].reset_index(drop=True),\n",
    "]\n",
    "labeler_2_lst = [\n",
    "    pd.read_csv('labeled_files/arc_ai_TEST_2_labeled_gradio.csv').iloc[1:51].reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/gsm_TEST_2_labeled_gradio.csv').head(50).reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/mmlu_main_sub_TEST_2_labeled_gradio.csv').head(34).reset_index(drop=True),\n",
    "    pd.read_csv('labeled_files/copa_TEST_gradio.csv').iloc[copa_2_indcs].reset_index(drop=True),\n",
    "]\n",
    "\n",
    "for df in labeler_1_lst + labeler_2_lst:\n",
    "    df.fillna('', inplace=True)\n",
    "\n",
    "labeler_1_lst = [pd.concat(labeler_1_lst, ignore_index=True)] + labeler_1_lst\n",
    "labeler_2_lst = [pd.concat(labeler_2_lst, ignore_index=True)] + labeler_2_lst\n",
    "\n",
    "for df_1, df_2 in zip(labeler_1_lst, labeler_2_lst):\n",
    "    assert (df_1['text_column'] == df_2['text_column']).all(), \"mismatch between the overlaping dataframes - English\"\n",
    "    assert (df_1['new_text_column'] == df_2['new_text_column']).all(), \"mismatch between the overlaping dataframes - Hebrew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8ee4a-0131-4a7f-bb66-3aac43cc4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(labeler_2_lst[1]['gold'] != '').sum(), (labeler_1_lst[1]['gold'] != '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a20386-ef78-4563-94f2-f55b87036b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = ['All Benchmarks', 'ARC-AI2', 'GSM8K', 'MMLU', 'COPA', 'HellaSwag']\n",
    "\n",
    "for df_1, df_2, title in zip(labeler_1_lst, labeler_2_lst, titles_lst):\n",
    "    print(title)\n",
    "    cm = confusion_matrix(df_1['gold'] != '', df_2['gold'] != '', labels=[False, True])\n",
    "    p0 = cm.trace() / cm.sum()\n",
    "    pe = ((cm.sum(axis=0) / cm.sum()) * (cm.sum(axis=1) / cm.sum())).sum()\n",
    "    kappa = (p0 - pe) / (1 - pe)\n",
    "    print(f'{p0:.2f}, {pe:.2f}, {kappa:.2f}')\n",
    "    display(cm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cabd6b4-8880-4bd9-8303-0efa907a2162",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_lst = ['All Benchmarks', 'ARC-AI2', 'GSM8K', 'MMLU', 'COPA', 'HellaSwag']\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "for i, j, df_1, df_2, title in zip([0, 0, 1, 1, 2, 2], [0, 1, 0, 1, 0, 1], labeler_1_lst, labeler_2_lst, titles_lst):\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        df_1['gold'] != '',\n",
    "        df_2['gold'] != '',\n",
    "        ax=axs[i, j],\n",
    "        colorbar=False,\n",
    "        text_kw={'size': 15},\n",
    "        labels=[False, True],\n",
    "        display_labels=[\"not fixed\", \"fixed\"],\n",
    "        normalize='all',\n",
    "        values_format='.0%'\n",
    "    ) \n",
    "    axs[i, j].set_ylabel('First labeler', fontsize=13)\n",
    "    axs[i, j].set_xlabel('Second labeler', fontsize=13)\n",
    "    axs[i, j].set_title(f'{title} - {df_1.shape[0]} samples', fontsize=13)\n",
    "    \n",
    "fig.suptitle(f'Rating agreement', fontsize=16)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'plots/overlap_gemini_fix.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8753705-126f-460b-8e98-a53f7f66bf65",
   "metadata": {},
   "source": [
    "#### MQM scores agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f5be2-1d4d-4c83-95eb-71f65694f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parse_labeling import map_mqm_to_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3407382d-cff8-4253-85bd-67f0e5080329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sev_cols_1 = [f'severity_annotation_{i}' for i in [1, 2, 3]]\n",
    "sev_cols_2 = [f'severity_annotation_{i}' for i in [4, 5, 6]]\n",
    "\n",
    "use_rows = ~((overlap_df_1['rating'] == 'SKIP') | (overlap_df_2['rating'] == 'SKIP'))\n",
    "# use_rows = use_rows * False + True\n",
    "\n",
    "scores_1 = pd.concat([overlap_df_1[use_rows][sev_cols_1].map(lambda x: map_mqm_to_score[x]).sum(axis=1), overlap_df_1[use_rows][sev_cols_2].map(lambda x: map_mqm_to_score[x]).sum(axis=1)], ignore_index=True)\n",
    "scores_2 = pd.concat([overlap_df_2[use_rows][sev_cols_1].map(lambda x: map_mqm_to_score[x]).sum(axis=1), overlap_df_2[use_rows][sev_cols_2].map(lambda x: map_mqm_to_score[x]).sum(axis=1)], ignore_index=True)\n",
    "\n",
    "scores_1.corr(scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23974a-c580-45fc-a30a-9ba97ccf1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqm_map = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    5: 'major',\n",
    "    6: 'major',\n",
    "    7: 'major',\n",
    "    10: 'major',\n",
    "    25: 'critical',\n",
    "    26: 'critical',\n",
    "    30: 'critical',\n",
    "}\n",
    "\n",
    "mqm_map_sev = {\n",
    "    0: '0',\n",
    "    1: 'minor',\n",
    "    2: 'minor',\n",
    "    3: 'minor',\n",
    "    5: 'major',\n",
    "    6: 'major',\n",
    "    7: 'major',\n",
    "    10: 'major',\n",
    "    25: 'critical',\n",
    "    26: 'critical',\n",
    "    30: 'critical',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ad1fb-5ce6-442d-941a-8a475576a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "mqm_score_kappa = 0\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    scores_1.apply(lambda x: mqm_map_sev[x]),\n",
    "    scores_2.apply(lambda x: mqm_map_sev[x]),\n",
    "    labels = ['0', 'minor', 'major', 'critical']\n",
    ")\n",
    "display(cm)\n",
    "p0 = cm.trace() / cm.sum()\n",
    "pe = ((cm.sum(axis=0) / cm.sum()) * (cm.sum(axis=1) / cm.sum())).sum()\n",
    "mqm_score_kappa = (p0 - pe) / (1 - pe)\n",
    "print(f'MQM score kappa: {mqm_score_kappa:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d713767-5812-4ca1-a48b-d5ef469129f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(\n",
    "    scores_1.apply(lambda x: mqm_map[x]),\n",
    "    scores_2.apply(lambda x: mqm_map[x]),\n",
    "    colorbar=False,\n",
    "    # normalize='all',\n",
    "    # values_format='2.1%'\n",
    ")\n",
    "plt.title('MQM scores agreement', fontsize=16)\n",
    "plt.ylabel('First labeler', fontsize=13)\n",
    "plt.xlabel('Second labeler', fontsize=13)\n",
    "# plt.savefig('plots/overlap_mqm_agree_count.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49a651-a270-43b5-9682-a2f104c00711",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay.from_predictions(scores_1, scores_2, colorbar=False)\n",
    "plt.title('MQM scores agreement', fontsize=16)\n",
    "plt.ylabel('First labeler', fontsize=13)\n",
    "plt.xlabel('Second labeler', fontsize=13)\n",
    "# plt.savefig('plots/overlap_mqm_agree.jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d3fb8-b661-47da-aacb-8682c7bd597a",
   "metadata": {},
   "source": [
    "#### MQM category agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4171b-236c-417d-9820-de262a3dc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "(overlap_df_1[['text_column', 'new_text_column']] == overlap_df_2[['text_column', 'new_text_column']]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd29df3-0dc3-4d4c-ad17-f6f5e81bf135",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1 = pd.concat([\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_4']].rename({'category_annotation_4': 'category'}, axis=1),\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_5']].rename({'category_annotation_5': 'category'}, axis=1),\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_6']].rename({'category_annotation_6': 'category'}, axis=1),\n",
    "])\n",
    "cat_1['index'] += 90\n",
    "\n",
    "cat_1 = pd.concat([\n",
    "    cat_1,\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_1']].rename({'category_annotation_1': 'category'}, axis=1),\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_2']].rename({'category_annotation_2': 'category'}, axis=1),\n",
    "    overlap_df_1.reset_index()[['index', 'category_annotation_3']].rename({'category_annotation_3': 'category'}, axis=1),\n",
    "])\n",
    "\n",
    "cat_2 = pd.concat([\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_4']].rename({'category_annotation_4': 'category'}, axis=1),\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_5']].rename({'category_annotation_5': 'category'}, axis=1),\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_6']].rename({'category_annotation_6': 'category'}, axis=1),\n",
    "])\n",
    "cat_2['index'] += 90\n",
    "\n",
    "cat_2 = pd.concat([\n",
    "    cat_2,\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_1']].rename({'category_annotation_1': 'category'}, axis=1),\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_2']].rename({'category_annotation_2': 'category'}, axis=1),\n",
    "    overlap_df_2.reset_index()[['index', 'category_annotation_3']].rename({'category_annotation_3': 'category'}, axis=1),\n",
    "])\n",
    "\n",
    "cat_1 = cat_1[cat_1['category'] != '']\n",
    "cat_2 = cat_2[cat_2['category'] != '']\n",
    "\n",
    "cat_1['sup_cat'] = cat_1['category'].str.split(' - ') .apply(lambda x: x[0])\n",
    "cat_2['sup_cat'] = cat_2['category'].str.split(' - ') .apply(lambda x: x[0])\n",
    "\n",
    "cat_1.shape, cat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70d2d6-76ac-4a38-8b10-f86230d3df59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_1['iden'] = cat_1.groupby(['index', 'category', 'sup_cat']).cumcount()\n",
    "cat_2['iden'] = cat_2.groupby(['index', 'category', 'sup_cat']).cumcount()\n",
    "\n",
    "cat_1['iden_sup'] = cat_1.groupby(['index', 'sup_cat']).cumcount()\n",
    "cat_2['iden_sup'] = cat_2.groupby(['index', 'sup_cat']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880f359-f638-4556-9078-c76f325c501a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_m = cat_1.merge(cat_2, on=['index', 'category', 'sup_cat', 'iden'])\n",
    "print('Number of identical category:', cat_m.shape[0])\n",
    "\n",
    "cat_m = cat_1.merge(cat_2, on=['index', 'sup_cat', 'iden_sup'])\n",
    "print('Number of identical sup category only:', cat_m.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
