{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08dcd4-feed-4c4b-8a1f-583bff2c667e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:17:18.606850Z",
     "start_time": "2025-07-16T19:17:14.589630Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install openpyxl\n",
    "!pip install -q -U google-genai\n",
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !pip install peft\n",
    "# !pip install bitsandbytes\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97ad523-0a87-473f-bffe-36a8de336c65",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d9e8a2-86eb-4018-9e98-7dc977560f7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:17:18.606850Z",
     "start_time": "2025-07-16T19:17:14.589630Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Call models\n",
    "from src.call_models import bedrock_connect, call_claude_bedrock\n",
    "from src.call_models import google_connect, call_gemini, all_string_gemini_config, all_int_gemini_config\n",
    "from src.translate_func import claude_translation, gemini_translation\n",
    "\n",
    "# Datasets\n",
    "from prompts import mmlu_prompts\n",
    "from src.benchmarks_code import mmlu\n",
    "# Access keys\n",
    "from my_access_keys import google_access_key, aws_access_key, aws_secret_key\n",
    "\n",
    "# .csv utils\n",
    "from src.save_utils import add_dataset_to_csv\n",
    "\n",
    "# Remove annoying warning\n",
    "from IPython.core.display_functions import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1799ef79a44e3a78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:17:18.723023Z",
     "start_time": "2025-07-16T19:17:18.610604Z"
    }
   },
   "outputs": [],
   "source": [
    "bedrock_client = bedrock_connect(aws_access_key, aws_secret_key)\n",
    "google_client = google_connect(google_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f88c2-84c5-4ec8-8a0f-1ee1696b42ae",
   "metadata": {},
   "source": [
    "# Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7105ab20d2156f9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:17:36.545759Z",
     "start_time": "2025-07-16T19:17:33.556177Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14042, 4) (157, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mmlu_test': Dataset({\n",
       "     features: ['question', 'subject', 'choices', 'answer'],\n",
       "     num_rows: 14042\n",
       " })}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_dataset = mmlu.get_mmlu_datasets()\n",
    "# mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test']\n",
    "size = mmlu_dataset['mmlu_test'].num_rows\n",
    "mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test'] #.select(np.arange(0, size, 90))\n",
    "\n",
    "df_mmlu_full = pd.DataFrame(mmlu_dataset['mmlu_test'])\n",
    "df_mmlu_part = pd.DataFrame(mmlu_dataset['mmlu_test'].select(np.arange(0, size, 90)))\n",
    "df_mmlu_part.index = np.arange(0, size, 90)\n",
    "\n",
    "print(df_mmlu_full.shape, df_mmlu_part.shape)\n",
    "# display(df_mmlu_full.head(2))\n",
    "# display(df_mmlu_part.head(2))\n",
    "\n",
    "mmlu_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdbef7d-04b1-422b-85ea-70fa222c8743",
   "metadata": {},
   "source": [
    "## How much needed from each subject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107a4b37-9178-4a5c-b0c6-00b6a71213af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu_labeled = pd.read_csv('labeled_files/mmlu_test_labeled_gradio.csv')\n",
    "df_mmlu_labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b06c2b3a-4d24-4b67-9255-553baa4fd349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "electrical_engineering          20\n",
       "econometrics                    20\n",
       "high_school_computer_science    20\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "miscellaneous       13\n",
       "moral_scenarios     12\n",
       "professional_law     6\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "need_from_each = pd.Series(index=df_mmlu_full['subject'].unique(), data=20)\n",
    "\n",
    "remove = df_mmlu_part[(df_mmlu_labeled.iloc[:df_mmlu_part.shape[0]]['rating'] != 'SKIP').values]['subject'].value_counts()\n",
    "remove = remove.reindex(need_from_each.index, fill_value=0)\n",
    "need_from_each -= remove\n",
    "need_from_each = need_from_each.sort_values(ascending=False)\n",
    "display(need_from_each.head(3))\n",
    "print()\n",
    "display(need_from_each.tail(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d5e5ca-21b7-423f-8c29-80a66a1ed664",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_subjects = [\n",
    "    \"professional_psychology\",\n",
    "    \"high_school_psychology\",\n",
    "    \"high_school_macroeconomics\",\n",
    "    \"elementary_mathematics\",\n",
    "    \"prehistory\",\n",
    "    \"philosophy\",\n",
    "    \"high_school_biology\",\n",
    "    \"nutrition\",\n",
    "    \"professional_accounting\",\n",
    "    \"professional_medicine\",\n",
    "    \"high_school_mathematics\",\n",
    "    \"clinical_knowledge\",\n",
    "    \"security_studies\",\n",
    "    \"high_school_microeconomics\",\n",
    "    \"high_school_world_history\",\n",
    "    \"conceptual_physics\",\n",
    "    \"marketing\",\n",
    "    \"human_aging\",\n",
    "    \"high_school_statistics\",\n",
    "    \"high_school_chemistry\",\n",
    "    \"sociology\",\n",
    "    \"high_school_geography\",\n",
    "    \"college_medicine\",\n",
    "    \"world_religions\",\n",
    "    \"virology\",\n",
    "    \"high_school_european_history\",\n",
    "    \"logical_fallacies\",\n",
    "    \"astronomy\",\n",
    "    \"high_school_physics\",\n",
    "    \"electrical_engineering\",\n",
    "    \"college_biology\",\n",
    "    \"anatomy\",\n",
    "    \"human_sexuality\",\n",
    "    \"formal_logic\",\n",
    "    \"international_law\",\n",
    "    \"econometrics\",\n",
    "    \"machine_learning\",\n",
    "    \"public_relations\",\n",
    "    \"management\",\n",
    "    \"college_physics\",\n",
    "    \"college_computer_science\",\n",
    "    \"college_mathematics\",\n",
    "    \"global_facts\",\n",
    "    \"high_school_computer_science\",\n",
    "    \"computer_security\",\n",
    "    \"abstract_algebra\",\n",
    "    \"business_ethics\",\n",
    "    \"college_chemistry\",\n",
    "    \"medical_genetics\",\n",
    "]\n",
    "\n",
    "side_subjects = [\n",
    "    \"professional_law\",\n",
    "    \"moral_scenarios\",\n",
    "    \"miscellaneous\",\n",
    "    \"moral_disputes\",\n",
    "    \"high_school_us_history\",\n",
    "    \"high_school_government_and_politics\",\n",
    "    \"jurisprudence\",\n",
    "    \"us_foreign_policy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd43c7c4-1864-4aa6-ad62-119fa8cf33b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(892, 124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "need_from_each[need_from_each.index.isin(use_subjects)].sum(), need_from_each[need_from_each.index.isin(side_subjects)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da128cf3-a836-4f91-9774-9dccc9018f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13885, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mmlu_full = df_mmlu_full[~df_mmlu_full.index.isin(df_mmlu_part.index)]\n",
    "df_mmlu_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb216500-2073-487b-a5ea-5b08edfb4770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "(164, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mmlu_test': Dataset({\n",
       "     features: ['question', 'subject', 'choices', 'answer'],\n",
       "     num_rows: 164\n",
       " })}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "needed_use_only = need_from_each[need_from_each.index.isin(side_subjects)]\n",
    "print(needed_use_only.shape)\n",
    "\n",
    "df_mmlu_full['subject_cnt'] = df_mmlu_full.groupby('subject').cumcount()\n",
    "take_indices = df_mmlu_full[df_mmlu_full['subject'].isin(side_subjects)]\n",
    "# take_indices = take_indices[take_indices.apply(lambda x: x['subject_cnt'] < 4, axis=1)]\n",
    "take_indices = take_indices[take_indices.apply(lambda x: x['subject_cnt'] < needed_use_only.loc[x['subject']] + 5, axis=1)]\n",
    "print(take_indices.shape)\n",
    "mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test'].select(take_indices.index)\n",
    "mmlu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a9bbd44-702c-4d49-8b9a-834e975dc92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject\n",
       "high_school_us_history                 25\n",
       "high_school_government_and_politics    24\n",
       "us_foreign_policy                      24\n",
       "jurisprudence                          23\n",
       "moral_disputes                         22\n",
       "miscellaneous                          18\n",
       "moral_scenarios                        17\n",
       "professional_law                       11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take_indices['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff2f51d-c2cf-4e5d-973b-fed3436e38b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(mmlu_dataset['mmlu_test'])['subject'].value_counts().sort_index() == needed_use_only.sort_index()).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763f1fc-51c7-4c0a-a6d3-c77a24760853",
   "metadata": {},
   "source": [
    "## Create save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8117c3ed-6eb9-45bb-aa1a-fdbcae9fbd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmlu_test': Dataset({\n",
       "     features: ['question', 'subject', 'choices', 'answer'],\n",
       "     num_rows: 164\n",
       " })}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0d10f92-660c-4093-b3a2-71dfb13a5169",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test']\n",
    "mmlu_file_name = 'compare_csv/mmlu/mmlu_test_prob_sub.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8dd7cde-20af-4f79-9395-c95eb27e013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cec59125-f0a1-4932-aa8c-185cc457bf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 162\n",
       "})"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmlu_dataset['mmlu_test'] = mmlu_dataset['mmlu_test'].select(list(range(24)) + list(range(25, 61)) + list(range(62, 164)))\n",
    "mmlu_dataset['mmlu_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28bfe589-5ed8-4965-8f10-38807b73f569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:17:36.744293Z",
     "start_time": "2025-07-16T19:17:36.716874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Which of the following best describe...\n",
       "1  <question>Which of the following statements do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Which of the following best describe...\n",
       "1  <question>Which of the following statements do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(mmlu_file_name, 'original', mmlu_dataset['mmlu_test'], mmlu.mmlu_sample_to_dict)\n",
    "text_df = add_dataset_to_csv(mmlu_file_name[:-4] + '-text.csv', 'original', mmlu_dataset['mmlu_test'], mmlu.mmlu_sample_to_dict)\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10f4181f-dfb8-452c-9c6a-ed76d70959bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Which of the following best describe...\n",
       "1  <question>Which of the following statements do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Which of the following best describe...\n",
       "1  <question>Which of the following statements do..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(mmlu_file_name)\n",
    "text_df = pd.read_csv(mmlu_file_name[:-4] + '-text.csv')\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "125551c5-9d6e-48f8-807b-a48706d62217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((162, 1), (162, 1))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ee915a-f8d9-475e-9fcb-bba47d33773c",
   "metadata": {},
   "source": [
    "# Run Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df110022-6596-4b41-a0b6-caa707af1e6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Claude"
   ]
  },
  {
   "cell_type": "raw",
   "id": "315da4fa-6e8b-45f0-9cb8-80b89ea03ee6",
   "metadata": {},
   "source": [
    "small = {}\n",
    "small['mmlu_test'] = mmlu_dataset['mmlu_test'].skip(124).take(1)\n",
    "small"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d613ded-a120-4320-bb08-fded5e7a97ec",
   "metadata": {},
   "source": [
    "!ls checkpoints/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c73a993-5a08-4be4-bb0f-bdc80587ba9a",
   "metadata": {},
   "source": [
    "!cp checkpoints/claude_mmlu_val_25.pkl checkpoints/save_101_125.pkl\n",
    "!cp checkpoints/claude_mmlu_val_25_text.pkl checkpoints/save_101_125_text.pkl"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c8e74a3-53bf-424a-884a-4c67dbe186e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:25:53.909676Z",
     "start_time": "2025-07-16T19:17:37.997012Z"
    }
   },
   "source": [
    "exp_name = 'claude_v1_refine'\n",
    "\n",
    "hebrew_datasets, text_output = claude_translation(\n",
    "    bedrock_client,\n",
    "    mmlu_dataset,\n",
    "    # small,\n",
    "    mmlu_prompts.MMLU_INSTRUCT_V1_CLAUDE_REFINE,\n",
    "    mmlu_prompts.MMLU_FEW_SHOTS,\n",
    "    mmlu_prompts.MMLU_FORMAT_REFINE,\n",
    "    mmlu.mmlu_sample_to_dict,\n",
    "    mmlu.mmlu_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3d67b4c-5f90-46b2-b931-786f5568f9c1",
   "metadata": {},
   "source": [
    "import pickle\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "with open('checkpoints/save_100.pkl', 'rb') as f:\n",
    "    lst_1 = pickle.load(f)\n",
    "with open('checkpoints/save_100_text.pkl', 'rb') as f:\n",
    "    lst_1_text = pickle.load(f)\n",
    "\n",
    "with open('checkpoints/save_101_125.pkl', 'rb') as f:\n",
    "    lst_2 = pickle.load(f)\n",
    "with open('checkpoints/save_101_125_text.pkl', 'rb') as f:\n",
    "    lst_2_text = pickle.load(f)\n",
    "len(lst_1), len(lst_1_text), len(lst_2), len(lst_2_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec40f4c5-b7e8-4ef9-8e4e-fde83b14c5c4",
   "metadata": {},
   "source": [
    "lst_1 = Dataset.from_list(lst_1)\n",
    "lst_2 = Dataset.from_list(lst_2)\n",
    "\n",
    "hebrew_datasets['mmlu_val'] = concatenate_datasets([lst_1, lst_2, hebrew_datasets['mmlu_val']])\n",
    "text_output['mmlu_val'] = lst_1_text + lst_2_text + text_output['mmlu_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969686b8-a09a-4825-a363-9937b44dd09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating mmlu_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9e2f0900564a5692c2697d27a237e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 161 ms, total: 1.27 s\n",
      "Wall time: 41min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# exp_name = 'claude_3-7_v7_thinking'\n",
    "exp_name = 'claude_thinking_v2'\n",
    "\n",
    "hebrew_datasets, text_output = claude_translation(\n",
    "    bedrock_client,\n",
    "    mmlu_dataset,\n",
    "    # small,\n",
    "    mmlu_prompts.MMLU_INSTRUCT_CLAUDE_V2,\n",
    "    mmlu_prompts.MMLU_FEW_SHOTS,\n",
    "    mmlu_prompts.MMLU_FORMAT,\n",
    "    mmlu.mmlu_sample_to_dict,\n",
    "    mmlu.mmlu_dict_to_sample,\n",
    "    if_four=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f649181e-c6b9-493b-8cf5-95c4075e8db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_mat(text):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ac5f71-5d3e-40da-9824-c2948f389ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     129\n",
       "5      24\n",
       "10      2\n",
       "15      1\n",
       "11      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pd.Series([len_mat(i) for i in text_output['mmlu_test']]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95494a7d-48e3-4217-88bc-1a074700b58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    132\n",
       "5     25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([len_mat(i.split('Text:')[-1]) for i in text_output['mmlu_test']]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa76e610-99c5-4cae-be4e-0f1148aea0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking:\n",
      "I need to translate this astronomy multiple-choice question about Jupiter's magnetic field from English to Hebrew. Let's break down the key terms and translate them accurately:\n",
      "\n",
      "1. \"Jupiter's magnetic field\" - \"השדה המגנטי של צדק\"\n",
      "2. \"20000 times stronger\" - \"חזק פי 20000\"\n",
      "3. \"Earth's magnetic field\" - \"השדה המגנטי של כדור הארץ\"\n",
      "4. \"traps charged particles\" - \"לוכד חלקיקים טעונים\"\n",
      "5. \"Io's volcanoes\" - \"הרי הגעש של איו\" (Io is one of Jupiter's moons)\n",
      "6. \"plasma torus\" - \"טורוס פלזמה\" (scientific term that would likely be used as-is in Hebrew with Hebrew pronunciation)\n",
      "7. \"auroral displays\" - \"מופעי זוהר\" or \"תצוגות זוהר קוטבי\"\n",
      "8. \"north and south poles\" - \"הקטבים הצפוני והדרומי\"\n",
      "9. \"switches polarity\" - \"מחליף קוטביות\"\n",
      "10. \"every 11 years\" - \"כל 11 שנים\"\n",
      "\n",
      "This is a universal subject (astronomy/planetary science), so I will perform a direct translation without needing to adapt to an Israeli context.\n",
      "\n",
      "Now for the full translation:\n",
      "\n",
      "Question: \"מה אינו נכון לגבי השדה המגנטי של צדק?\"\n",
      "\n",
      "Option A: \"הוא חזק פי 20000 בערך מהשדה המגנטי של כדור הארץ\"\n",
      "Option B: \"הוא לוכד חלקיקים טעונים מהרי הגעש של איו ב'טורוס פלזמה' סביב כוכב הלכת\"\n",
      "Option C: \"הוא גורם לתצוגות זוהר קוטבי מרהיבות בקטבים הצפוני והדרומי של צדק\"\n",
      "Option D: \"הוא מחליף קוטביות כל 11 שנים\"\n",
      "\n",
      "Text:\n",
      "<subject>אסטרונומיה</subject>\n",
      "<question>מה אינו נכון לגבי השדה המגנטי של צדק?</question>\n",
      "<choice_a>הוא חזק פי 20000 בערך מהשדה המגנטי של כדור הארץ</choice_a>\n",
      "<choice_b>הוא לוכד חלקיקים טעונים מהרי הגעש של איו ב\"טורוס פלזמה\" סביב כוכב הלכת</choice_b>\n",
      "<choice_c>הוא גורם לתצוגות זוהר קוטבי מרהיבות בקטבים הצפוני והדרומי של צדק</choice_c>\n",
      "<choice_d>הוא מחליף קוטביות כל 11 שנים</choice_d>\n"
     ]
    }
   ],
   "source": [
    "print(text_output['mmlu_test'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "246fb0d3-174b-405e-9834-abee47031a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:26:03.776119Z",
     "start_time": "2025-07-16T19:26:03.750308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_thinking_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Find the degree for the given field ...</td>\n",
       "      <td>&lt;question&gt;מצאו את המעלה עבור הרחבת השדה הנתונה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Statement 1 | If a finite group has ...</td>\n",
       "      <td>&lt;question&gt;היגד 1 | אם חבורה סופית היא מסדר n א...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Find the degree for the given field ...   \n",
       "1  <question>Statement 1 | If a finite group has ...   \n",
       "\n",
       "                                  claude_thinking_v2  \n",
       "0  <question>מצאו את המעלה עבור הרחבת השדה הנתונה...  \n",
       "1  <question>היגד 1 | אם חבורה סופית היא מסדר n א...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(mmlu_file_name, exp_name, hebrew_datasets['mmlu_test'], mmlu.mmlu_sample_to_dict)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da014da9-a2ed-4f77-832e-f7872b9b264e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_thinking_v2 text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Find the degree for the given field ...</td>\n",
       "      <td>Thinking:\\nI need to translate the given Engli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Statement 1 | If a finite group has ...</td>\n",
       "      <td>Thinking:\\nI need to translate the given abstr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Find the degree for the given field ...   \n",
       "1  <question>Statement 1 | If a finite group has ...   \n",
       "\n",
       "                             claude_thinking_v2 text  \n",
       "0  Thinking:\\nI need to translate the given Engli...  \n",
       "1  Thinking:\\nI need to translate the given abstr...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[exp_name + ' text'] = text_output['mmlu_test']\n",
    "text_df.to_csv(mmlu_file_name[:-4] + '-text.csv', index=False)\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbff7eac-2262-4ad8-a8e0-f7a4347ea66f",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd00f990-0b07-4458-9d2f-7a666bc61047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmlu_test': Dataset({\n",
       "     features: ['question', 'subject', 'choices', 'answer'],\n",
       "     num_rows: 102\n",
       " })}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jumped over 24? and 61?\n",
    "small = {}\n",
    "small['mmlu_test'] = mmlu_dataset['mmlu_test'].select(list(range(62, mmlu_dataset['mmlu_test'].num_rows)))\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "135fb749-60b1-451c-8e76-31be1d0c9ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:36:12.646277Z",
     "start_time": "2025-07-16T19:26:11.778501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating mmlu_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9623cbf1854744a62fd08818cb73fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|-|"
     ]
    }
   ],
   "source": [
    "exp_name = 'gemini'\n",
    "\n",
    "hebrew_datasets, text_output = gemini_translation(\n",
    "    google_client,\n",
    "    # mmlu_dataset,\n",
    "    small,\n",
    "    mmlu_prompts.MMLU_INSTRUCT_V1_GEMINI,\n",
    "    mmlu_prompts.MMLU_FEW_SHOTS,\n",
    "    mmlu.mmlu_sample_to_dict,\n",
    "    mmlu.mmlu_dict_to_sample,\n",
    "    if_pro=True,\n",
    "    think_bud=4_096,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38861594-faea-4a4a-9ced-b0621f3061bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mmlu_test': Dataset({\n",
       "     features: ['question', 'subject', 'choices', 'answer', 'translation_status'],\n",
       "     num_rows: 102\n",
       " })}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebrew_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "939daaaf-8dca-45d1-af8d-d27d614ae70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 60)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "\n",
    "with open('gemini_cp/ck1 - gemini_mmlu_test_15.pkl', 'rb') as f:\n",
    "    lst_1 = pickle.load(f)\n",
    "with open('gemini_cp/ck1 - gemini_mmlu_test_15_text.pkl', 'rb') as f:\n",
    "    lst_1_text = pickle.load(f)\n",
    "\n",
    "with open('gemini_cp/ck2 - gemini_mmlu_test_45.pkl', 'rb') as f:\n",
    "    lst_1 += pickle.load(f)\n",
    "with open('gemini_cp/ck2 - gemini_mmlu_test_45_text.pkl', 'rb') as f:\n",
    "    lst_1_text += pickle.load(f)\n",
    "\n",
    "len(lst_1), len(lst_1_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8de18d6-6fdb-4769-8866-d7851966ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = Dataset.from_list(lst_1)\n",
    "\n",
    "hebrew_datasets['mmlu_test_fixed'] = concatenate_datasets([lst_1, hebrew_datasets['mmlu_test']])\n",
    "text_output['mmlu_test_fixed'] = lst_1_text + text_output['mmlu_test']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c864e3c-6d2e-4404-96f8-f6bc1589d757",
   "metadata": {},
   "source": [
    "hebrew_datasets['mmlu_test_fixed'] = hebrew_datasets['mmlu_test']\n",
    "text_output['mmlu_test_fixed'] = text_output['mmlu_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa1cb985-9ac0-46b3-a581-db00b345731b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer', 'translation_status'],\n",
       "    num_rows: 162\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebrew_datasets['mmlu_test_fixed']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "id": "1c03ce45-1455-49b8-b341-903f170b69b8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from src.translate_func import dict_to_prompt\n",
    "\n",
    "for i in range(32):\n",
    "    print('Example', i, mmlu_dataset['mmlu_test'][i]['subject'])\n",
    "    print()\n",
    "    print('English:')\n",
    "    print(dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_dataset['mmlu_test'][i])))\n",
    "    print()\n",
    "    print('Hebrew:')\n",
    "    print(dict_to_prompt(mmlu.mmlu_sample_to_dict(hebrew_datasets['mmlu_test'][i])))\n",
    "    print()\n",
    "    print('-' * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6abd9f54-8e78-48e4-870a-bb0940f7d316",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i in range(0, 199, 20):\n",
    "    print(i)\n",
    "    display(mmlu_dataset['mmlu_test'][i])\n",
    "    display(hebrew_datasets['mmlu_test_fixed'][i])\n",
    "    print()\n",
    "    print('-' * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "755c5dca-06fe-4657-8963-3456238b0ca2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-16T19:26:03.776119Z",
     "start_time": "2025-07-16T19:26:03.750308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gemini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "      <td>&lt;question&gt;איזו מהאפשרויות הבאות מתארת בצורה הט...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "      <td>&lt;question&gt;איזו מהטענות הבאות אינה מתארת נכונה ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which of the following best describe...   \n",
       "1  <question>Which of the following statements do...   \n",
       "\n",
       "                                              gemini  \n",
       "0  <question>איזו מהאפשרויות הבאות מתארת בצורה הט...  \n",
       "1  <question>איזו מהטענות הבאות אינה מתארת נכונה ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gemini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>&lt;question&gt;The dominant course for foreign poli...</td>\n",
       "      <td>&lt;question&gt;התפיסה האסטרטגית, שהייתה בעלת השפעה ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>&lt;question&gt;What led Britain to impose new taxes...</td>\n",
       "      <td>&lt;question&gt;מה הייתה סיבה מרכזית להטלת מיסים על ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original  \\\n",
       "160  <question>The dominant course for foreign poli...   \n",
       "161  <question>What led Britain to impose new taxes...   \n",
       "\n",
       "                                                gemini  \n",
       "160  <question>התפיסה האסטרטגית, שהייתה בעלת השפעה ...  \n",
       "161  <question>מה הייתה סיבה מרכזית להטלת מיסים על ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gemini text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "      <td>**Analysis of a Translation Task: US Constitut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "      <td>**Okay, let's break down this task, step by st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which of the following best describe...   \n",
       "1  <question>Which of the following statements do...   \n",
       "\n",
       "                                         gemini text  \n",
       "0  **Analysis of a Translation Task: US Constitut...  \n",
       "1  **Okay, let's break down this task, step by st...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(mmlu_file_name, exp_name, hebrew_datasets['mmlu_test_fixed'], mmlu.mmlu_sample_to_dict)\n",
    "text_df[exp_name + ' text'] = text_output['mmlu_test_fixed']\n",
    "text_df.to_csv(mmlu_file_name[:-4] + '-text.csv', index=False)\n",
    "display(df.head(2))\n",
    "display(df.tail(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "00e7b917-e812-4fbe-acd0-0281d7383868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "df['answer_label'] = pd.Series(hebrew_datasets['mmlu_test_fixed']['answer'])\n",
    "df['subject'] = pd.Series(hebrew_datasets['mmlu_test_fixed']['subject'])\n",
    "print((df['answer_label'] == pd.Series(hebrew_datasets['mmlu_test_fixed']['answer'])).all())\n",
    "df.to_csv(mmlu_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e9332cc5-e2b0-4242-aab0-e8f354623539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gemini</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which of the following best describe...</td>\n",
       "      <td>&lt;question&gt;איזו מהאפשרויות הבאות מתארת בצורה הט...</td>\n",
       "      <td>ד</td>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which of the following statements do...</td>\n",
       "      <td>&lt;question&gt;איזו מהטענות הבאות אינה מתארת נכונה ...</td>\n",
       "      <td>ב</td>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;question&gt;Which of the following plays the mos...</td>\n",
       "      <td>&lt;question&gt;לאיזה מהבאים יש את התפקיד המשמעותי ב...</td>\n",
       "      <td>ב</td>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;question&gt;What power was granted to the states...</td>\n",
       "      <td>&lt;question&gt;איזו מהסמכויות הבאות, שהוחזקה על ידי...</td>\n",
       "      <td>א</td>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;question&gt;The primary function of political ac...</td>\n",
       "      <td>&lt;question&gt;תפקידן העיקרי של ועדות פעולה פוליטיו...</td>\n",
       "      <td>א</td>\n",
       "      <td>high_school_government_and_politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which of the following best describe...   \n",
       "1  <question>Which of the following statements do...   \n",
       "2  <question>Which of the following plays the mos...   \n",
       "3  <question>What power was granted to the states...   \n",
       "4  <question>The primary function of political ac...   \n",
       "\n",
       "                                              gemini answer_label  \\\n",
       "0  <question>איזו מהאפשרויות הבאות מתארת בצורה הט...            ד   \n",
       "1  <question>איזו מהטענות הבאות אינה מתארת נכונה ...            ב   \n",
       "2  <question>לאיזה מהבאים יש את התפקיד המשמעותי ב...            ב   \n",
       "3  <question>איזו מהסמכויות הבאות, שהוחזקה על ידי...            א   \n",
       "4  <question>תפקידן העיקרי של ועדות פעולה פוליטיו...            א   \n",
       "\n",
       "                               subject  \n",
       "0  high_school_government_and_politics  \n",
       "1  high_school_government_and_politics  \n",
       "2  high_school_government_and_politics  \n",
       "3  high_school_government_and_politics  \n",
       "4  high_school_government_and_politics  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f9a81b8c-7b8e-4264-a777-5649c7fb7de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>gemini</th>\n",
       "      <th>answer_label</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>&lt;question&gt;Why do Liberal Internationalists arg...</td>\n",
       "      <td>&lt;question&gt;מדוע ליברלים אינטרנציונליסטים טוענים...</td>\n",
       "      <td>ב</td>\n",
       "      <td>us_foreign_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>&lt;question&gt;What was the significance of the Tru...</td>\n",
       "      <td>&lt;question&gt;מה הייתה משמעותה של דוקטרינת טרומן?&lt;...</td>\n",
       "      <td>ד</td>\n",
       "      <td>us_foreign_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>&lt;question&gt;What tend to be the effects of oil a...</td>\n",
       "      <td>&lt;question&gt;מהן ההשפעות של סחר בנפט ובמשאבי טבע ...</td>\n",
       "      <td>ג</td>\n",
       "      <td>us_foreign_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>&lt;question&gt;The dominant course for foreign poli...</td>\n",
       "      <td>&lt;question&gt;התפיסה האסטרטגית, שהייתה בעלת השפעה ...</td>\n",
       "      <td>ג</td>\n",
       "      <td>us_foreign_policy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>&lt;question&gt;What led Britain to impose new taxes...</td>\n",
       "      <td>&lt;question&gt;מה הייתה סיבה מרכזית להטלת מיסים על ...</td>\n",
       "      <td>ב</td>\n",
       "      <td>us_foreign_policy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              original  \\\n",
       "157  <question>Why do Liberal Internationalists arg...   \n",
       "158  <question>What was the significance of the Tru...   \n",
       "159  <question>What tend to be the effects of oil a...   \n",
       "160  <question>The dominant course for foreign poli...   \n",
       "161  <question>What led Britain to impose new taxes...   \n",
       "\n",
       "                                                gemini answer_label  \\\n",
       "157  <question>מדוע ליברלים אינטרנציונליסטים טוענים...            ב   \n",
       "158  <question>מה הייתה משמעותה של דוקטרינת טרומן?<...            ד   \n",
       "159  <question>מהן ההשפעות של סחר בנפט ובמשאבי טבע ...            ג   \n",
       "160  <question>התפיסה האסטרטגית, שהייתה בעלת השפעה ...            ג   \n",
       "161  <question>מה הייתה סיבה מרכזית להטלת מיסים על ...            ב   \n",
       "\n",
       "               subject  \n",
       "157  us_foreign_policy  \n",
       "158  us_foreign_policy  \n",
       "159  us_foreign_policy  \n",
       "160  us_foreign_policy  \n",
       "161  us_foreign_policy  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
