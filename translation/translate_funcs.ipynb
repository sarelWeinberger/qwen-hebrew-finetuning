{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de8480e5-c3d0-40b2-884c-66c86a21dfde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:44:18.247473Z",
     "start_time": "2025-07-14T07:44:07.313929Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.33.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading huggingface_hub-0.33.4-py3-none-any.whl (515 kB)\n",
      "Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m167.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, propcache, multidict, hf-xet, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[2K  Attempting uninstall: dill\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.0━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/15\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: multiprocess0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m 6/15\u001b[0m [dill]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [datasets]/15\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.14 aiosignal-1.4.0 async-timeout-5.0.1 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 hf-xet-1.1.5 huggingface-hub-0.33.4 multidict-6.6.3 multiprocess-0.70.16 propcache-0.3.2 xxhash-3.5.0 yarl-1.20.1\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [openpyxl]1/2\u001b[0m [openpyxl]\n",
      "\u001b[1A\u001b[2KSuccessfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install openpyxl\n",
    "!pip install -q -U google-genai\n",
    "# !pip install transformers\n",
    "# !pip install accelerate\n",
    "# !pip install peft\n",
    "# !pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52ac5aa-eb0a-4ae5-b8de-a5d2a6fbc453",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5c1afb-bf91-456d-aecd-63dbe731d117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:45:18.857392Z",
     "start_time": "2025-07-14T07:45:18.835995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# Call models\n",
    "from src.call_models import bedrock_connect, call_claude_bedrock\n",
    "from src.call_models import google_connect, call_gemini, all_string_gemini_config, all_int_gemini_config\n",
    "from src.translate_func import claude_translation, gemini_translation\n",
    "\n",
    "# Datasets\n",
    "from src.benchmarks_code import arc_ai\n",
    "from src.benchmarks_code import gsm8k\n",
    "from prompts import arc_prompts\n",
    "from prompts import gsm_prompts\n",
    "#from prompts import hellaswag_prompts\n",
    "\n",
    "# Access keys\n",
    "from my_access_keys import google_access_key, aws_access_key, aws_secret_key\n",
    "\n",
    "# .csv utils\n",
    "from src.save_utils import add_dataset_to_csv\n",
    "\n",
    "# Remove annoying warning\n",
    "from IPython.core.display_functions import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23027f8a-2c23-4dfb-96ec-8bfe768ec35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_access_keys import google_project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4c23e3-3705-4090-b599-f06d7bef152e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:45:20.897912Z",
     "start_time": "2025-07-14T07:45:20.537138Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the model's access keys\n",
    "bedrock_client = bedrock_connect(aws_access_key, aws_secret_key)\n",
    "google_client = google_connect(google_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d558c746-5323-449a-9715-0787c26e8144",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Check Models Calls"
   ]
  },
  {
   "cell_type": "raw",
   "id": "befff497-7ce7-4b96-b8d9-9a9a8f1e0f40",
   "metadata": {},
   "source": [
    "print('claude:')\n",
    "print(call_claude_bedrock(\n",
    "    bedrock_client,\n",
    "    'Which one is more accurate in Hebrew? repeat the right sentence, without adding anything\\nכדור הארץ מסתובב על צירו OR כדור הארץ מסתובב סביב צירו',\n",
    "    system_prompt='ALWAYS start and end your answers with \"*\"',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81c5d593-94d8-4c77-9edd-f2d88f54bb8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:45:29.155206Z",
     "start_time": "2025-07-14T07:45:26.180645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini:\n",
      "{\"recipe\": \"Classic Chocolate Chip Cookies\", \"ingredients\": \"1 cup (2 sticks) unsalted butter, softened; 3/4 cup granulated sugar; 3/4 cup packed light brown sugar; 2 large eggs; 1 teaspoon vanilla extract; 2 1/4 cups all-purpose flour; 1 teaspoon baking soda; 1/2 teaspoon salt; 12 ounces chocolate chips (semi-sweet or milk chocolate)\"}\n",
      "---\n",
      "dict_keys(['recipe', 'ingredients'])\n"
     ]
    }
   ],
   "source": [
    "print('Gemini:')\n",
    "generate_content_config = all_string_gemini_config(['recipe', 'ingredients'], 'ALWAYS THINK BEFORE ANSWERING!', think_bud=200)\n",
    "response = call_gemini(google_client, \"List a popular cookie recipe, and include the amounts of ingredients.\", generate_content_config)\n",
    "print(response.text)\n",
    "print('---')\n",
    "my_recipes = response.parsed\n",
    "print(my_recipes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b7c3-0fe6-4d38-9f14-11dbc22c4407",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ARC_AI2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f8b0ca-de73-46c6-908d-35f288bb3c16",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1f8efc-d4cb-4b6e-b88c-7b3ef27d2f4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T07:45:56.319299Z",
     "start_time": "2025-07-14T07:45:39.967771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_csv/arc_ai2_chall_train_top_100_for_comparison.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'arc_challenge_train': Dataset({\n",
       "     features: ['id', 'question', 'choices', 'answerKey'],\n",
       "     num_rows: 90\n",
       " })}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arc_dataset = arc_ai.get_arc_ai2_datasets()\n",
    "arc_dataset['arc_challenge_train'] = arc_dataset['arc_challenge_train'].skip(5).take(90)\n",
    "file_name = 'compare_csv/arc_ai2_chall_train_top_100_for_comparison.csv'\n",
    "\n",
    "print(file_name)\n",
    "arc_dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cca0b8a-1659-42dd-8ccb-3155787326e7",
   "metadata": {},
   "source": [
    "df = add_dataset_to_csv(file_name, 'original', arc_dataset['arc_challenge_train'], arc_ai.arc_sample_to_dict)\n",
    "text_df = add_dataset_to_csv(file_name[:-4] + '-text.csv', 'original', arc_dataset['arc_challenge_train'], arc_ai.arc_sample_to_dict)\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "455857a2-45ec-4121-9d95-89217136fd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>&lt;question&gt;איזו צורת נוף היא תוצאה של הכוח הבונ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>&lt;question&gt;איזה משפט משווה בצורה הטובה ביותר בי...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                                    claude_v2_refine  \n",
       "0  <question>איזו צורת נוף היא תוצאה של הכוח הבונ...  \n",
       "1  <question>איזה משפט משווה בצורה הטובה ביותר בי...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו צורת קרקע ה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו אמירה משווה...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                               claude_v2_refine text  \n",
       "0  First translation:\\n<question>איזו צורת קרקע ה...  \n",
       "1  First translation:\\n<question>איזו אמירה משווה...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(file_name)\n",
    "text_df = pd.read_csv(file_name[:-4] + '-text.csv')\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0110eefb-aab4-451d-b273-b0d5a554c91f",
   "metadata": {},
   "source": [
    "## Run Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f09840-3fa3-4124-8feb-a52d8cb213f9",
   "metadata": {},
   "source": [
    "### Claude"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d9179d4-749f-435f-be77-912ce48c7712",
   "metadata": {},
   "source": [
    "exp_name = 'claude_v6_system_prompt'\n",
    "\n",
    "hebrew_datasets = claude_translation(\n",
    "    bedrock_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_V6_CLAUDE,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_prompts.ARC_FORMAT,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11b230d6-5403-4d5a-9616-7e2c9536b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674dd432f5b54e53a735b8a3832823ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = 'claude_v2_refine'\n",
    "\n",
    "hebrew_datasets, text_output = claude_translation(\n",
    "    bedrock_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_V2_CLAUDE_REFINE,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_prompts.ARC_FORMAT,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e72a24-55f5-4bbd-8ad6-6775c0e592a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>&lt;question&gt;איזו צורת נוף היא תוצאה של הכוח הבונ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>&lt;question&gt;איזה משפט משווה בצורה הטובה ביותר בי...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                                    claude_v2_refine  \n",
       "0  <question>איזו צורת נוף היא תוצאה של הכוח הבונ...  \n",
       "1  <question>איזה משפט משווה בצורה הטובה ביותר בי...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו צורת קרקע ה...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו אמירה משווה...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                               claude_v2_refine text  \n",
       "0  First translation:\\n<question>איזו צורת קרקע ה...  \n",
       "1  First translation:\\n<question>איזו אמירה משווה...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(file_name, exp_name, hebrew_datasets['arc_challenge_train'], arc_ai.arc_sample_to_dict)\n",
    "text_df[exp_name + ' text'] = text_output['arc_challenge_train']\n",
    "text_df.to_csv(file_name[:-4] + '-text.csv', index=False)\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a501e-f0e0-4897-a3d2-f922f52d9719",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d01fc077-f79e-48e6-aa76-86872d0350f3",
   "metadata": {},
   "source": [
    "small = {}\n",
    "small['check'] = arc_dataset['arc_challenge_train'].take(2)\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c7138f8-5877-491e-b656-828508414445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating arc_challenge_train...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797c8bd4c37347c0b3ab145d772becab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping in the While.... Done!                   "
     ]
    }
   ],
   "source": [
    "exp_name = 'gemini_pro_think_v2'\n",
    "\n",
    "hebrew_datasets, text_output = gemini_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    # small,\n",
    "    arc_prompts.ARC_INSTRUCT_V2_GEMINI,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    "    if_pro=True,\n",
    "    # if_pro=False,\n",
    "    think_bud=20_000\n",
    "    # think_bud=2_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "75c38d8d-1ce5-48d7-83a5-7ba547572dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arc_challenge_train': Dataset({\n",
       "     features: ['id', 'question', 'choices', 'answerKey', 'translation_status'],\n",
       "     num_rows: 90\n",
       " })}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hebrew_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd92c3ba-325c-458b-9fbe-5c6bc87282e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine</th>\n",
       "      <th>gemini_pro_think_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>&lt;question&gt;איזו צורת נוף היא תוצאה של הכוח הבונ...</td>\n",
       "      <td>&lt;question&gt;איזו תצורת נוף היא תוצאה של הכוח הבו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>&lt;question&gt;איזה משפט משווה בצורה הטובה ביותר בי...</td>\n",
       "      <td>&lt;question&gt;איזה משפט משווה בצורה הטובה ביותר בי...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                                    claude_v2_refine  \\\n",
       "0  <question>איזו צורת נוף היא תוצאה של הכוח הבונ...   \n",
       "1  <question>איזה משפט משווה בצורה הטובה ביותר בי...   \n",
       "\n",
       "                                 gemini_pro_think_v2  \n",
       "0  <question>איזו תצורת נוף היא תוצאה של הכוח הבו...  \n",
       "1  <question>איזה משפט משווה בצורה הטובה ביותר בי...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine text</th>\n",
       "      <th>gemini_pro_think_v2 text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Which land form is the result of the...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו צורת קרקע ה...</td>\n",
       "      <td>**Hebrew Translation of a Glacial Geology Ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;Which statement best compares single...</td>\n",
       "      <td>First translation:\\n&lt;question&gt;איזו אמירה משווה...</td>\n",
       "      <td>**Thought Process: Translating a Science Quest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Which land form is the result of the...   \n",
       "1  <question>Which statement best compares single...   \n",
       "\n",
       "                               claude_v2_refine text  \\\n",
       "0  First translation:\\n<question>איזו צורת קרקע ה...   \n",
       "1  First translation:\\n<question>איזו אמירה משווה...   \n",
       "\n",
       "                            gemini_pro_think_v2 text  \n",
       "0  **Hebrew Translation of a Glacial Geology Ques...  \n",
       "1  **Thought Process: Translating a Science Quest...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(file_name, exp_name, hebrew_datasets['arc_challenge_train'], arc_ai.arc_sample_to_dict)\n",
    "text_df[exp_name + ' text'] = text_output['arc_challenge_train']\n",
    "text_df.to_csv(file_name[:-4] + '-text.csv', index=False)\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e175a518-d5d5-4995-9086-b2ae542f5639",
   "metadata": {},
   "source": [
    "exp_name = 'gemini_v1_few_options'\n",
    "\n",
    "hebrew_datasets = gemini_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_V1_GEMINI_MULTI,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    "    if_pro=False,\n",
    "    think_bud=20_000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1691522-c65b-44ef-9bd4-3a8eefa04c3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multi-options Translation - Gemini"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f9b6a17-318b-42ee-ab40-5cc3b9fee748",
   "metadata": {},
   "source": [
    "print(arc_prompts.ARC_INSTRUCT_MULTI_V1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6731727d-c775-4ce5-95c2-ec7d2b90dd03",
   "metadata": {},
   "source": [
    "hebrew_datasets = gemini_multi_translation(\n",
    "    google_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_MULTI_V1,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851254f5-cfbf-462e-98dd-3338614ff9ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Claude vs Gemini (using Gemini as judge)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56a89000-d34e-41bc-95b0-2fdd574d3676",
   "metadata": {},
   "source": [
    "hebrew_datasets = gemini_claude_best_translation(\n",
    "    google_client,\n",
    "    bedrock_client,\n",
    "    arc_dataset,\n",
    "    arc_prompts.ARC_INSTRUCT_V,\n",
    "    arc_prompts.ARC_FEW_SHOTS,\n",
    "    arc_prompts.ARC_FORMAT,\n",
    "    arc_ai.arc_sample_to_dict,\n",
    "    arc_ai.arc_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296388da-d4fb-4b36-a2db-1c57f951882e",
   "metadata": {},
   "source": [
    "# GSM8K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a0c4f1-e6ad-4c67-ae6b-bee463139102",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4560b4b-9ace-40fc-843e-65d41b309da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare_csv/gsm8k_main_test_top_200.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gsm8k_test': Dataset({\n",
       "     features: ['question', 'answer'],\n",
       "     num_rows: 200\n",
       " })}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm_dataset = gsm8k.get_gsm8k_datasets()\n",
    "gsm_dataset['gsm8k_test'] = gsm_dataset['gsm8k_test'].take(200)\n",
    "gsm_file_name = 'compare_csv/gsm8k_main_test_top_200.csv'\n",
    "\n",
    "print(gsm_file_name)\n",
    "gsm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e72b19-b219-4a37-bbf3-5a244bb16705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...\n",
       "1  <question>A robe takes 2 bolts of blue fiber a..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...\n",
       "1  <question>A robe takes 2 bolts of blue fiber a..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(gsm_file_name, 'original', gsm_dataset['gsm8k_test'], gsm8k.gsm8k_sample_to_dict)\n",
    "text_df = add_dataset_to_csv(gsm_file_name[:-4] + '-text.csv', 'original', gsm_dataset['gsm8k_test'], gsm8k.gsm8k_sample_to_dict)\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c8a092e-dd74-4620-9817-5198cfe02007",
   "metadata": {},
   "source": [
    "df = pd.read_csv(gsm_file_name)\n",
    "text_df = pd.read_csv(gsm_file_name[:-4] + '-text.csv')\n",
    "display(df.head(2))\n",
    "display(text_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fb0d82-bb51-4e63-801c-0df8d2f85b8d",
   "metadata": {},
   "source": [
    "## Run Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd27f1cb-ef7d-4bdd-9f34-05292e28f7ea",
   "metadata": {},
   "source": [
    "### Claude"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0ac7385-066f-43e7-810c-ac750793f3c2",
   "metadata": {},
   "source": [
    "small = {}\n",
    "small['check'] = gsm_dataset['gsm8k_test'].take(4)\n",
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad5ace54-e441-4ab3-8f14-9ee884624b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating gsm8k_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44682c4b6856443c92ae36091ec8e290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = 'claude_v2_refine'\n",
    "\n",
    "hebrew_datasets, text_output = claude_translation(\n",
    "    bedrock_client,\n",
    "    # small,\n",
    "    gsm_dataset,\n",
    "    gsm_prompts.GSM_INSTRUCT_CLAUDE_REFINE_V2,\n",
    "    gsm_prompts.GSM_FEW_SHOTS,\n",
    "    # gsm_prompts.GSM_FORMAT,\n",
    "    gsm_prompts.GSM_FORMAT_REFINE,\n",
    "    gsm8k.gsm8k_sample_to_dict,\n",
    "    gsm8k.gsm8k_dict_to_sample,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "056391ad-23bb-4ebf-9a7c-89d9820f2310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_mat(text):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f225c03-c75b-47b0-b5bc-80920d4bf28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pd.Series([len_mat(i) for i in text_output['gsm8k_test']]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d01c5ed8-40de-46d3-812c-1de240b572ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "      <td>&lt;question&gt;הברווזים של יעל מטילים 16 ביצים ביום...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "      <td>&lt;question&gt;לתפירת חלוק נדרשים 2 גלילי אריג כחול...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...   \n",
       "1  <question>A robe takes 2 bolts of blue fiber a...   \n",
       "\n",
       "                                    claude_v2_refine  \n",
       "0  <question>הברווזים של יעל מטילים 16 ביצים ביום...  \n",
       "1  <question>לתפירת חלוק נדרשים 2 גלילי אריג כחול...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(gsm_file_name, exp_name, hebrew_datasets['gsm8k_test'], gsm8k.gsm8k_sample_to_dict)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a2413a70-6c2a-4816-84a7-21912c3bde72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "      <td>First translation attempt:\\n&lt;question&gt;התרנגולו...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "      <td>First translation attempt:\\n&lt;question&gt;גלימה דו...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...   \n",
       "1  <question>A robe takes 2 bolts of blue fiber a...   \n",
       "\n",
       "                               claude_v2_refine text  \n",
       "0  First translation attempt:\\n<question>התרנגולו...  \n",
       "1  First translation attempt:\\n<question>גלימה דו...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[exp_name + ' text'] = text_output['gsm8k_test']\n",
    "text_df.to_csv(gsm_file_name[:-4] + '-text.csv', index=False)\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a511b93a-e919-4a52-ac18-a9f708277213",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First translation attempt:\n",
      "<question>התרנגולות של ינט מטילות 16 ביצים ביום. היא אוכלת שלוש לארוחת בוקר כל בוקר ואופה מאפינס לחבריה כל יום עם ארבע. היא מוכרת את השאר בשוק האיכרים מדי יום ב-2$ לביצת ברווז טרייה. כמה דולרים היא מרוויחה כל יום בשוק האיכרים?</question>\n",
      "<answer>ינט מוכרת 16 - 3 - 4 = <<16-3-4=9>>9 ביצי ברווז ביום.\n",
      "היא מרוויחה 9 * 2 = $<<9*2=18>>18 כל יום בשוק האיכרים.\n",
      "#### 18</answer>\n",
      "\n",
      "<explain>\n",
      "The translation needs several improvements:\n",
      "1. \"Janet\" should be changed to a more common Israeli name like \"יעל\"\n",
      "2. The original mentions \"ducks\" but I mistakenly translated to \"תרנגולות\" (chickens) in the first sentence\n",
      "3. Need to change dollars ($) to shekels (₪)\n",
      "4. \"Farmers' market\" should be translated to the more common Israeli term \"שוק איכרים\" \n",
      "5. Need to ensure consistency with \"duck eggs\" throughout the translation\n",
      "6. The formatting and structure should be preserved but with Hebrew right-to-left orientation\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>הברווזים של יעל מטילים 16 ביצים ביום. היא אוכלת שלוש לארוחת בוקר כל בוקר ואופה מאפינס לחבריה כל יום עם ארבע. היא מוכרת את שאר הביצים בשוק האיכרים מדי יום ב-2 ₪ לביצת ברווז טרייה. כמה שקלים היא מרוויחה כל יום בשוק האיכרים?</question>\n",
      "<answer>יעל מוכרת 16 - 3 - 4 = <<16-3-4=9>>9 ביצי ברווז ביום.\n",
      "היא מרוויחה 9 * 2 = ₪<<9*2=18>>18 כל יום בשוק האיכרים.\n",
      "#### 18</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>גלימה דורשת 2 גלילי בד כחול וחצי מכמות זו של בד לבן. כמה גלילי בד סך הכל דרושים?</question>\n",
      "<answer>דרוש 2/2=<<2/2=1>>1 גליל של בד לבן\n",
      "אז הכמות הכוללת של בד היא 2+1=<<2+1=3>>3 גלילי בד\n",
      "#### 3</answer>\n",
      "\n",
      "<explain>\n",
      "התרגום הראשוני טוב, אבל יש מקום לשיפור:\n",
      "1. המילה \"robe\" תורגמה ל\"גלימה\" שזה נכון, אבל אפשר להשתמש במילה \"חלוק\" שיותר נפוצה בעברית יומיומית.\n",
      "2. המילה \"bolts\" תורגמה ל\"גלילי בד\" שזה תרגום טוב, אבל אפשר להשתמש במילה \"גלילים\" שהיא יותר נפוצה.\n",
      "3. המילה \"fiber\" תורגמה ל\"בד\" שזה לא מדויק לחלוטין, אך מתאים להקשר. אפשר להשתמש במילה \"אריג\" שהיא יותר מדויקת.\n",
      "4. כדאי לשפר את הניסוח בתשובה כדי שיהיה יותר טבעי בעברית.\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>לתפירת חלוק נדרשים 2 גלילי אריג כחול וחצי מכמות זו של אריג לבן. כמה גלילי אריג נדרשים בסך הכל?</question>\n",
      "<answer>נדרש 2/2=<<2/2=1>>1 גליל של אריג לבן\n",
      "לכן הכמות הכוללת של אריג היא 2+1=<<2+1=3>>3 גלילי אריג\n",
      "#### 3</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>ג'וש מחליט לנסות לשפץ בית ולמכור אותו ברווח. הוא קונה בית ב-80,000 דולר ואז משקיע 50,000 דולר בשיפוצים. זה הגדיל את ערך הבית ב-150%. כמה רווח הוא עשה?</question>\n",
      "<answer>עלות הבית והשיפוצים הסתכמה ב-80,000+50,000=$<<80000+50000=130000>>130,000\n",
      "הוא הגדיל את ערך הבית ב-80,000*1.5=<<80000*1.5=120000>>120,000\n",
      "אז הערך החדש של הבית הוא 120,000+80,000=$<<120000+80000=200000>>200,000\n",
      "אז הוא עשה רווח של 200,000-130,000=$<<200000-130000=70000>>70,000\n",
      "#### 70000</answer>\n",
      "\n",
      "<explain>\n",
      "The translation needs several improvements:\n",
      "1. Replace dollars with shekels (₪) as the currency\n",
      "2. Use a more Israeli name instead of Josh\n",
      "3. Use the term \"פליפ\" which is commonly used in Israel for house flipping\n",
      "4. Make sure all monetary values use the shekel symbol consistently\n",
      "5. Use more natural Hebrew phrasing for the real estate context\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>יואב מחליט לנסות לעשות \"פליפ\" לדירה. הוא קונה דירה ב-80,000₪ ואז משקיע 50,000₪ בשיפוצים. זה העלה את ערך הדירה ב-150%. כמה רווח הוא עשה?</question>\n",
      "<answer>עלות הדירה והשיפוצים הסתכמה ב-80,000+50,000=₪<<80000+50000=130000>>130,000\n",
      "הוא העלה את ערך הדירה ב-80,000*1.5=<<80000*1.5=120000>>120,000₪\n",
      "אז הערך החדש של הדירה הוא 120,000+80,000=₪<<120000+80000=200000>>200,000\n",
      "אז הוא עשה רווח של 200,000-130,000=₪<<200000-130000=70000>>70,000\n",
      "#### 70000</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>ג'יימס מחליט לרוץ 3 ספרינטים 3 פעמים בשבוע. הוא רץ 60 מטרים בכל ספרינט. כמה מטרים סך הכל הוא רץ בשבוע?</question>\n",
      "<answer>הוא מבצע ספרינט 3*3=<<3*3=9>>9 פעמים\n",
      "אז הוא רץ 9*60=<<9*60=540>>540 מטרים\n",
      "#### 540</answer>\n",
      "\n",
      "<explain>\n",
      "התרגום הראשוני טוב באופן כללי, אך יש מקום לשיפור:\n",
      "1. כדאי להחליף את השם \"ג'יימס\" לשם ישראלי נפוץ יותר כמו \"יעקב\" או \"יוסי\"\n",
      "2. אפשר לשפר את הניסוח של המשפט הראשון בתשובה ל\"הוא רץ ספרינט\" במקום \"הוא מבצע ספרינט\"\n",
      "3. אפשר להוסיף את המילה \"בסך הכל\" במשפט השני של התשובה לשיפור הבהירות\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>יוסי מחליט לרוץ 3 ספרינטים 3 פעמים בשבוע. הוא רץ 60 מטרים בכל ספרינט. כמה מטרים סך הכל הוא רץ בשבוע?</question>\n",
      "<answer>הוא רץ ספרינט 3*3=<<3*3=9>>9 פעמים בשבוע\n",
      "אז בסך הכל הוא רץ 9*60=<<9*60=540>>540 מטרים\n",
      "#### 540</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>בכל יום, ונדי מאכילה כל אחת מהתרנגולות שלה שלוש כוסות של תערובת מזון לתרנגולות, המכילה זרעים, תולעי קמח וירקות כדי לשמור על בריאותן. היא נותנת לתרנגולות את המזון שלהן בשלוש ארוחות נפרדות. בבוקר, היא נותנת ללהקת התרנגולות שלה 15 כוסות מזון. אחר הצהריים, היא נותנת לתרנגולות שלה עוד 25 כוסות מזון. כמה כוסות מזון היא צריכה לתת לתרנגולות שלה בארוחה האחרונה של היום אם גודל להקת התרנגולות של ונדי הוא 20 תרנגולות?</question>\n",
      "<answer>אם כל תרנגולת אוכלת 3 כוסות מזון ביום, אז עבור 20 תרנגולות הן יצטרכו 3*20=<<3*20=60>>60 כוסות מזון ביום.\n",
      "אם היא מאכילה את הלהקה 15 כוסות מזון בבוקר, ו-25 כוסות אחר הצהריים, אז הארוחה האחרונה תדרוש 60-15-25=<<60-15-25=20>>20 כוסות מזון לתרנגולות.\n",
      "#### 20</answer>\n",
      "\n",
      "<explain>\n",
      "התרגום הראשוני טוב באופן כללי, אך יש מספר שינויים שכדאי לבצע כדי להתאים אותו יותר לקהל ישראלי:\n",
      "\n",
      "1. שם: \"ונדי\" הוא שם לא נפוץ בישראל, עדיף להחליף אותו בשם ישראלי יותר כמו \"נועה\".\n",
      "2. מונחים: \"להקת תרנגולות\" נשמע קצת מוזר בעברית, עדיף \"להקת העופות\" או פשוט \"התרנגולות שלה\".\n",
      "3. ניסוח: כדאי לשפר מעט את הניסוח כדי שיהיה טבעי יותר בעברית.\n",
      "4. עקביות: להשתמש במונח \"תערובת מזון\" באופן עקבי.\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>בכל יום, נועה מאכילה כל אחת מהתרנגולות שלה שלוש כוסות של תערובת מזון, המכילה זרעים, תולעי קמח וירקות כדי לשמור על בריאותן. היא נותנת לתרנגולות את המזון בשלוש ארוחות נפרדות. בבוקר, היא נותנת לתרנגולות שלה 15 כוסות תערובת. אחר הצהריים, היא נותנת להן עוד 25 כוסות תערובת. כמה כוסות תערובת היא צריכה לתת לתרנגולות בארוחה האחרונה של היום אם בלול של נועה יש 20 תרנגולות?</question>\n",
      "<answer>אם כל תרנגולת אוכלת 3 כוסות תערובת מזון ביום, אז עבור 20 תרנגולות הן יצטרכו 3*20=<<3*20=60>>60 כוסות תערובת ביום.\n",
      "אם היא מאכילה את התרנגולות 15 כוסות תערובת בבוקר, ו-25 כוסות אחר הצהריים, אז בארוחה האחרונה היא תצטרך לתת 60-15-25=<<60-15-25=20>>20 כוסות תערובת.\n",
      "#### 20</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>קיילר הלך לחנות לקנות כוסות לדירתו החדשה. כוס אחת עולה 5₪, אבל כל כוס שנייה עולה רק 60% מהמחיר. קיילר רוצה לקנות 16 כוסות. כמה עליו לשלם עבורן?</question>\n",
      "<answer>המחיר המוזל של כוס אחת הוא 60/100 * 5 = ₪<<60/100*5=3>>3.\n",
      "אם כל כוס שנייה זולה יותר, זה אומר שקיילר הולך לקנות 16 / 2 = <<16/2=8>>8 כוסות מוזלות.\n",
      "אז עבור הכוסות המוזלות, קיילר הולך לשלם 8 * 3 = ₪<<8*3=24>>24.\n",
      "ועבור הכוסות במחיר רגיל, קיילר ישלם 8 * 5 = ₪<<8*5=40>>40.\n",
      "אז בסך הכל קיילר צריך לשלם 24 + 40 = ₪<<24+40=64>>64 עבור הכוסות שהוא רוצה לקנות.\n",
      "#### 64</answer>\n",
      "\n",
      "<explain>\n",
      "התרגום הראשוני טוב, אך יש מקום לשיפור:\n",
      "1. השם \"קיילר\" אינו נפוץ בישראל, עדיף להחליף אותו בשם ישראלי יותר כמו \"קובי\".\n",
      "2. כדאי להשתמש במילה \"כוסות\" באופן עקבי במקום לעבור בין \"כוסות\" ל\"כוס\".\n",
      "3. אפשר לשפר מעט את הניסוח כדי שיהיה טבעי יותר בעברית.\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>קובי הלך לחנות לקנות כוסות לדירתו החדשה. כוס אחת עולה 5₪, אבל כל כוס שנייה עולה רק 60% מהמחיר. קובי רוצה לקנות 16 כוסות. כמה עליו לשלם עבורן?</question>\n",
      "<answer>המחיר המוזל של כוס אחת הוא 60/100 * 5 = ₪<<60/100*5=3>>3.\n",
      "אם כל כוס שנייה זולה יותר, זה אומר שקובי הולך לקנות 16 / 2 = <<16/2=8>>8 כוסות מוזלות.\n",
      "עבור הכוסות המוזלות, קובי ישלם 8 * 3 = ₪<<8*3=24>>24.\n",
      "ועבור הכוסות במחיר רגיל, קובי ישלם 8 * 5 = ₪<<8*5=40>>40.\n",
      "בסך הכל קובי צריך לשלם 24 + 40 = ₪<<24+40=64>>64 עבור הכוסות שהוא רוצה לקנות.\n",
      "#### 64</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>לטל יש פי שניים כבשים מאשר לחן. לחן יש פי 4 כבשים מאשר לשירה. כמה כבשים יש לטל, חן ושירה ביחד אם לשירה יש 20 כבשים?</question>\n",
      "<answer>אם לשירה יש 20 כבשים, לחן יש 4 * 20 כבשים = <<20*4=80>>80 כבשים\n",
      "לטל יש פי שניים כבשים מאשר לחן, שזה 2 * 80 כבשים = <<2*80=160>>160 כבשים\n",
      "ביחד, לשלושתן יש 20 כבשים + 160 כבשים + 80 כבשים = <<20+160+80=260>>260 כבשים\n",
      "#### 260</answer>\n",
      "\n",
      "<explain>\n",
      "The translation is generally good, but I made the following changes:\n",
      "1. I replaced the foreign names (Toulouse, Charleston, Seattle) with common Israeli names (Tal, Chen, Shira) to make the problem more relatable for Israeli students.\n",
      "2. I used feminine forms for the names since the Hebrew translation requires gender agreement.\n",
      "3. I maintained the same mathematical structure and relationships between the quantities.\n",
      "4. The translation preserves the original formatting and calculation steps.\n",
      "\n",
      "For the improved version, I'll keep the same translation but ensure the gender agreement is consistent throughout.\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>לטל יש פי שניים כבשים מאשר לחן. לחן יש פי 4 כבשים מאשר לשירה. כמה כבשים יש לטל, חן ושירה ביחד אם לשירה יש 20 כבשים?</question>\n",
      "<answer>אם לשירה יש 20 כבשים, לחן יש 4 * 20 כבשים = <<20*4=80>>80 כבשים\n",
      "לטל יש פי שניים כבשים מאשר לחן, שזה 2 * 80 כבשים = <<2*80=160>>160 כבשים\n",
      "ביחד, לשלושתן יש 20 כבשים + 160 כבשים + 80 כבשים = <<20+160+80=260>>260 כבשים\n",
      "#### 260</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>קרלה מורידה קובץ בגודל 200 ג'יגה-בייט. בדרך כלל היא יכולה להוריד 2 ג'יגה-בייט לדקה, אבל אחרי 40% מההורדה, חלונות מאלצת אותה לאתחל את המחשב כדי להתקין עדכונים, מה שלוקח 20 דקות. אז קרלה צריכה להתחיל את ההורדה מחדש מההתחלה. כמה זמן לוקח להוריד את הקובץ?</question>\n",
      "<answer>קודם נמצא כמה ג'יגה-בייט יש ב-40% מהקובץ: 200 ג'יגה-בייט * 40% = <<200*40*.01=80>>80 ג'יגה-בייט\n",
      "אז נחלק את המספר הזה בקצב ההורדה כדי למצוא את הזמן עד שחלונות מתאתחלת: 80 ג'יגה-בייט / 2 ג'יגה-בייט לדקה = <<80/2=40>>40 דקות\n",
      "אז נמצא את הזמן להוריד את כל הקובץ אחרי האתחול: 200 ג'יגה-בייט / 2 ג'יגה-בייט לדקה = <<200/2=100>>100 דקות\n",
      "אז נחבר את הזמן להוריד 40% מהקובץ, להוריד את כל הקובץ, ולחכות שחלונות תתעדכן: 40 דקות + 100 דקות + 20 דקות = <<40+100+20=160>>160 דקות\n",
      "#### 160</answer>\n",
      "\n",
      "<explain>\n",
      "The translation is generally good, but there are a few improvements we can make:\n",
      "\n",
      "1. Change the name \"קרלה\" (Carla) to a more common Israeli name like \"כרמל\" (Carmel)\n",
      "2. Use the feminine form correctly for \"מורידה\" (downloading)\n",
      "3. Make the wording more natural in Hebrew by adjusting some phrases\n",
      "4. Fix a typo in the question - \"How load\" should be \"How long\"\n",
      "5. Use the proper Hebrew term for Windows operating system (חלונות)\n",
      "6. Make sure all technical terms are properly translated and consistent\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>כרמל מורידה קובץ בגודל 200 ג'יגה-בייט. בדרך כלל היא יכולה להוריד 2 ג'יגה-בייט לדקה, אבל לאחר השלמת 40% מההורדה, מערכת ההפעלה חלונות מאלצת אתחול מחדש כדי להתקין עדכונים, תהליך שאורך 20 דקות. לאחר מכן, כרמל נאלצת להתחיל את ההורדה מחדש מההתחלה. כמה זמן בסך הכל לוקח להוריד את הקובץ?</question>\n",
      "<answer>ראשית נמצא כמה ג'יגה-בייט יש ב-40% מהקובץ: 200 ג'יגה-בייט * 40% = <<200*40*.01=80>>80 ג'יגה-בייט\n",
      "כעת נחלק את המספר הזה בקצב ההורדה כדי למצוא את הזמן עד שחלונות מתאתחלת: 80 ג'יגה-בייט / 2 ג'יגה-בייט לדקה = <<80/2=40>>40 דקות\n",
      "אחר כך נמצא את הזמן להוריד את כל הקובץ אחרי האתחול: 200 ג'יגה-בייט / 2 ג'יגה-בייט לדקה = <<200/2=100>>100 דקות\n",
      "לבסוף נחבר את הזמן להוריד 40% מהקובץ, את זמן העדכון של חלונות, ואת הזמן להוריד את כל הקובץ מחדש: 40 דקות + 20 דקות + 100 דקות = <<40+100+20=160>>160 דקות\n",
      "#### 160</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>יוחנן נוהג במשך 3 שעות במהירות של 60 מייל לשעה ואז מסתובב כי הוא מבין שהוא שכח משהו חשוב מאוד בבית. הוא מנסה להגיע הביתה תוך 4 שעות אבל מבלה את השעתיים הראשונות בפקק תנועה. הוא מבלה את חצי השעה הבאה בנהיגה במהירות של 30 מייל לשעה, לפני שהוא מצליח לנהוג את שארית הזמן של 4 השעות במהירות של 80 מייל לשעה. כמה רחוק הוא מהבית בסוף אותן 4 שעות?</question>\n",
      "<answer>כאשר הוא הסתובב הוא היה 3*60=<<3*60=180>>180 מייל מהבית\n",
      "הוא הצליח לנהוג רק 4-2=<<4-2=2>>2 שעות בארבע השעות הראשונות\n",
      "בחצי שעה הוא נוסע 30*.5=<<30*.5=15>>15 מייל\n",
      "אז הוא נוהג עוד 2-.5=<<2-.5=1.5>>1.5 שעות\n",
      "בזמן הזה הוא נוסע 80*1.5=<<80*1.5=120>>120 מייל\n",
      "אז הוא נהג 120+15=<<120+15=135>>135 מייל\n",
      "אז הוא נמצא 180-135=<<180-135=45>>45 מייל מהבית\n",
      "#### 45</answer>\n",
      "\n",
      "<explain>\n",
      "The translation needs several improvements:\n",
      "1. Convert miles to kilometers as this is the standard unit in Israel\n",
      "2. Use a more common Israeli name instead of \"יוחנן\" (Yochanan)\n",
      "3. Improve the flow of the Hebrew text to sound more natural\n",
      "4. Keep the mathematical calculations in miles to maintain consistency with the original problem\n",
      "5. Use more natural Hebrew phrasing for describing traffic situations\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>יובל נוהג במשך 3 שעות במהירות של 60 קמ\"ש ואז מסתובב כי הוא נזכר ששכח משהו חשוב מאוד בבית. הוא מנסה להגיע הביתה תוך 4 שעות, אבל במשך השעתיים הראשונות הוא תקוע בפקק תנועה ולא מתקדם כלל. לאחר מכן הוא נוהג חצי שעה במהירות של 30 קמ\"ש, ואת שארית הזמן מתוך 4 השעות הוא נוהג במהירות של 80 קמ\"ש. כמה רחוק הוא מהבית בסוף אותן 4 שעות?</question>\n",
      "<answer>כאשר הוא הסתובב הוא היה 3*60=<<3*60=180>>180 קמ\"ש מהבית\n",
      "הוא הצליח לנהוג רק 4-2=<<4-2=2>>2 שעות מתוך ארבע השעות\n",
      "בחצי שעה הוא נסע 30*0.5=<<30*0.5=15>>15 ק\"מ\n",
      "אחר כך הוא נהג עוד 2-0.5=<<2-0.5=1.5>>1.5 שעות\n",
      "בזמן הזה הוא נסע 80*1.5=<<80*1.5=120>>120 ק\"מ\n",
      "סך הכל הוא נסע 120+15=<<120+15=135>>135 ק\"מ\n",
      "לכן הוא נמצא 180-135=<<180-135=45>>45 ק\"מ מהבית\n",
      "#### 45</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n",
      "First translation attempt:\n",
      "<question>השכר השעתי של אליזה עבור 40 השעות הראשונות שהיא עובדת בכל שבוע הוא 10$. היא גם מקבלת תשלום שעות נוספות של 1.2 פעמים משכרה השעתי הרגיל. אם אליזה עבדה 45 שעות השבוע, כמה היא הרוויחה השבוע?</question>\n",
      "<answer>אליזה זכאית ל-45 - 40 = <<45-40=5>>5 שעות נוספות.\n",
      "השכר השעתי שלה עבור שעות נוספות הוא 10$ × 1.2 = $<<10*1.2=12>>12.\n",
      "לכן, אליזה תקבל 12$ × 5 = $<<12*5=60>>60 עבור שעות נוספות.\n",
      "השכר השבועי הרגיל שלה הוא 10$ × 40 = $<<10*40=400>>400.\n",
      "לכן, אליזה תקבל סך הכל 400$ + 60$ = $<<400+60=460>>460 עבור עבודתה השבוע.\n",
      "#### 460</answer>\n",
      "\n",
      "<explain>\n",
      "התרגום הראשוני טוב, אך יש מספר שינויים שכדאי לבצע:\n",
      "1. להחליף את השם \"אליזה\" לשם ישראלי נפוץ יותר כמו \"אלה\"\n",
      "2. להחליף דולרים לשקלים\n",
      "3. לשפר את הניסוח בעברית כך שיהיה טבעי יותר\n",
      "4. להתאים את המונחים לשוק העבודה הישראלי (למשל \"שעות נוספות\" במקום תרגום מילולי של \"overtime pay\")\n",
      "5. לוודא שהסימון של המטבע עקבי ומופיע אחרי המספר כמקובל בעברית (₪)\n",
      "</explain>\n",
      "\n",
      "Improved translation:\n",
      "<question>השכר השעתי של אלה עבור 40 השעות הראשונות שהיא עובדת בכל שבוע הוא 10₪. היא גם מקבלת תשלום עבור שעות נוספות בשיעור של 1.2 פעמים משכרה השעתי הרגיל. אם אלה עבדה 45 שעות השבוע, כמה היא הרוויחה בסך הכל השבוע?</question>\n",
      "<answer>אלה זכאית ל-45 - 40 = <<45-40=5>>5 שעות נוספות.\n",
      "השכר השעתי שלה עבור שעות נוספות הוא 10₪ × 1.2 = <<10*1.2=12>>12₪.\n",
      "לכן, אלה תקבל 12₪ × 5 = <<12*5=60>>60₪ עבור שעות נוספות.\n",
      "השכר השבועי הרגיל שלה הוא 10₪ × 40 = <<10*40=400>>400₪.\n",
      "לכן, אלה תקבל בסך הכל 400₪ + 60₪ = <<400+60=460>>460₪ עבור עבודתה השבוע.\n",
      "#### 460</answer>\n",
      "\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(text_df['claude_v2_refine text'].iloc[i])\n",
    "    print('\\n - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "626db1a1-0360-470f-b862-9511c10379fa",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i in range(10):\n",
    "    print(df['original'].iloc[i])\n",
    "    print()\n",
    "    print(df['claude_v1'].iloc[i])\n",
    "    print('\\n - - - - - - - - - - - - - - - - - - - - - - - - - - - - \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5fe66-3d0b-4c0e-8493-25df183943e3",
   "metadata": {},
   "source": [
    "### Gemini"
   ]
  },
  {
   "cell_type": "raw",
   "id": "729fa52f-68d1-4662-bb0b-21b48948201f",
   "metadata": {},
   "source": [
    "use_num = 2\n",
    "\n",
    "small = {}\n",
    "small['gsm8k_test'] = gsm_dataset['gsm8k_test'].take(use_num)\n",
    "small\n",
    "\n",
    "size = gsm_dataset['gsm8k_test'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9bcf4d-b33f-41cb-9993-289642e9037b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating gsm8k_test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c2895cf43d4b2bb0f9f9400a1d1460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = 'gemini_pro_think_v2'\n",
    "\n",
    "hebrew_datasets, text_output = gemini_translation(\n",
    "    google_client,\n",
    "    # small,\n",
    "    gsm_dataset,\n",
    "    gsm_prompts.GSM_INSTRUCT_GEMINI_V2,\n",
    "    gsm_prompts.GSM_FEW_SHOTS,\n",
    "    gsm8k.gsm8k_sample_to_dict,\n",
    "    gsm8k.gsm8k_dict_to_sample,\n",
    "    if_pro=True,\n",
    "    think_bud=4_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4514d75-5241-47fd-be9d-c0b5e922f700",
   "metadata": {},
   "source": [
    "from datasets import Dataset, concatenate_datasets\n",
    "empty = {key: ['EMPTY'] * (size - use_num) for key in small['gsm8k_test'].column_names}\n",
    "empty = Dataset.from_dict(empty)\n",
    "hebrew_datasets['gsm8k_test'] = concatenate_datasets([hebrew_datasets['gsm8k_test'], empty])\n",
    "\n",
    "text_output['gsm8k_test'] = text_output['gsm8k_test'] + ['EMPTY'] * (size - use_num)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0aab47e7-edd9-427e-af64-d4858d8a88a0",
   "metadata": {},
   "source": [
    "len(text_output['gsm8k_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "48e6836e-3452-4063-b5e3-e12cfff88815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine</th>\n",
       "      <th>gemini_pro_think_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "      <td>&lt;question&gt;הברווזים של יעל מטילים 16 ביצים ביום...</td>\n",
       "      <td>&lt;question&gt;הברווזים של יעל מטילים 16 ביצים ביום...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "      <td>&lt;question&gt;לתפירת חלוק נדרשים 2 גלילי אריג כחול...</td>\n",
       "      <td>&lt;question&gt;להכנת חלוק צריך 2 גלילי בד כחול וחצי...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...   \n",
       "1  <question>A robe takes 2 bolts of blue fiber a...   \n",
       "\n",
       "                                    claude_v2_refine  \\\n",
       "0  <question>הברווזים של יעל מטילים 16 ביצים ביום...   \n",
       "1  <question>לתפירת חלוק נדרשים 2 גלילי אריג כחול...   \n",
       "\n",
       "                                 gemini_pro_think_v2  \n",
       "0  <question>הברווזים של יעל מטילים 16 ביצים ביום...  \n",
       "1  <question>להכנת חלוק צריך 2 גלילי בד כחול וחצי...  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = add_dataset_to_csv(gsm_file_name, exp_name, hebrew_datasets['gsm8k_test'], gsm8k.gsm8k_sample_to_dict)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "43c2bdf5-8fc0-48e2-95a7-8504f3ea032e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>claude_v2_refine text</th>\n",
       "      <th>gemini_pro_think_v2 text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;question&gt;Janet’s ducks lay 16 eggs per day. S...</td>\n",
       "      <td>First translation attempt:\\n&lt;question&gt;התרנגולו...</td>\n",
       "      <td>**My Thought Process: Translating a Math Probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;question&gt;A robe takes 2 bolts of blue fiber a...</td>\n",
       "      <td>First translation attempt:\\n&lt;question&gt;גלימה דו...</td>\n",
       "      <td>**Problem Solving in Translation**\\n\\nOkay, so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original  \\\n",
       "0  <question>Janet’s ducks lay 16 eggs per day. S...   \n",
       "1  <question>A robe takes 2 bolts of blue fiber a...   \n",
       "\n",
       "                               claude_v2_refine text  \\\n",
       "0  First translation attempt:\\n<question>התרנגולו...   \n",
       "1  First translation attempt:\\n<question>גלימה דו...   \n",
       "\n",
       "                            gemini_pro_think_v2 text  \n",
       "0  **My Thought Process: Translating a Math Probl...  \n",
       "1  **Problem Solving in Translation**\\n\\nOkay, so...  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df[exp_name + ' text'] = text_output['gsm8k_test']\n",
    "text_df.to_csv(gsm_file_name[:-4] + '-text.csv', index=False)\n",
    "text_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "443f817a-38d4-4a34-abff-ecedb1b1dc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
