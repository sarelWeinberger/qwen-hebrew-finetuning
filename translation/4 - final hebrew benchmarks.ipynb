{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb607844-f55b-4221-937f-02c656ff22d6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3d6f4-b8ac-4463-bb86-1af50b9e16dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "\n",
    "from src.benchmarks_code import gsm8k\n",
    "from src.benchmarks_code import arc_ai\n",
    "from src.benchmarks_code import mmlu\n",
    "from src.benchmarks_code import hellaswag\n",
    "\n",
    "from src.parse_labeling import parse_from_gradio, parse_single_file_gradio, map_rating_to_model\n",
    "from src.translate_func import dict_to_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fb839-318b-4d77-be9c-2eef161b66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_sample(text):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    return {key: value.strip() for key, value in matches}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c92406-16e7-42cc-9611-2d5d28350471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gold(or_df, return_original_sample=False):\n",
    "    \"\"\"\n",
    "    or_df - a Dataframe with the columns 'rating model', 'gold', 'option 1', 'option 2', 'model 1', 'model 2'\n",
    "    \"\"\"\n",
    "    final_lst = []\n",
    "    \n",
    "    if return_original_sample:\n",
    "        original_text_lst = []\n",
    "    for cnt, row in or_df.iterrows():\n",
    "        if row['rating model'] == 'SKIP':\n",
    "            continue\n",
    "        elif row['gold'] != '':\n",
    "            final_lst.append(row['gold'].replace('Option 1:\\n', '').replace('Option 2:\\n', ''))\n",
    "        elif row['rating model'] == 'BOTH':\n",
    "            if 'gemini' in row['model 1']:\n",
    "                final_lst.append(row['option 1'])\n",
    "            else:\n",
    "                final_lst.append(row['option 2'])\n",
    "        elif row['rating model'] == row['model 1']:\n",
    "            final_lst.append(row['option 1'])\n",
    "        elif row['rating model'] == row['model 2']:\n",
    "            final_lst.append(row['option 2'])\n",
    "        else:\n",
    "            print(cnt, row)\n",
    "            assert False, \"ERROR ERROR ERRORRRRRR!\"\n",
    "\n",
    "        if return_original_sample:\n",
    "            # Add the original (english) text always - unless it is a 'SKIP' sample\n",
    "            original_text_lst.append(row['original'])\n",
    "    \n",
    "    final_lst = [query_to_sample(s) for s in final_lst]\n",
    "    # original_text_lst = [query_to_sample(s) for s in original_text_lst]\n",
    "\n",
    "    if return_original_sample:\n",
    "        return final_lst, original_text_lst\n",
    "    else:\n",
    "        return final_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d6940-e1ab-49f7-a7a4-39fd7eb136c0",
   "metadata": {},
   "source": [
    "# ARC-AI2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f97876-6d3f-4a2e-b224-e8012dc6f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_en = arc_ai.get_arc_ai2_datasets()\n",
    "arc_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776b78a-16ff-4238-a35d-cc13b5231cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_label_train, arc_or_train = parse_from_gradio(\n",
    "    'labeled_files/arc_ai_labeled_gradio.csv',\n",
    "    'manual_compare/arc_ai2_train_top_200_FULL.csv',\n",
    ")\n",
    "\n",
    "print(arc_label_train.shape, arc_or_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154f7531-c7ac-4ca7-adbd-d78b5fe5e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_label_train['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de33f3-6dad-4271-b26d-23aaae807572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be False\n",
    "(arc_or_train['original'] != arc_label_train['text_column']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12557264-2ea0-4c7b-875b-2620c7dd0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_or_train['gold'] = arc_label_train['gold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84c1ed-a634-45e1-9cd6-4a077a2d2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_label_test_1 = pd.read_csv('labeled_files/arc_ai_TEST_labeled_gradio.csv')\n",
    "arc_label_test_2 = pd.read_csv('labeled_files/arc_ai_TEST_2_labeled_gradio.csv')\n",
    "\n",
    "(arc_label_test_1.tail(51)['text_column'] == arc_label_test_2.head(51)['text_column'].values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b6255-937d-417d-b7d1-8c49cf45dc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_label_test_1 = pd.read_csv('labeled_files/arc_ai_TEST_labeled_gradio.csv')\n",
    "arc_label_test_2 = pd.read_csv('labeled_files/arc_ai_TEST_2_labeled_gradio.csv').iloc[51:]\n",
    "\n",
    "arc_label_test = pd.concat([arc_label_test_1, arc_label_test_2], ignore_index=True)\n",
    "\n",
    "arc_label_test = arc_label_test.fillna('')\n",
    "arc_label_test['rating'] = arc_label_test['rating'].apply(str).replace('1.0', '1').replace('2.0', '2')\n",
    "\n",
    "print(f\"Throw away {(arc_label_test['rating'] == 'SKIP').sum()} 'SKIP' samples\")\n",
    "arc_label_test = arc_label_test[arc_label_test['rating'] != 'SKIP']\n",
    "\n",
    "old = arc_label_test.copy()\n",
    "arc_label_test.loc[arc_label_test['gold'] == '', 'gold'] = arc_label_test.loc[arc_label_test['gold'] == '']['new_text_column'].values\n",
    "\n",
    "arc_label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b5c4f-9d57-4027-b831-d45c9a0f3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(old['gold'] != '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66688a11-4f8a-4970-bace-47eccde717d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be True\n",
    "(old.loc[old['gold'] != '', 'gold'] == arc_label_test.loc[old['gold'] != '', 'gold']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32b5ad5-f8bc-4197-9b8a-c9fb3788cd85",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe321b5-c7c1-4094-a0df-a431c65a4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_he_lst_train, original_txt_train = get_gold(arc_or_train, True)\n",
    "\n",
    "arc_he_lst_train = [{\n",
    "    'query': d['question'],\n",
    "    'choices': [d[f'option {i}'] for i in [1, 2, 3, 4]],\n",
    "} for d in arc_he_lst_train]\n",
    "\n",
    "len(arc_he_lst_train), len(original_txt_train), arc_label_train.shape[0] - (arc_label_train['rating'] == 'SKIP').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726a1aa-6ecb-439a-ad48-ae435d8b365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_he_lst_test = []\n",
    "original_txt_test = []\n",
    "\n",
    "for _, row in arc_label_test.iterrows():\n",
    "    d = query_to_sample(row['gold'])\n",
    "    arc_he_lst_test.append({\n",
    "        'query': d['question'],\n",
    "        'choices': [d[f'option {i}'] for i in [1, 2, 3, 4]],\n",
    "    })\n",
    "    \n",
    "    original_txt_test.append(row['text_column'])\n",
    "\n",
    "len(arc_he_lst_test), len(original_txt_test), arc_label_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e55e48-e662-41ff-b15e-dc38d7bc0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_LABEL_TO_ANSWER_INDEX = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    '1': 0,\n",
    "    '2': 1,\n",
    "    '3': 2,\n",
    "    '4': 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e3507d-ad21-47f3-8042-76b1c996d2fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_indcs_train = {}\n",
    "cnt = 0\n",
    "for i in range(len(arc_he_lst_train)):\n",
    "    while dict_to_prompt(arc_ai.arc_sample_to_dict(arc_en['arc_challenge_train'][cnt])) != original_txt_train[i]:\n",
    "        cnt += 1\n",
    "    map_indcs_train[i] = cnt\n",
    "\n",
    "map_indcs_test = {}\n",
    "cnt = 0\n",
    "for i in range(len(arc_he_lst_test)):\n",
    "    while len(arc_en['arc_challenge_test'][cnt]['choices']['label']) < 4 or dict_to_prompt(arc_ai.arc_sample_to_dict(arc_en['arc_challenge_test'][cnt])) != original_txt_test[i]:\n",
    "        cnt += 1\n",
    "    map_indcs_test[i] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19810bc-a9b4-4ae0-ae2c-97698d365470",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(arc_he_lst_train)):\n",
    "    if dict_to_prompt(arc_ai.arc_sample_to_dict(arc_en['arc_challenge_train'][map_indcs_train[i]])) != original_txt_train[i]:\n",
    "        print('WWWWWWWWWWWWWAAAAAAAAAAAAAAAA', i)\n",
    "        break\n",
    "    arc_he_lst_train[i]['answer_index'] = MAP_LABEL_TO_ANSWER_INDEX[arc_en['arc_challenge_train'][map_indcs_train[i]]['answerKey']]\n",
    "    arc_he_lst_train[i]['id'] = arc_en['arc_challenge_train'][map_indcs_train[i]]['id']\n",
    "    arc_he_lst_train[i]['from_arc_split'] = 'train'\n",
    "\n",
    "for i in range(len(arc_he_lst_test)):\n",
    "    if dict_to_prompt(arc_ai.arc_sample_to_dict(arc_en['arc_challenge_test'][map_indcs_test[i]])) != original_txt_test[i]:\n",
    "        print('WWWWWWWWWWWWWAAAAAAAAAAAAAAAA', i)\n",
    "        break\n",
    "    arc_he_lst_test[i]['answer_index'] = MAP_LABEL_TO_ANSWER_INDEX[arc_en['arc_challenge_test'][map_indcs_test[i]]['answerKey']]\n",
    "    arc_he_lst_test[i]['id'] = arc_en['arc_challenge_test'][map_indcs_test[i]]['id']\n",
    "    arc_he_lst_test[i]['from_arc_split'] = 'test'\n",
    "\n",
    "len(arc_he_lst_train), len(arc_he_lst_test), len(arc_he_lst_train) + len(arc_he_lst_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b928c-c510-4b6d-9eec-0d434b1f2f6a",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929dec7c-2e69-44b2-bdfe-5a1ec6f91182",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"final_hebrew_bnch/arc_ai2_chall_heb.jsonl\"\n",
    "\n",
    "# Open the file and write each dictionary as a new line\n",
    "with open(output_filename, 'w') as f:\n",
    "    for item in arc_he_lst_train:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "    for item in arc_he_lst_test:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529b787-5905-4ab9-ab27-dda655fbde40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121bd3d1-8b62-420f-b6ab-87973eb89ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_en = gsm8k.get_gsm8k_datasets()\n",
    "gsm_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbec3fb-994c-4bb1-b7ee-01e64b32d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_label, gsm_or = parse_from_gradio(\n",
    "    'labeled_files/gsm8k_labeled_gradio.csv',\n",
    "    'manual_compare/gsm8k_169_FULL.csv',\n",
    ")\n",
    "\n",
    "print(gsm_label.shape, gsm_or.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911fcd3-5ff8-4641-b042-a459b4bece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gsm_or['original'] != gsm_label['text_column']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96daca-f61e-4be4-a819-c862a44eb5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_or['gold'] = gsm_label['gold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafa6d9-9bbe-4d5e-9720-cb20e85b0501",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09ecf45-3b6e-4a7f-aee4-f329a73ea909",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_he_lst = get_gold(gsm_or)\n",
    "\n",
    "gsm_he_lst = [{\n",
    "    'query': d['question'],\n",
    "    'gold': d['answer'],\n",
    "} for d in gsm_he_lst]\n",
    "\n",
    "len(gsm_he_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a94f4-ef34-43c9-8e52-439a6227f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_label_1 = pd.read_csv('labeled_files/gsm_TEST_labeled_gradio.csv')\n",
    "gsm_label_2 = pd.read_csv('labeled_files/gsm_TEST_2_labeled_gradio.csv')\n",
    "\n",
    "(gsm_label_1.tail(50)['text_column'] == gsm_label_2.head(50)['text_column'].values).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cf9042-a5e0-43b8-8e86-951666a69a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_label_1 = pd.read_csv('labeled_files/gsm_TEST_labeled_gradio.csv')\n",
    "gsm_label_2 = pd.read_csv('labeled_files/gsm_TEST_2_labeled_gradio.csv').iloc[50:215]\n",
    "\n",
    "def clean(df):\n",
    "    df = df.fillna('')\n",
    "    df['rating'] = df['rating'].apply(str).replace('1.0', '1').replace('2.0', '2')\n",
    "\n",
    "    print(f\"Throw away {(df['rating'] == 'SKIP').sum()} 'SKIP' samples\")\n",
    "    df = df[df['rating'] != 'SKIP']\n",
    "\n",
    "    old = df.copy()\n",
    "    df.loc[df['gold'] == '', 'gold'] = df.loc[df['gold'] == '']['new_text_column'].values\n",
    "\n",
    "    return df\n",
    "\n",
    "gsm_label_1 = clean(gsm_label_1)\n",
    "gsm_label_2 = clean(gsm_label_2)\n",
    "\n",
    "gsm_label_1.shape, gsm_label_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ef569-a056-44e2-9077-fe929908e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_he_1 = []\n",
    "gsm_he_2 = []\n",
    "\n",
    "for _, row in gsm_label_1.iterrows():\n",
    "    d = query_to_sample(row['gold'])\n",
    "    gsm_he_1.append({\n",
    "        'query': d['question'],\n",
    "        'gold': d['answer'],\n",
    "    })\n",
    "\n",
    "for _, row in gsm_label_2.iterrows():\n",
    "    if row['gold'] == 'דילגתי':\n",
    "        continue\n",
    "        #...\n",
    "    d = query_to_sample(row['gold'])\n",
    "    gsm_he_2.append({\n",
    "        'query': d['question'],\n",
    "        'gold': d['answer'],\n",
    "    })\n",
    "\n",
    "len(gsm_he_1), len(gsm_he_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f2ee1-9b78-4e1e-80b4-cec1bfde650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gsm_he_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2e0a6-018b-4287-a39c-f4d6014d5f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm_he_lst = gsm_he_lst + gsm_he_1 + gsm_he_2\n",
    "\n",
    "len(gsm_he_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d9ba24-eb3c-4868-b0fb-549ededf3e30",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7397291-0ee0-4f46-93d5-f33ff5ee9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"final_hebrew_bnch/gsm8k_heb.jsonl\"\n",
    "\n",
    "# Open the file and write each dictionary as a new line\n",
    "with open(output_filename, 'w') as f:\n",
    "    for item in gsm_he_lst:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70414386-d03a-49c4-8ed8-e0894262c752",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269ff64c-5b0a-4fcb-8033-3b85b4b8c45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mmlu_en = mmlu.get_mmlu_datasets()\n",
    "mmlu_en['mmlu_train'] = load_dataset(\"cais/mmlu\", \"all\", split='auxiliary_train')\n",
    "mmlu_en['mmlu_val'] = load_dataset(\"cais/mmlu\", \"all\", split='validation')\n",
    "mmlu_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184c050f-96c3-4b53-a2a5-27484f556488",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_labels = parse_single_file_gradio('labeled_files/mmlu_test_labeled_gradio.csv')\n",
    "\n",
    "# manual fix\n",
    "mmlu_labels.loc[145, 'rating'] = '1'  # rating missing\n",
    "mmlu_labels.loc[35, 'rating'] = '2'  # rating missing\n",
    "mmlu_labels.loc[35, 'rating model'] =  mmlu_labels.loc[35, 'model 2'] # rating missing\n",
    "mmlu_labels.loc[68, 'gold'] = ''  # the gold is '\\n' instead of ''\n",
    "\n",
    "mmlu_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37526c-8d93-4584-9878-8d4205c59e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_labels['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae91214-b0cb-4d67-9305-fb7cef587d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Throw away {(mmlu_labels['rating'] == 'SKIP').sum()} 'SKIP' samples\")\n",
    "mmlu_labels = mmlu_labels[mmlu_labels['rating'] != 'SKIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247de7f6-c0e2-40a2-867d-740fcaa4c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca8ed47-5c83-4e08-9b97-242d4f37daee",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9b2cf-16f9-4bac-ab76-252e6d6db103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mmlu_labels['rating'] = mmlu_labels.apply(lambda x: map_rating_to_model(x, mmlu_labels), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dd9cd-eb97-4f52-b669-f9d59457a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_he_lst, mmlu_original_txt = get_gold(mmlu_labels, True)\n",
    "\n",
    "mmlu_he_lst = [{\n",
    "    'query': d['question'],\n",
    "    'choices': [d[f'choice_{i}'] for i in ['a', 'b', 'c', 'd']],\n",
    "} for d in mmlu_he_lst]\n",
    "\n",
    "len(mmlu_he_lst), len(mmlu_original_txt), mmlu_labels.shape[0] - (mmlu_labels['rating'] == 'SKIP').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28125690-8168-47cb-94d6-a6f149117fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('labeled_files/mmlu_main_sub_TEST_2_labeled_gradio.csv')['rating'].iloc[34:] == 'SKIP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff875829-8008-42eb-9202-9fa0661c463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d8eeb3-4eb1-464c-af50-e6454be9a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_mmlu = {}\n",
    "more_mmlu['mmlu_main_1'] = pd.read_csv('labeled_files/mmlu_main_sub_TEST_labeled_gradio.csv')\n",
    "more_mmlu['mmlu_main_2'] = pd.read_csv('labeled_files/mmlu_main_sub_TEST_2_labeled_gradio.csv')\n",
    "more_mmlu['mmlu_prob_1'] = pd.read_csv('labeled_files/mmlu_prob_TEST_gradio.csv')\n",
    "more_mmlu['mmlu_prob_2'] = pd.read_csv('labeled_files/mmlu_prob_TEST_2_gradio.csv').head(64)\n",
    "\n",
    "# overlap:\n",
    "assert (more_mmlu['mmlu_main_1']['text_column'].iloc[:500:15] == more_mmlu['mmlu_main_2']['text_column'].head(34).values).all(), 'nonono!'\n",
    "more_mmlu['mmlu_main_2'] = more_mmlu['mmlu_main_2'].iloc[34:]\n",
    "\n",
    "# manual fix\n",
    "if more_mmlu['mmlu_main_1'].loc[326, 'gold'].startswith('question>'):\n",
    "    more_mmlu['mmlu_main_1'].loc[326, 'gold'] = '<' + more_mmlu['mmlu_main_1'].loc[326, 'gold']\n",
    "\n",
    "more_mmlu['mmlu_main_2'].loc[212, 'rating'] = 'SKIP'\n",
    "\n",
    "\n",
    "def clean(df):\n",
    "    df = df.fillna('')\n",
    "    df['rating'] = df['rating'].apply(str).replace('1.0', '1').replace('2.0', '2')\n",
    "\n",
    "    print(f\"Throw away {(df['rating'] == 'SKIP').sum()} 'SKIP' samples\")\n",
    "    df = df[df['rating'] != 'SKIP']\n",
    "\n",
    "    old = df.copy()\n",
    "    df.loc[df['gold'] == '', 'gold'] = df.loc[df['gold'] == '']['new_text_column'].values\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "more_mmlu_he_lst = {k: [] for k in more_mmlu}\n",
    "more_mmlu_original_txt = {k: [] for k in more_mmlu}\n",
    "for k in more_mmlu:\n",
    "    more_mmlu[k] = clean(more_mmlu[k])\n",
    "    for _, row in more_mmlu[k].iterrows():\n",
    "        d = query_to_sample(row['gold'])\n",
    "        more_mmlu_he_lst[k].append({\n",
    "            'query': d['question'],\n",
    "            'choices': [d[f'choice_{i}'] for i in ['a', 'b', 'c', 'd']],\n",
    "        })\n",
    "\n",
    "        more_mmlu_original_txt[k].append(row['text_column'])\n",
    "\n",
    "for k in more_mmlu:\n",
    "    print(k, more_mmlu[k].shape, len(more_mmlu_original_txt[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6d54d0-261d-4e46-8a89-ae66d2311513",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_LABEL_TO_ANSWER_INDEX = {\n",
    "    'A': 0,\n",
    "    'B': 1,\n",
    "    'C': 2,\n",
    "    'D': 3,\n",
    "    '1': 0,\n",
    "    '2': 1,\n",
    "    '3': 2,\n",
    "    '4': 3,\n",
    "    0: 0,\n",
    "    1: 1,\n",
    "    2: 2,\n",
    "    3: 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e9f9e-559c-465b-8bfa-cd6152960cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_indcs = {}\n",
    "cnt = 0\n",
    "# The mmlu test file contains also 22 samples from the val....\n",
    "for i in range(len(mmlu_he_lst)):  # len(mmlu_he_lst)):\n",
    "    while dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_test'][cnt])) != mmlu_original_txt[i]:\n",
    "        cnt += 1\n",
    "        if cnt >= mmlu_en['mmlu_test'].num_rows:\n",
    "            break\n",
    "    if cnt >= mmlu_en['mmlu_test'].num_rows:\n",
    "        break\n",
    "    map_indcs[i] = cnt\n",
    "\n",
    "start_again_from = i\n",
    "print(start_again_from)\n",
    "\n",
    "map_indcs_val = {}\n",
    "cnt = 0\n",
    "for i in range(start_again_from, len(mmlu_he_lst)):\n",
    "    while dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_val'][cnt])) != mmlu_original_txt[i]:\n",
    "        cnt += 1\n",
    "    map_indcs_val[i] = cnt\n",
    "\n",
    "print('----')\n",
    "\n",
    "more_mmlu_map_indcs = {k: {} for k in more_mmlu_he_lst}\n",
    "for k in more_mmlu_he_lst:\n",
    "    cnt = 0\n",
    "    for i in range(len(more_mmlu_he_lst[k])):\n",
    "        while dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_test'][cnt])) != more_mmlu_original_txt[k][i]:\n",
    "            cnt += 1\n",
    "        more_mmlu_map_indcs[k][i] = cnt\n",
    "\n",
    "print(len(map_indcs), len(map_indcs_val), len(mmlu_he_lst), len(map_indcs) + len(map_indcs_val))\n",
    "for k in more_mmlu_he_lst:\n",
    "    print(len(more_mmlu_he_lst[k]), len(more_mmlu_map_indcs[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72735f24-decc-445c-9f49-48075db7ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(start_again_from):\n",
    "    original_en = dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_test'][map_indcs[i]]))\n",
    "    if original_en != mmlu_original_txt[i]:\n",
    "        print('WWWWWWWWWWWWWAAAAAAAAAAAAAAAA', i)\n",
    "        break\n",
    "    new_answer = MAP_LABEL_TO_ANSWER_INDEX[mmlu_en['mmlu_test'][map_indcs[i]]['answer']]\n",
    "    mmlu_he_lst[i]['answer_index'] = new_answer\n",
    "    mmlu_he_lst[i]['from_mmlu_split'] = 'test'\n",
    "    mmlu_he_lst[i]['subject'] = mmlu_en['mmlu_test'][map_indcs[i]]['subject']\n",
    "\n",
    "for i in range(start_again_from, len(mmlu_he_lst)):\n",
    "    original_en = dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_val'][map_indcs_val[i]]))\n",
    "    if original_en != mmlu_original_txt[i]:\n",
    "        print('WWWWWWWWWWWWWAAAAAAAAAAAAAAAA', i)\n",
    "        break\n",
    "    new_answer = MAP_LABEL_TO_ANSWER_INDEX[mmlu_en['mmlu_val'][map_indcs_val[i]]['answer']]\n",
    "    mmlu_he_lst[i]['answer_index'] = new_answer\n",
    "    mmlu_he_lst[i]['from_mmlu_split'] = 'validation'\n",
    "    mmlu_he_lst[i]['subject'] = mmlu_en['mmlu_val'][map_indcs_val[i]]['subject']\n",
    "\n",
    "for k in more_mmlu_he_lst:\n",
    "    for i in range(len(more_mmlu_he_lst[k])):\n",
    "        original_en = dict_to_prompt(mmlu.mmlu_sample_to_dict(mmlu_en['mmlu_test'][more_mmlu_map_indcs[k][i]]))\n",
    "        if original_en != more_mmlu_original_txt[k][i]:\n",
    "            print('WWWWWWWWWWWWWAAAAAAAAAAAAAAAA', i)\n",
    "            break\n",
    "        new_answer = MAP_LABEL_TO_ANSWER_INDEX[mmlu_en['mmlu_test'][more_mmlu_map_indcs[k][i]]['answer']]\n",
    "        more_mmlu_he_lst[k][i]['answer_index'] = new_answer\n",
    "        more_mmlu_he_lst[k][i]['from_mmlu_split'] = 'test'\n",
    "        more_mmlu_he_lst[k][i]['subject'] = mmlu_en['mmlu_test'][more_mmlu_map_indcs[k][i]]['subject']\n",
    "\n",
    "print(len(mmlu_he_lst))\n",
    "for k in more_mmlu_he_lst:\n",
    "    print(len(more_mmlu_he_lst[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35a24f-df8d-4442-bc19-1ba3d5845246",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb51a00-0408-4724-83d2-cdd93d75745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"final_hebrew_bnch/MMLU_heb.jsonl\"\n",
    "\n",
    "# Open the file and write each dictionary as a new line\n",
    "with open(output_filename, 'w') as f:\n",
    "    for item in mmlu_he_lst:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "    for k in more_mmlu_he_lst:\n",
    "        for item in more_mmlu_he_lst[k]:\n",
    "            # Convert dict to a JSON string and add a newline character\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af205d74-f0b5-42d8-859e-56218a89e127",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b0ab97-118f-4ed9-b696-b2cb6142eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the file in chunks of 1000 lines at a time\n",
    "chunk_iterator = pd.read_json(output_filename, lines=True, chunksize=1000)\n",
    "\n",
    "for chunk in chunk_iterator:\n",
    "    mmlu_df = chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce21ffb-a38b-4db3-a867-586c2ac39201",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu_df['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb903c-e80d-4c3a-b255-beb046e43db0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HellaSwag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd7d5a-e2fc-406e-b6d4-fb527843b1f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hellaswag_en = hellaswag.get_hellaswag_datasets()\n",
    "hellaswag_en = hellaswag_en['hellaswag_val'].select(range(0, 1_000, 30))\n",
    "hellaswag_en = hellaswag_en.take(20)\n",
    "hellaswag_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceafac7b-8392-4b90-8b82-9832f388e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "hellaswag_labels = pd.read_csv('compare_csv/hellaswag/hellaswag_test_20_samples.csv')\n",
    "\n",
    "hellaswag_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfd672-24e1-479f-9ae2-4360d051c16b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hellaswag_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323cc704-8d0c-4008-ad87-c6431967dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_to_sample(hellaswag_labels.loc[0, 'gemini'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae9259-e1f7-4803-9e6f-14122f8088a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hellaswag_he_lst = []\n",
    "for cnt, row in hellaswag_labels.iterrows():\n",
    "    d = query_to_sample(row['gemini'])\n",
    "    hellaswag_he_lst.append({\n",
    "        'query': d['ctx'],\n",
    "        'choices': [d[f'ending {i}'] for i in ['1', '2', '3', '4']],\n",
    "        'answer_index': row['answer_label']\n",
    "    })\n",
    "\n",
    "len(hellaswag_he_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29454b95-177b-4422-bbb5-1406f6226da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hellaswag_he_lst[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752ed0b-f433-4f2c-aedb-692174637245",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddfe157-360a-44d0-9967-b5185dd017e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"final_hebrew_bnch/hellaswag_20_samples.jsonl\"\n",
    "\n",
    "# Open the file and write each dictionary as a new line\n",
    "with open(output_filename, 'w') as f:\n",
    "    for item in hellaswag_he_lst:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved data to {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd74e0-e9dd-4496-8057-e7f142c8aa20",
   "metadata": {},
   "source": [
    "# COPA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51644719-9eda-4e84-aad7-b6b9547cd2be",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "copa_en = copa.get_copa_datasets()\n",
    "copa_en = copa_en['copa_val'].select(range(0, 1_000, 30))\n",
    "copa_en = copa_en.take(20)\n",
    "copa_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef774e-39c1-4205-a0a7-85ea5ca58c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_labels_1 = pd.read_csv('labeled_files/copa_TRAIN_gradio.csv')\n",
    "copa_labels_2 = pd.read_csv('labeled_files/copa_TEST_gradio.csv')\n",
    "copa_labels_1 = copa_labels_1.fillna('')\n",
    "copa_labels_2 = copa_labels_2.fillna('')\n",
    "\n",
    "copa_labels_1['from_copa_split'] = 'train'\n",
    "copa_labels_2['from_copa_split'] = 'test'\n",
    "\n",
    "copa_labels_1.shape, copa_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a3e90-febb-4ab2-9719-a63dcc76c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "(copa_labels_1['rating'] == 'SKIP').argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d089a986-c104-4f99-8e5a-6dea3713d08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be True\n",
    "print((copa_labels_1['text_column'].iloc[500:515] == copa_labels_2['text_column'].iloc[0:15].values).all())\n",
    "print((copa_labels_1['text_column'].iloc[515:] == copa_labels_2['text_column'].iloc[250:265].values).all())\n",
    "print((copa_labels_1['text_column'].iloc[0:15] == copa_labels_2['text_column'].iloc[500:515].values).all())\n",
    "print((copa_labels_1['text_column'].iloc[250:265] == copa_labels_2['text_column'].iloc[515:].values).all())\n",
    "\n",
    "copa_labels_1 = copa_labels_1.iloc[15:500]\n",
    "copa_labels_2 = copa_labels_2.iloc[:515]\n",
    "\n",
    "copa_labels_1.shape, copa_labels_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baacbb7-afc8-4557-99f3-523c2c359895",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_labels_1.merge(copa_labels_2, on='text_column').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0602b-226c-40d2-be28-c33dd83a77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_labels = pd.concat([copa_labels_1, copa_labels_2], ignore_index=True)\n",
    "copa_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09082e27-db40-4d7c-b4f3-cee03f48eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = df.fillna('')\n",
    "    df['rating'] = df['rating'].apply(str).replace('1.0', '1').replace('2.0', '2')\n",
    "\n",
    "    print(f\"Throw away {(df['rating'] == 'SKIP').sum()} 'SKIP' samples\")\n",
    "    df = df[df['rating'] != 'SKIP']\n",
    "\n",
    "    old = df.copy()\n",
    "    df.loc[df['gold'] == '', 'gold'] = df.loc[df['gold'] == '']['new_text_column'].values\n",
    "\n",
    "    return df\n",
    "\n",
    "copa_labels = clean(copa_labels)\n",
    "copa_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49441b4-3fd7-4d7b-8488-89caf5e748f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_he_lst = []\n",
    "for cnt, row in copa_labels.iterrows():\n",
    "    d = query_to_sample(row['gold'])\n",
    "    copa_he_lst.append({\n",
    "        'query': d['premise'],\n",
    "        'choices': [d[f'choice{i}'] for i in ['1', '2']],\n",
    "        'answer_index': row['answer_label'],\n",
    "        'from_copa_split': row['from_copa_split'],\n",
    "    })\n",
    "\n",
    "len(copa_he_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77347d8-05c5-4268-86b2-20da7cd435be",
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_he_lst[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726086f9-dd2a-4dbe-a937-e48644f50eac",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9413d0f-5e46-4cdf-a409-9fbcf3c15e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = \"final_hebrew_bnch/copa_heb.jsonl\"\n",
    "\n",
    "# Open the file and write each dictionary as a new line\n",
    "with open(output_filename, 'w') as f:\n",
    "    for item in copa_he_lst:\n",
    "        # Convert dict to a JSON string and add a newline character\n",
    "        f.write(json.dumps(item) + '\\n')\n",
    "\n",
    "print(f\"Successfully saved data to {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
