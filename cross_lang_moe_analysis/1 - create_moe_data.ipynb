{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ade609c-484f-43f3-abd2-19977a1fe71d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3557db-7c0a-482f-98a6-0d91537d5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e90841-ab91-41f7-b48f-60585b59725d",
   "metadata": {},
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d042e0-312d-4bd2-8cc7-dd29b6dbd638",
   "metadata": {},
   "source": [
    "## Read relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eac60c-f71d-4656-9fa0-f8ecfbab78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_name):\n",
    "    data = []\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                # Parse each line as a JSON object\n",
    "                json_object = json.loads(line)\n",
    "                data.append(json_object)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON on line: {line.strip()}. Error: {e}\")\n",
    "    return data\n",
    "\n",
    "def clean_copa(x):\n",
    "    if x.startswith('Cause:\\n\\n'):\n",
    "        return x[len('Cause:\\n\\n'):]\n",
    "    elif x.startswith('Effect:\\n\\n'):\n",
    "        return x[len('Effect:\\n\\n'):]\n",
    "    return x\n",
    "\n",
    "def into_arc(row):\n",
    "    return '<question>' + row['qwery'] + '</question>\\n' + '\\n'.join([f'<option {i + 1}>{row[\"choices\"][i]}</option {i + 1}>' for i in range(4)])\n",
    "\n",
    "def into_mmlu(row):\n",
    "    letters = ['a', 'b', 'c', 'd']\n",
    "    return '<question>' + row['qwery'] + '</question>\\n' + '\\n'.join([f'<choice_{letters[i]}>{row[\"choices\"][i]}</choice_{letters[i]}>' for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f65b15-451b-4b9d-9ba9-25255624488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/home/ec2-user/SageMaker/qwen-hebrew-finetuning - translation/translation/'\n",
    "use_files = {\n",
    "    'arc': prefix + 'labeled_files/arc_ai_TEST_labeled_gradio.csv',\n",
    "    'gsm': prefix + 'labeled_files/gsm_TEST_labeled_gradio.csv',\n",
    "    'mmlu': prefix + 'labeled_files/mmlu_main_sub_TEST_labeled_gradio.csv',\n",
    "    'copa': prefix + 'labeled_files/copa_TRAIN_gradio.csv',\n",
    "}\n",
    "\n",
    "hebrew_final = {\n",
    "    'arc': prefix + 'final_hebrew_bnch/arc_ai2_chall_heb.jsonl',\n",
    "    'mmlu': prefix + 'final_hebrew_bnch/MMLU_heb_2.jsonl',\n",
    "}\n",
    "\n",
    "for k in use_files:\n",
    "    use_files[k] = pd.read_csv(use_files[k]).fillna('')\n",
    "    use_files[k] = use_files[k][use_files[k]['rating'] != 'SKIP']\n",
    "    use_files[k] = use_files[k].iloc[np.linspace(0, use_files[k].shape[0] - 1, 500, dtype='int')]\n",
    "    use_files[k] = use_files[k].drop_duplicates()\n",
    "    use_files[k].loc[use_files[k]['gold'] == '', 'gold'] = use_files[k].loc[use_files[k]['gold'] == '']['new_text_column']\n",
    "\n",
    "    print(use_files[k].shape, k)\n",
    "\n",
    "hebrew_final['arc'] = pd.DataFrame(read_jsonl(hebrew_final['arc']))\n",
    "hebrew_final['arc']['gold'] = hebrew_final['arc'].apply(into_arc, axis=1)\n",
    "hebrew_final['mmlu'] = pd.DataFrame(read_jsonl(hebrew_final['mmlu']))\n",
    "hebrew_final['mmlu']['gold'] = hebrew_final['mmlu'].apply(into_mmlu, axis=1)\n",
    "\n",
    "for k in ['arc', 'mmlu']:\n",
    "    use_files[k] = use_files[k].merge(hebrew_final[k], on='gold')\n",
    "    use_files[k] = use_files[k][['text_column', 'gold', 'answer_index']].rename({\n",
    "        'text_column': 'Eng',\n",
    "        'gold': 'Heb',\n",
    "        'answer_index': 'label',\n",
    "    }, axis=1)\n",
    "\n",
    "use_files['copa']['text_column'] = use_files['copa']['text_column'].apply(clean_copa)\n",
    "use_files['copa'] = use_files['copa'][['text_column', 'gold', 'answer_label']].rename({\n",
    "    'text_column': 'Eng',\n",
    "    'gold': 'Heb',\n",
    "    'answer_label': 'label',\n",
    "}, axis=1)\n",
    "\n",
    "use_files['gsm'] = use_files['gsm'][['text_column', 'gold']].rename({\n",
    "    'text_column': 'Eng',\n",
    "    'gold': 'Heb',\n",
    "}, axis=1)\n",
    "\n",
    "print([(k, use_files[k].shape) for k in use_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc4875-2776-4808-ab02-4a4015c9af6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def into_final_text_arc(row):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches_en = re.findall(pattern, row['Eng'], re.DOTALL)\n",
    "    sample_en = {key: value.strip() for key, value in matches_en}\n",
    "    matches_he = re.findall(pattern, row['Heb'], re.DOTALL)\n",
    "    sample_he = {key: value.strip() for key, value in matches_he}\n",
    "\n",
    "    eng = sample_en['question'] + '\\n' + sample_en[f'option {row[\"label\"] + 1}']\n",
    "    heb = sample_he['question'] + '\\n' + sample_he[f'option {row[\"label\"] + 1}']\n",
    "    return (eng, heb)\n",
    "\n",
    "\n",
    "def into_final_text_mmlu(row):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches_en = re.findall(pattern, row['Eng'], re.DOTALL)\n",
    "    sample_en = {key: value.strip() for key, value in matches_en}\n",
    "    matches_he = re.findall(pattern, row['Heb'], re.DOTALL)\n",
    "    sample_he = {key: value.strip() for key, value in matches_he}\n",
    "\n",
    "    labels_map = ['a', 'b', 'c', 'd']\n",
    "    \n",
    "    eng = sample_en['question'] + '\\n' + sample_en[f'choice_{labels_map[row[\"label\"]]}']\n",
    "    heb = sample_he['question'] + '\\n' + sample_he[f'choice_{labels_map[row[\"label\"]]}']\n",
    "    return (eng, heb)\n",
    "\n",
    "\n",
    "def into_final_text_copa(row):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches_en = re.findall(pattern, row['Eng'], re.DOTALL)\n",
    "    sample_en = {key: value.strip() for key, value in matches_en}\n",
    "    matches_he = re.findall(pattern, row['Heb'], re.DOTALL)\n",
    "    sample_he = {key: value.strip() for key, value in matches_he}\n",
    "    \n",
    "    eng = sample_en['premise'] + '\\n' + sample_en[f'choice{row[\"label\"] + 1}']\n",
    "    heb = sample_he['premise'] + '\\n' + sample_he[f'choice{row[\"label\"] + 1}']\n",
    "    return (eng, heb)\n",
    "\n",
    "def into_final_text_gsm(row):\n",
    "    pattern = r\"<(?!response_format\\b)([^>]+)>(.*?)</\\1>\"\n",
    "    matches_en = re.findall(pattern, row['Eng'], re.DOTALL)\n",
    "    sample_en = {key: value.strip() for key, value in matches_en}\n",
    "    matches_he = re.findall(pattern, row['Heb'], re.DOTALL)\n",
    "    sample_he = {key: value.strip() for key, value in matches_he}\n",
    "    \n",
    "    eng = sample_en['question'] + '\\n' + sample_en['answer']\n",
    "    heb = sample_he['question'] + '\\n' + sample_he['answer']\n",
    "    return (eng, heb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6925e0-40c6-45f5-afee-bfd6289a52c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "use_files['arc'][['en_prompt', 'he_prompt']] = use_files['arc'].apply(into_final_text_arc, result_type='expand', axis=1)\n",
    "use_files['mmlu'][['en_prompt', 'he_prompt']] = use_files['mmlu'].apply(into_final_text_mmlu, result_type='expand', axis=1)\n",
    "use_files['copa'][['en_prompt', 'he_prompt']] = use_files['copa'].apply(into_final_text_copa, result_type='expand', axis=1)\n",
    "use_files['gsm'][['en_prompt', 'he_prompt']] = use_files['gsm'].apply(into_final_text_gsm, result_type='expand', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c7568-7f39-4691-8969-c40c8dc6f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(k, use_files[k].shape) for k in use_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7cb22f-a3d9-4273-809f-1d2bd9e0f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in use_files:\n",
    "    use_files[k].to_csv(f'moe_analysis_data/{k}_en_he_500.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26b513-a91b-49ca-b6c2-1d5f85517a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in use_files:\n",
    "    print(k)\n",
    "    display(use_files[k][['en_prompt', 'he_prompt']].map(lambda x: x.split(' ')).map(len).mean(axis=0))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66c048c2-6058-4f75-8e35-75575ceebd8e",
   "metadata": {},
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "76f30a9a-ea3f-4a2a-acd6-06d7b07ee57b",
   "metadata": {},
   "source": [
    "model_name = \"Qwen/Qwen3-30B-A3B-Base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88fac5ee-e493-4978-847d-af39f47b9b6b",
   "metadata": {},
   "source": [
    "prompt = use_files['arc']['en_prompt'].iloc[1]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "66cc39c0-e0b6-44a1-b433-2f0f117537d0",
   "metadata": {},
   "source": [
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "model_inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df829d3b-8fe7-42b8-9649-084b7ebaa180",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in use_files:\n",
    "    print(k)\n",
    "    print(use_files[k].iloc[0]['en_prompt'])\n",
    "    print(use_files[k].iloc[0]['he_prompt'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c8e34d-2422-4215-a224-f374426d6db8",
   "metadata": {},
   "source": [
    "## Find more data on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28302ccd-bbbe-41dd-848f-867c8a180222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset in streaming mode to avoid downloading everything\n",
    "streamed_dataset = load_dataset(\n",
    "    \"HebArabNlpProject/HebNLI\",\n",
    "    split=\"train\",  # Specify the split you want, e.g., 'train'\n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "# 2. Define a function to filter examples on the fly\n",
    "def filter_long_sentences(example):\n",
    "    # Keep the example only if 'sentence1' is longer than 500 chars\n",
    "    return len(example['sentence1']) > 450\n",
    "\n",
    "# 3. Apply the filter to the stream\n",
    "filtered_stream = streamed_dataset.filter(filter_long_sentences)\n",
    "\n",
    "# 4. Take the first 500 examples that pass the filter\n",
    "final_dataset_iterator = filtered_stream.take(500)\n",
    "\n",
    "# Convert the final iterator to a list to use the data\n",
    "# This step will process the stream until 500 examples are found\n",
    "final_examples = Dataset.from_list(list(final_dataset_iterator))\n",
    "\n",
    "final_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e8cc8-27a8-4feb-ba7a-2fd119807899",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_df = pd.DataFrame(final_examples)[['sentence1', 'translation1']]\n",
    "nli_df.columns = ['en_prompt', 'he_prompt']\n",
    "print(nli_df.shape)\n",
    "nli_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b04a9ae-6a60-48bc-8fe0-a0ef70fff039",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_df.to_csv('moe_analysis_data/nli_en_he_460.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d1d26f-37d0-4552-a35d-8547cf9e4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_df.map(lambda x: len(x.split())).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98486e91-ff21-444c-abf2-0509119f5eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_examples[0]['sentence1'])\n",
    "print()\n",
    "print(final_examples[0]['translation1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7358a-421a-40c1-ba63-e6ca3e055c4e",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9a2d6-c901-4fb7-b1d1-5acaa2fea294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "out = []\n",
    "buffer_en, buffer_he = [], []\n",
    "\n",
    "length = 250\n",
    "\n",
    "def flush_chunk():\n",
    "    \"\"\"If buffer has >=300 words, add to output and reset.\"\"\"\n",
    "    global buffer_en, buffer_he\n",
    "    en_text = \" \".join(buffer_en).strip()\n",
    "    he_text = \" \".join(buffer_he).strip()\n",
    "    if len(en_text.split()) >= length and len(he_text.split()) >= length:\n",
    "        out.append({\"en_prompt\": en_text, \"he_prompt\": he_text,\n",
    "                    \"en_words\": len(en_text.split()),\n",
    "                    \"he_words\": len(he_text.split())})\n",
    "    buffer_en, buffer_he = [], []\n",
    "\n",
    "# paths to your downloaded files\n",
    "for en_file, he_file in [\n",
    "    (\n",
    "        \"moe_analysis_data/NeuLab-TedTalks.en-he.en\", \"moe_analysis_data/NeuLab-TedTalks.en-he.he\"\n",
    "    ), (\n",
    "        \"moe_analysis_data/TED2020.en-he.en\", \"moe_analysis_data/TED2020.en-he.he\"\n",
    "    )]:\n",
    "\n",
    "    with open(en_file, encoding=\"utf-8\") as f_en, open(he_file, encoding=\"utf-8\") as f_he:\n",
    "        for en_line, he_line in zip(f_en, f_he):\n",
    "            en_line, he_line = en_line.strip(), he_line.strip()\n",
    "            if not en_line or not he_line:\n",
    "                continue\n",
    "            buffer_en.append(en_line)\n",
    "            buffer_he.append(he_line)\n",
    "            # check length and flush if long enough\n",
    "            if len(\" \".join(buffer_en).split()) >= length:\n",
    "                flush_chunk()\n",
    "\n",
    "# flush remaining sentences\n",
    "flush_chunk()\n",
    "\n",
    "print(f\"Built {len(out)} parallel samples (â‰¥{length} words each).\")\n",
    "\n",
    "df = pd.DataFrame(out)\n",
    "print(df.shape)   # (rows, columns)\n",
    "display(df.head())\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(\"moe_analysis_data/ted_he_en_chunks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc29a4-381a-4a66-b59f-9131ff2b6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "((df['en_words'] >= 300) & (df['he_words'] >= 300)).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
