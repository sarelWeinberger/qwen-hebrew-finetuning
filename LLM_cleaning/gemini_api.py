#!/usr/bin/env python3
"""
Gepeta Project - Geektime Files Processor
×¢×™×‘×•×“ ×§×‘×¦×™ Geektime ×¢× Google Gemma API

Usage:
1. pip install google-generativeai boto3 pandas python-dotenv
2. ×”×’×“×¨ GOOGLE_API_KEY ×•-AWS credentials
3. python geektime_processor.py
"""

import google.generativeai as genai
import boto3
import pandas as pd
from io import StringIO
import time
import os
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv
import json

# =============================================================================
# ×”×’×“×¨×•×ª
# =============================================================================

load_dotenv()

# API Keys
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY_SANDBOX_2", "YOUR_API_KEY_HERE")

# S3 Settings
SOURCE_BUCKET = "gepeta-datasets"
SOURCE_PREFIX = "partly-processed/regex-and-dedup"
TARGET_BUCKET = "gepeta-datasets"
TARGET_PREFIX = "processed/"

# Processing Settings
PREFIX_FILTER = "Geektime"  # ×”×§×™×“×•××ª ×©×× ×—× ×• ××¢×‘×“×™× (× ×™×ª×Ÿ ×œ×©×™× ×•×™)
MAX_WORKERS = 10  # ××¡×¤×¨ threads ××§×‘×™×œ×™× (×”×’×“×¨×” ××™×˜×‘×™×ª ×©××¦×× ×•)
BATCH_SIZE = 50  # ×’×•×“×œ ×‘××¦' ×œ×¢×™×‘×•×“
TEST_LIMIT = 100  # ××¡×¤×¨ ×§×‘×¦×™× ×œ×‘×“×™×§×” (None ×œ×›×œ ×”×§×‘×¦×™×)


class GeektimeProcessor:
    """××¢×‘×“ ×§×‘×¦×™ Geektime ×¢× Google API"""

    def __init__(self, api_key):
        """××ª×—×•×œ ×”××¢×‘×“"""
        if api_key == "YOUR_API_KEY_HERE":
            raise ValueError("âŒ ×¢×“×›×Ÿ ××ª GOOGLE_API_KEY!")

        # Google AI Setup
        genai.configure(api_key=api_key)
        #self.model_name = 'gemma-3-27b-it'
        self.model_name = 'gemini-1.5-flash'

        # S3 Setup
        self.s3_client = boto3.client('s3')

        # Statistics
        self.stats = {
            'files_processed': 0,
            'texts_processed': 0,
            'total_time': 0,
            'errors': [],
            'start_time': datetime.now()
        }

        print("ğŸš€ Gepeta Generic Prefix Processor ××•×›×Ÿ")
        print(f"ğŸ“ ××§×•×¨: s3://{SOURCE_BUCKET}/{SOURCE_PREFIX}")
        print(f"ğŸ¯ ×™×¢×“: s3://{TARGET_BUCKET}/{TARGET_PREFIX}{PREFIX_FILTER.lower()}/")
        print(f"ğŸ” ×§×™×“×•××ª: {PREFIX_FILTER}")
        print(f"ğŸ‘¥ Workers: {MAX_WORKERS}")
        print(f"â° ×”×ª×—×œ×”: {self.stats['start_time'].strftime('%H:%M:%S')}")

    def list_geektime_files(self, limit=None):
        """××¦×™××ª ×›×œ ×§×‘×¦×™ Geektime"""
        print(f"ğŸ” ××—×¤×© ×§×‘×¦×™ {PREFIX_FILTER}...")

        files = []
        paginator = self.s3_client.get_paginator('list_objects_v2')

        page_count = 0
        for page in paginator.paginate(Bucket=SOURCE_BUCKET, Prefix=SOURCE_PREFIX):
            page_count += 1
            print(f"  ×¡×•×¨×§ ×“×£ {page_count}...")

            if 'Contents' not in page:
                continue

            page_files = [
                obj['Key'] for obj in page['Contents']
                if obj['Key'].endswith('.csv')
                   and PREFIX_FILTER in os.path.basename(obj['Key'])
                   and obj['Size'] > 0
            ]

            files.extend(page_files)
            print(f"  ×“×£ {page_count}: × ××¦××• {len(page_files)} ×§×‘×¦×™ {PREFIX_FILTER}")

            # ×”×’×‘×œ×” ×œ×‘×“×™×§×”
            if limit and len(files) >= limit:
                files = files[:limit]
                break

        print(f"âœ… × ××¦××• {len(files)} ×§×‘×¦×™ {PREFIX_FILTER} ×›×•×œ×œ")
        return files

    def read_csv_from_s3(self, bucket, key):
        """×§×¨×™××ª CSV ×-S3"""
        try:
            response = self.s3_client.get_object(Bucket=bucket, Key=key)
            content = response['Body'].read().decode('utf-8')
            df = pd.read_csv(StringIO(content))
            return df
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×§×¨×™××ª {key}: {e}")
            return None

    def save_csv_to_s3(self, df, bucket, key):
        """×©××™×¨×ª CSV ×œ-S3"""
        try:
            csv_buffer = StringIO()
            df.to_csv(csv_buffer, index=False, encoding='utf-8')

            self.s3_client.put_object(
                Bucket=bucket,
                Key=key,
                Body=csv_buffer.getvalue(),
                ContentType='text/csv'
            )
            return True
        except Exception as e:
            print(f"âŒ ×©×’×™××” ×‘×©××™×¨×ª {key}: {e}")
            return False

    def clean_text_with_api(self, text):
        """× ×™×§×•×™ ×˜×§×¡×˜ ×™×—×™×“ ×¢× Google API"""
        model = genai.GenerativeModel(self.model_name)

        prompt = f"""× ×§×” ××ª ×”×˜×§×¡×˜ ×”×¢×‘×¨×™ ×”×‘× ××¤×’××™ ×§×™×“×•×“, ×ª×’×™×•×ª HTML, ×¤×¨×¡×•××•×ª ×•×ª×‘× ×™×•×ª. ×”×—×–×¨ ×¨×§ ×˜×§×¡×˜ × ×§×™ ×‘×¢×‘×¨×™×ª:

{text[:800]}

×˜×§×¡×˜ × ×§×™:"""

        try:
            response = model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            return f"[API_ERROR] {str(e)}"

    def process_texts_parallel(self, texts):
        """×¢×™×‘×•×“ ××§×‘×™×œ×™ ×©×œ ×¨×©×™××ª ×˜×§×¡×˜×™×"""
        results = [''] * len(texts)  # ×©××™×¨×ª ×¡×“×¨

        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # ×©×œ×™×—×ª ×‘×§×©×•×ª ×¢× index
            future_to_index = {
                executor.submit(self.clean_text_with_api, text): i
                for i, text in enumerate(texts)
            }

            # ××™×¡×•×£ ×ª×•×¦××•×ª
            for future in as_completed(future_to_index):
                index = future_to_index[future]
                try:
                    result = future.result()
                    results[index] = result
                except Exception as e:
                    results[index] = f"[ERROR] {str(e)}"

        return results

    def process_single_file(self, file_key):
        """×¢×™×‘×•×“ ×§×•×‘×¥ ×™×—×™×“"""
        file_name = os.path.basename(file_key)
        print(f"\nğŸ“ ××¢×‘×“: {file_name}")

        file_start_time = time.time()

        # ×§×¨×™××ª ×§×•×‘×¥
        df = self.read_csv_from_s3(SOURCE_BUCKET, file_key)
        if df is None:
            self.stats['errors'].append(f"×œ× ×”×¦×œ×™×— ×œ×§×¨×•×: {file_name}")
            return False

        print(f"ğŸ“Š × ×˜×¢×Ÿ: {len(df)} ×©×•×¨×•×ª")

        # ×‘×“×™×§×ª ×¢××•×“×ª text
        if 'text' not in df.columns:
            print(f"âŒ ××™×Ÿ ×¢××•×“×ª 'text' ×‘-{file_name}")
            self.stats['errors'].append(f"××™×Ÿ ×¢××•×“×ª text: {file_name}")
            return False

        # ×”×›× ×ª ×˜×§×¡×˜×™× ×œ×¢×™×‘×•×“
        texts = df['text'].dropna().tolist()
        if not texts:
            print(f"âš ï¸ ××™×Ÿ ×˜×§×¡×˜×™× ×‘-{file_name}")
            return False

        print(f"ğŸ”„ ××¢×‘×“ {len(texts)} ×˜×§×¡×˜×™× ×‘×‘××¦'×™×...")

        # ×¢×™×‘×•×“ ×‘×‘××¦'×™×
        all_cleaned_texts = []
        total_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE

        for batch_idx in range(0, len(texts), BATCH_SIZE):
            batch_num = (batch_idx // BATCH_SIZE) + 1
            batch = texts[batch_idx:batch_idx + BATCH_SIZE]

            print(f"  ğŸ“¦ ×‘××¦' {batch_num}/{total_batches} ({len(batch)} ×˜×§×¡×˜×™×)")

            batch_start = time.time()
            cleaned_batch = self.process_texts_parallel(batch)
            batch_time = time.time() - batch_start

            all_cleaned_texts.extend(cleaned_batch)

            print(f"  âœ… ×”×•×©×œ×: {batch_time:.1f}s ({batch_time / len(batch):.2f}s/text)")

            # ×”××ª× ×” ×§×˜× ×” ×œ×× ×™×¢×ª rate limiting
            if batch_num < total_batches:
                time.sleep(0.5)

        # ×™×¦×™×¨×ª DataFrame ×¢× ×ª×•×¦××•×ª
        df_result = df.copy()
        df_result['cleaned_text'] = all_cleaned_texts[:len(df)]

        # ×©××™×¨×” ×œ-S3
        target_key = f"{TARGET_PREFIX}{PREFIX_FILTER.lower()}/{file_name}"
        success = self.save_csv_to_s3(df_result, TARGET_BUCKET, target_key)

        file_time = time.time() - file_start_time

        if success:
            print(f"âœ… × ×©××¨: s3://{TARGET_BUCKET}/{target_key}")
            print(f"â° ×–××Ÿ ×§×•×‘×¥: {file_time / 60:.1f} ×“×§×•×ª")

            # ×¢×“×›×•×Ÿ ×¡×˜×˜×™×¡×˜×™×§×•×ª
            self.stats['files_processed'] += 1
            self.stats['texts_processed'] += len(texts)
            self.stats['total_time'] += file_time

            return True
        else:
            self.stats['errors'].append(f"×©×’×™××” ×‘×©××™×¨×ª: {file_name}")
            return False

    def print_progress(self, current, total, start_time):
        """×”×“×¤×¡×ª ×”×ª×§×“××•×ª"""
        elapsed = time.time() - start_time
        if current > 0:
            avg_time_per_file = elapsed / current
            estimated_remaining = (total - current) * avg_time_per_file

            print(f"ğŸ“Š ×”×ª×§×“××•×ª: {current}/{total} ({current / total * 100:.1f}%)")
            print(f"â° ×–××Ÿ ×©×—×œ×£: {elapsed / 60:.1f} ×“×§×•×ª")
            print(f"ğŸ”® ×–××Ÿ ××©×•×¢×¨ ×œ×¡×™×•×: {estimated_remaining / 60:.1f} ×“×§×•×ª")
            print(f"ğŸ“ˆ ×§×¦×‘: {self.stats['texts_processed'] / elapsed:.1f} ×˜×§×¡×˜×™×/×©× ×™×™×”")

    def print_final_stats(self):
        """×”×“×¤×¡×ª ×¡×˜×˜×™×¡×˜×™×§×•×ª ×¡×•×¤×™×•×ª"""
        total_time = time.time() - self.stats['start_time'].timestamp()

        print(f"\n{'=' * 60}")
        print("ğŸ“Š ×¡×™×›×•× ×¢×™×‘×•×“ Geektime")
        print("=" * 60)
        print(f"âœ… ×§×‘×¦×™× ××¢×•×‘×“×™×: {self.stats['files_processed']}")
        print(f"ğŸ“ ×˜×§×¡×˜×™× ××¢×•×‘×“×™×: {self.stats['texts_processed']:,}")
        print(f"â° ×–××Ÿ ×›×•×œ×œ: {total_time / 60:.1f} ×“×§×•×ª")

        if self.stats['texts_processed'] > 0:
            avg_time = total_time / self.stats['texts_processed']
            print(f"âš¡ ×–××Ÿ ×××•×¦×¢ ×œ×˜×§×¡×˜: {avg_time:.2f} ×©× ×™×•×ª")
            print(f"ğŸš€ ×§×¦×‘ ×¢×™×‘×•×“: {self.stats['texts_processed'] / total_time:.1f} ×˜×§×¡×˜×™×/×©× ×™×™×”")

        if self.stats['errors']:
            print(f"\nâŒ ×©×’×™××•×ª ({len(self.stats['errors'])}):")
            for error in self.stats['errors'][:5]:  # ×¨×§ 5 ×¨××©×•× ×•×ª
                print(f"  â€¢ {error}")
            if len(self.stats['errors']) > 5:
                print(f"  ... ×•×¢×•×“ {len(self.stats['errors']) - 5} ×©×’×™××•×ª")

        print(f"\nğŸ’¾ ×§×‘×¦×™× × ×©××¨×• ×‘: s3://{TARGET_BUCKET}/{TARGET_PREFIX}{PREFIX_FILTER.lower()}/")

    def run_processing(self, test_mode=True):
        """×”×¨×¦×ª ×¢×™×‘×•×“ ××œ×"""
        print(f"ğŸš€ ××ª×—×™×œ ×¢×™×‘×•×“ ×§×‘×¦×™ {PREFIX_FILTER}")

        # ××¦×™××ª ×§×‘×¦×™×
        limit = TEST_LIMIT if test_mode else None
        files = self.list_geektime_files(limit)

        if not files:
            print(f"âŒ ×œ× × ××¦××• ×§×‘×¦×™ {PREFIX_FILTER}")
            return

        print(f"\nğŸ¯ ××¦×‘: {'×‘×“×™×§×”' if test_mode else '×™×™×¦×•×¨'}")
        print(f"ğŸ“ ××¡×¤×¨ ×§×‘×¦×™× ×œ×¢×™×‘×•×“: {len(files)}")

        # ××™×©×•×¨ ××©×ª××©
        if not test_mode:
            response = input(f"\nâ“ ×œ×”×ª×—×™×œ ×¢×™×‘×•×“ {len(files)} ×§×‘×¦×™×? (y/N): ")
            if response.lower() != 'y':
                print("âŒ ×¢×™×‘×•×“ ×‘×•×˜×œ")
                return

        # ×¢×™×‘×•×“ ×§×‘×¦×™×
        start_time = time.time()
        successful_files = 0

        for i, file_key in enumerate(files, 1):
            print(f"\n{'=' * 60}")
            print(f"ğŸ“ ×§×•×‘×¥ {i}/{len(files)}: {os.path.basename(file_key)}")

            success = self.process_single_file(file_key)
            if success:
                successful_files += 1

            # ×”×ª×§×“××•×ª ×›×œ 5 ×§×‘×¦×™×
            if i % 5 == 0 or i == len(files):
                self.print_progress(i, len(files), start_time)

        # ×¡×™×›×•×
        self.print_final_stats()

        print(f"\nğŸ‰ ×¢×™×‘×•×“ ×”×•×©×œ×!")
        print(f"âœ… {successful_files}/{len(files)} ×§×‘×¦×™× ×¢×•×‘×“×• ×‘×”×¦×œ×—×”")


def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    print("ğŸš€ Gepeta Geektime Processor")
    print("=" * 60)

    try:
        # ×™×¦×™×¨×ª ××¢×‘×“
        processor = GeektimeProcessor(GOOGLE_API_KEY)

        # ×‘×—×™×¨×ª ××¦×‘
        print(f"\nğŸ¯ ××¤×©×¨×•×™×•×ª:")
        print(f"1. ×‘×“×™×§×” ({TEST_LIMIT} ×§×‘×¦×™×)")
        print(f"2. ×™×™×¦×•×¨ (×›×œ ×”×§×‘×¦×™×)")

        choice = input("×‘×—×¨ (1/2): ").strip()

        if choice == "1":
            print(f"\nğŸ§ª ××ª×—×™×œ ×‘×“×™×§×” ×¢× {TEST_LIMIT} ×§×‘×¦×™×...")
            processor.run_processing(test_mode=True)
        elif choice == "2":
            print(f"\nğŸ­ ××ª×—×™×œ ×¢×™×‘×•×“ ×™×™×¦×•×¨...")
            processor.run_processing(test_mode=False)
        else:
            print("âŒ ×‘×—×™×¨×” ×œ× ×ª×§×™× ×”")
            return

    except ValueError as e:
        print(f"âŒ {e}")
        print("ğŸ’¡ ×¢×“×›×Ÿ ××ª GOOGLE_API_KEY ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥ ××• ×‘×§×•×‘×¥ .env")
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")

    print(f"\nâ° ×¡×™×•×: {datetime.now().strftime('%H:%M:%S')}")


if __name__ == "__main__":
    main()