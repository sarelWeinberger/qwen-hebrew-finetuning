{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f255c6-a8e4-4d93-b60d-11c481d8ff6b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (20.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub>=0.24.0->datasets)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, hf-xet, fsspec, dill, multiprocess, huggingface-hub, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1\n",
      "\u001b[2K  Attempting uninstall: dill╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: dill 0.4.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling dill-0.4.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/7\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled dill-0.4.090m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: multiprocess[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [dill]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:0m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m3/7\u001b[0m [dill]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [datasets]6/7\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires dill>=0.4.0, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 dill-0.3.8 fsspec-2025.3.0 hf-xet-1.1.5 huggingface-hub-0.33.2 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bb3e78a-0cb8-40bd-a3f4-3402318b915d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from gsm8k import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99cfc876-e2a2-434d-8344-fd2fcf48f6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5831e3276e334d9ba1bacf1075c382f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc0282016ec46079faf929f8687a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d8f531812a4b978587e2c1a003daf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "main/test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b24c51c6ca443f09b910aa5d64a8d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b680f2ae65594ddf9db384bc9dc2b2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data= get_gsm8k_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "203d6339-3391-4770-80ab-ddc54162d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GSM8K dataset...\n",
      "Dataset loaded successfully!\n",
      "Number of training samples: 7473\n",
      "\n",
      "Original sample:\n",
      "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How m...\n",
      "Answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether...\n",
      "\n",
      "Converted to dict:\n",
      "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How m...\n",
      "Answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether...\n",
      "\n",
      "Reconstructed sample:\n",
      "Question: Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How m...\n",
      "Answer: Natalia sold 48/2 = <<48/2=24>>24 clips in May.\n",
      "Natalia sold 48+24 = <<48+24=72>>72 clips altogether...\n",
      "\n",
      "All functions working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "print(\"Loading GSM8K dataset...\")\n",
    "datasets = get_gsm8k_datasets()\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Number of training samples: {len(datasets['gsm8k_train'])}\")\n",
    "\n",
    "# Test with a sample\n",
    "sample = datasets['gsm8k_train'][0]\n",
    "print(\"\\nOriginal sample:\")\n",
    "print(f\"Question: {sample['question'][:100]}...\")\n",
    "print(f\"Answer: {sample['answer'][:100]}...\")\n",
    "\n",
    "# Test sample_to_dict\n",
    "sample_dict = gsm8k_sample_to_dict(sample)\n",
    "print(\"\\nConverted to dict:\")\n",
    "print(f\"Question: {sample_dict['question'][:100]}...\")\n",
    "print(f\"Answer: {sample_dict['answer'][:100]}...\")\n",
    "\n",
    "# Test dict_to_sample\n",
    "reconstructed_sample = gsm8k_dict_to_sample(sample.copy(), sample_dict)\n",
    "print(\"\\nReconstructed sample:\")\n",
    "print(f\"Question: {reconstructed_sample['question'][:100]}...\")\n",
    "print(f\"Answer: {reconstructed_sample['answer'][:100]}...\")\n",
    "\n",
    "print(\"\\nAll functions working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0401de5-3a10-4d87-a2fb-45f56d78f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "from hellaswag import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffbcfb8-7459-484a-83fc-141316326e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HellaSwag dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91089513b13345448d82e8fe45f71874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518231cd6d76433f829998b952adbf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hellaswag.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9190b5b88e4cf1bbc8e2d6b229f349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for hellaswag contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/hellaswag.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974518b7cd4d496ca311c812a2b713b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b23debd4c0148769f852eb46ce5c1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267dff2c11db46a0bd83048bc72f99da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/12.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9b5b3d66184838b93b29e346ced0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/39905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ce27dbe8604232800570c28bb67c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ebd32e93d94714ab0e96cd2e72a69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of training samples: 39905\n",
      "\n",
      "Original sample:\n",
      "Activity: Removing ice from car\n",
      "Context (ctx): Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\n",
      "Context A (ctx_a): Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles.\n",
      "Context B (ctx_b): then\n",
      "Endings: [', the man adds wax to the windshield and cuts it.', ', a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.', ', the man puts on a christmas coat, knitted with netting.', ', the man continues removing the snow on his car.']\n",
      "Correct label: 3\n",
      "\n",
      "Converted to dict:\n",
      "Question: Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\n",
      "Option 1: , the man adds wax to the windshield and cuts it.\n",
      "Option 2: , a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.\n",
      "Option 3: , the man puts on a christmas coat, knitted with netting.\n",
      "Option 4: , the man continues removing the snow on his car.\n",
      "\n",
      "Reconstructed sample:\n",
      "Context: Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. then\n",
      "Endings: [', the man adds wax to the windshield and cuts it.', ', a person board a ski lift, while two men supporting the head of the person wearing winter clothes snow as the we girls sled.', ', the man puts on a christmas coat, knitted with netting.', ', the man continues removing the snow on his car.']\n",
      "Label (converted): 3\n",
      "\n",
      "==================================================\n",
      "MORE EXAMPLES:\n",
      "==================================================\n",
      "\n",
      "Example 2:\n",
      "Activity: Baking cookies\n",
      "Context: A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. the ...\n",
      "Options:\n",
      "    0: contain egg yolks and baking soda....\n",
      "    1: are then sprinkled with brown sugar....\n",
      "    2: are placed in a strainer on the counter....\n",
      "  ✓ 3: are filled with pastries and loaded into the oven....\n",
      "Correct answer: 3\n",
      "\n",
      "Example 3:\n",
      "Activity: Baking cookies\n",
      "Context: A female chef in white uniform shows a stack of baking pans in a large kitchen presenting them. The ...\n",
      "Options:\n",
      "    0: is seen moving on a board and cutting out its cont...\n",
      "    1: hits the peeled cheesecake, followed by sliced cus...\n",
      "    2: etches a shape into the inside of the baked pans....\n",
      "  ✓ 3: is used to cut cylinder shaped dough into rounds....\n",
      "Correct answer: 3\n",
      "\n",
      "Example 4:\n",
      "Activity: Baking cookies\n",
      "Context: A tray of potatoes is loaded into the oven and removed. A large tray of cake is flipped over and pla...\n",
      "Options:\n",
      "    0: is placed onto a baked potato....\n",
      "    1: , ls, and pickles are placed in the oven....\n",
      "    2: is poured into a midden....\n",
      "  ✓ 3: is prepared then it is removed from the oven by a ...\n",
      "Correct answer: 3\n",
      "\n",
      "All functions working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "print(\"Loading HellaSwag dataset...\")\n",
    "datasets = get_hellaswag_datasets()\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Number of training samples: {len(datasets['hellaswag_train'])}\")\n",
    "\n",
    "# Test with a sample\n",
    "sample = datasets['hellaswag_train'][0]\n",
    "print(\"\\nOriginal sample:\")\n",
    "print(f\"Activity: {sample['activity_label']}\")\n",
    "print(f\"Context (ctx): {sample['ctx']}\")\n",
    "print(f\"Context A (ctx_a): {sample['ctx_a']}\")\n",
    "print(f\"Context B (ctx_b): {sample['ctx_b']}\")\n",
    "print(f\"Endings: {sample['endings']}\")\n",
    "print(f\"Correct label: {sample['label']}\")\n",
    "\n",
    "# Test sample_to_dict\n",
    "sample_dict = hellaswag_sample_to_dict(sample)\n",
    "print(\"\\nConverted to dict:\")\n",
    "print(f\"Question: {sample_dict['question']}\")\n",
    "print(f\"Option 1: {sample_dict['option 1']}\")\n",
    "print(f\"Option 2: {sample_dict['option 2']}\")\n",
    "print(f\"Option 3: {sample_dict['option 3']}\")\n",
    "print(f\"Option 4: {sample_dict['option 4']}\")\n",
    "\n",
    "# Test dict_to_sample\n",
    "reconstructed_sample = hellaswag_dict_to_sample(sample.copy(), sample_dict)\n",
    "print(\"\\nReconstructed sample:\")\n",
    "print(f\"Context: {reconstructed_sample['ctx']}\")\n",
    "print(f\"Endings: {reconstructed_sample['endings']}\")\n",
    "print(f\"Label (converted): {reconstructed_sample['label']}\")\n",
    "\n",
    "# Show a few more examples to understand the format better\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MORE EXAMPLES:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    sample = datasets['hellaswag_train'][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Activity: {sample['activity_label']}\")\n",
    "    print(f\"Context: {sample['ctx'][:100]}...\")\n",
    "    print(f\"Options:\")\n",
    "    for j, ending in enumerate(sample['endings']):\n",
    "        marker = \"✓\" if j == int(sample['label']) else \" \"\n",
    "        print(f\"  {marker} {j}: {ending[:50]}...\")\n",
    "    print(f\"Correct answer: {sample['label']}\")\n",
    "\n",
    "print(\"\\nAll functions working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c35abb-79ec-4490-bf3b-030e921030fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmlu import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd19f97d-db65-4334-88c1-62fe1c706176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MMLU dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732fe35ff6a2479e98853cdf19a3e1ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd077645308545729e2b62877f1c96ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b63a244e9641dca4a0069f46ddfeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/3.50M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd496c05dee2460e8e6bae28e977e677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/408k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601165c191cf42b9a4cb6880e9ad7954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dev-00000-of-00001.parquet:   0%|          | 0.00/76.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66cc0ae24fa4a53b3d57aa8456132cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "auxiliary_train-00000-of-00001.parquet:   0%|          | 0.00/47.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb12f5f113fa41749e0f5e10381e39a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68da689e1a0442cbb22338085872559b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1531 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e98f57ef914471bb422e60bb8607d96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating dev split:   0%|          | 0/285 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03a1a0bb88e44d5864a850316f73a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating auxiliary_train split:   0%|          | 0/99842 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of dev samples: 285\n",
      "\n",
      "Original sample:\n",
      "Subject: abstract_algebra\n",
      "Question: Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\n",
      "Choices: ['0', '1', '2', '3']\n",
      "Answer: 1 (index: 1)\n",
      "Correct answer: B - 1\n",
      "\n",
      "Converted to dict:\n",
      "Question: Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\n",
      "Option 1: 0\n",
      "Option 2: 1\n",
      "Option 3: 2\n",
      "Option 4: 3\n",
      "\n",
      "Reconstructed sample:\n",
      "Question: Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\n",
      "Choices: ['0', '1', '2', '3']\n",
      "Answer (converted): 1\n",
      "\n",
      "============================================================\n",
      "EXAMPLES FROM DIFFERENT SUBJECTS:\n",
      "============================================================\n",
      "Available subjects: ['us_foreign_policy', 'machine_learning', 'professional_accounting', 'elementary_mathematics', 'global_facts', 'professional_medicine', 'high_school_macroeconomics', 'high_school_biology', 'anatomy', 'high_school_physics']...\n",
      "\n",
      "Example from US_FOREIGN_POLICY:\n",
      "Q: How did the 2008 financial crisis affect America's international reputation?...\n",
      "  ✓ A: It damaged support for the US model of political economy and...\n",
      "    B: It created anger at the United States for exaggerating the c...\n",
      "    C: It increased support for American global leadership under Pr...\n",
      "    D: It reduced global use of the US dollar...\n",
      "Correct: A\n",
      "\n",
      "Example from MACHINE_LEARNING:\n",
      "Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side ...\n",
      "    A: 2.0/15...\n",
      "  ✓ B: 1.0/7...\n",
      "    C: 3.0/16...\n",
      "    D: 1.0/5...\n",
      "Correct: B\n",
      "\n",
      "Example from PROFESSIONAL_ACCOUNTING:\n",
      "Q: Box a nongovernmental not-for-profit organization had the following transactions during the year: Pr...\n",
      "    A: $70,000...\n",
      "    B: $75,000...\n",
      "    C: $80,000...\n",
      "  ✓ D: 100000...\n",
      "Correct: D\n",
      "\n",
      "Example from ELEMENTARY_MATHEMATICS:\n",
      "Q: The population of the city where Michelle was born is 145,826. What is the value of the 5 in the num...\n",
      "  ✓ A: 5 thousands...\n",
      "    B: 5 hundreds...\n",
      "    C: 5 tens...\n",
      "    D: 5 ones...\n",
      "Correct: A\n",
      "\n",
      "Example from GLOBAL_FACTS:\n",
      "Q: Which of the following pairs of statements are both true (as of 2019)?...\n",
      "    A: People tend to be optimistic about their own future and the ...\n",
      "  ✓ B: People tend to be optimistic about their own future but pess...\n",
      "    C: People tend to be pessimistic about their own future but opt...\n",
      "    D: People tend to be pessimistic about their own future and the...\n",
      "Correct: B\n",
      "\n",
      "============================================================\n",
      "DATASET STATISTICS:\n",
      "============================================================\n",
      "Total subjects: 57\n",
      "Questions per subject: 5 (approximately)\n",
      "Top 10 subjects by question count:\n",
      "  abstract_algebra: 5 questions\n",
      "  anatomy: 5 questions\n",
      "  astronomy: 5 questions\n",
      "  business_ethics: 5 questions\n",
      "  clinical_knowledge: 5 questions\n",
      "  college_biology: 5 questions\n",
      "  college_chemistry: 5 questions\n",
      "  college_computer_science: 5 questions\n",
      "  college_mathematics: 5 questions\n",
      "  college_medicine: 5 questions\n",
      "\n",
      "All functions working correctly!\n"
     ]
    }
   ],
   "source": [
    "# Test the functions\n",
    "print(\"Loading MMLU dataset...\")\n",
    "datasets = get_mmlu_datasets()\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Number of dev samples: {len(datasets['mmlu_dev'])}\")\n",
    "\n",
    "# Test with a sample\n",
    "sample = datasets['mmlu_dev'][0]\n",
    "print(\"\\nOriginal sample:\")\n",
    "print(f\"Subject: {sample['subject']}\")\n",
    "print(f\"Question: {sample['question']}\")\n",
    "print(f\"Choices: {sample['choices']}\")\n",
    "print(f\"Answer: {sample['answer']} (index: {sample['answer']})\")\n",
    "\n",
    "# Convert answer index to letter for display\n",
    "answer_letters = ['A', 'B', 'C', 'D']\n",
    "print(f\"Correct answer: {answer_letters[sample['answer']]} - {sample['choices'][sample['answer']]}\")\n",
    "\n",
    "# Test sample_to_dict\n",
    "sample_dict = mmlu_sample_to_dict(sample)\n",
    "print(\"\\nConverted to dict:\")\n",
    "print(f\"Question: {sample_dict['question']}\")\n",
    "print(f\"Option 1: {sample_dict['option 1']}\")\n",
    "print(f\"Option 2: {sample_dict['option 2']}\")\n",
    "print(f\"Option 3: {sample_dict['option 3']}\")\n",
    "print(f\"Option 4: {sample_dict['option 4']}\")\n",
    "\n",
    "# Test dict_to_sample\n",
    "reconstructed_sample = mmlu_dict_to_sample(sample.copy(), sample_dict)\n",
    "print(\"\\nReconstructed sample:\")\n",
    "print(f\"Question: {reconstructed_sample['question']}\")\n",
    "print(f\"Choices: {reconstructed_sample['choices']}\")\n",
    "print(f\"Answer (converted): {reconstructed_sample['answer']}\")\n",
    "\n",
    "# Show examples from different subjects\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXAMPLES FROM DIFFERENT SUBJECTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Get unique subjects\n",
    "subjects = list(set([item['subject'] for item in datasets['mmlu_dev']]))\n",
    "print(f\"Available subjects: {subjects[:10]}...\")  # Show first 10\n",
    "\n",
    "# Show examples from first few subjects\n",
    "for i, subject in enumerate(subjects[:5]):\n",
    "    # Find first example from this subject\n",
    "    subject_sample = None\n",
    "    for item in datasets['mmlu_dev']:\n",
    "        if item['subject'] == subject:\n",
    "            subject_sample = item\n",
    "            break\n",
    "    \n",
    "    if subject_sample:\n",
    "        print(f\"\\nExample from {subject.upper()}:\")\n",
    "        print(f\"Q: {subject_sample['question'][:100]}...\")\n",
    "        for j, choice in enumerate(subject_sample['choices']):\n",
    "            marker = \"✓\" if j == subject_sample['answer'] else \" \"\n",
    "            print(f\"  {marker} {chr(65+j)}: {choice[:60]}...\")\n",
    "        print(f\"Correct: {chr(65+subject_sample['answer'])}\")\n",
    "\n",
    "# Show statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STATISTICS:\")\n",
    "print(\"=\"*60)\n",
    "subject_counts = {}\n",
    "for item in datasets['mmlu_dev']:\n",
    "    subject = item['subject']\n",
    "    subject_counts[subject] = subject_counts.get(subject, 0) + 1\n",
    "\n",
    "print(f\"Total subjects: {len(subject_counts)}\")\n",
    "print(f\"Questions per subject: {285 // len(subject_counts)} (approximately)\")\n",
    "print(f\"Top 10 subjects by question count:\")\n",
    "sorted_subjects = sorted(subject_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "for subject, count in sorted_subjects[:10]:\n",
    "    print(f\"  {subject}: {count} questions\")\n",
    "\n",
    "print(\"\\nAll functions working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361a62ef-2c86-4a7d-9ff5-d0f9d02fe9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from winograd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b87c8c-5f30-4ec3-bf99-1d26cfdc9255",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WinoGrande dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0d0b5fa26fc49c2a2fac2b41ea5d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8abe49d69bbf41f285d4ab106d7c214b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "winogrande.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "The repository for winogrande contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/winogrande.\n",
      "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
      "\n",
      "Do you wish to run the custom code? [y/N]  y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cedee3dc0f64a42914b23b0f692353a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37197668fc3c446aa50763715d2b03ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce5d18f900b94052bb75763f4dffa6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1767 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a86394838842048e24f2149d65e832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1267 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Number of training samples: 9248\n",
      "\n",
      "Original sample:\n",
      "Sentence: John moved the couch from the garage to the backyard to create space. The _ is small.\n",
      "Option 1: garage\n",
      "Option 2: backyard\n",
      "Answer: 1\n",
      "Correct answer: Option 1 - garage\n",
      "\n",
      "Converted to dict:\n",
      "Question: John moved the couch from the garage to the backyard to create space. The _ is small.\n",
      "Option 1: garage\n",
      "Option 2: backyard\n",
      "\n",
      "Reconstructed sample:\n",
      "Sentence: John moved the couch from the garage to the backyard to create space. The _ is small.\n",
      "Option 1: garage\n",
      "Option 2: backyard\n",
      "Answer (converted): 1\n",
      "\n",
      "============================================================\n",
      "MORE EXAMPLES:\n",
      "============================================================\n",
      "\n",
      "Example 2:\n",
      "Sentence: The doctor diagnosed Justin with bipolar and Robert with anxiety. _ had terrible nerves recently.\n",
      "Options:\n",
      "    1: Justin\n",
      "  ✓ 2: Robert\n",
      "Correct answer: 2\n",
      "\n",
      "Example 3:\n",
      "Sentence: Dennis drew up a business proposal to present to Logan because _ wants his investment.\n",
      "Options:\n",
      "  ✓ 1: Dennis\n",
      "    2: Logan\n",
      "Correct answer: 1\n",
      "\n",
      "Example 4:\n",
      "Sentence: Felicia unexpectedly made fried eggs for breakfast in the morning for Katrina and now _ owes a favor.\n",
      "Options:\n",
      "    1: Felicia\n",
      "  ✓ 2: Katrina\n",
      "Correct answer: 2\n",
      "\n",
      "Example 5:\n",
      "Sentence: My shampoo did not lather easily on my Afro hair because the _ is too dirty.\n",
      "Options:\n",
      "    1: shampoo\n",
      "  ✓ 2: hair\n",
      "Correct answer: 2\n",
      "\n",
      "Example 6:\n",
      "Sentence: The circuit failed to power the television but kept the radio going, as the _ had a weak connection.\n",
      "Options:\n",
      "  ✓ 1: television\n",
      "    2: radio\n",
      "Correct answer: 1\n",
      "\n",
      "============================================================\n",
      "UNDERSTANDING THE TASK:\n",
      "============================================================\n",
      "Original sentence: John moved the couch from the garage to the backyard to create space. The _ is small.\n",
      "This is a fill-in-the-blank task where '_' needs to be filled with one of the options:\n",
      "Option 1: garage\n",
      "Option 2: backyard\n",
      "\n",
      "With Option 1: John moved the couch from the garage to the backyard to create space. The garage is small.\n",
      "With Option 2: John moved the couch from the garage to the backyard to create space. The backyard is small.\n",
      "Correct choice: Option 1\n",
      "\n",
      "============================================================\n",
      "DATASET STATISTICS:\n",
      "============================================================\n",
      "WinoGrande is a commonsense reasoning dataset\n",
      "Task: Fill-in-the-blank with binary choice\n",
      "Total training samples: 9248\n",
      "Each sample has exactly 2 options (binary choice)\n",
      "Requires commonsense reasoning to determine the correct answer\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 83\u001b[0m\n\u001b[1;32m     81\u001b[0m answer_counts \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m}\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinogrande_train\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m1000\u001b[39m]:  \u001b[38;5;66;03m# Check first 1000 samples\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m answer_counts:\n\u001b[1;32m     84\u001b[0m         answer_counts[sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnswer distribution (first 1000 samples):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "print(\"Loading WinoGrande dataset...\")\n",
    "datasets = get_winogrande_datasets()\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Number of training samples: {len(datasets['winogrande_train'])}\")\n",
    "\n",
    "# Test with a sample\n",
    "sample = datasets['winogrande_train'][0]\n",
    "print(\"\\nOriginal sample:\")\n",
    "print(f\"Sentence: {sample['sentence']}\")\n",
    "print(f\"Option 1: {sample['option1']}\")\n",
    "print(f\"Option 2: {sample['option2']}\")\n",
    "print(f\"Answer: {sample['answer']}\")\n",
    "\n",
    "# Show which option is correct\n",
    "if sample['answer'] == '1':\n",
    "    print(f\"Correct answer: Option 1 - {sample['option1']}\")\n",
    "elif sample['answer'] == '2':\n",
    "    print(f\"Correct answer: Option 2 - {sample['option2']}\")\n",
    "\n",
    "# Test sample_to_dict\n",
    "sample_dict = winogrande_sample_to_dict(sample)\n",
    "print(\"\\nConverted to dict:\")\n",
    "print(f\"Question: {sample_dict['question']}\")\n",
    "print(f\"Option 1: {sample_dict['option 1']}\")\n",
    "print(f\"Option 2: {sample_dict['option 2']}\")\n",
    "\n",
    "# Test dict_to_sample\n",
    "reconstructed_sample = winogrande_dict_to_sample(sample.copy(), sample_dict)\n",
    "print(\"\\nReconstructed sample:\")\n",
    "print(f\"Sentence: {reconstructed_sample['sentence']}\")\n",
    "print(f\"Option 1: {reconstructed_sample['option1']}\")\n",
    "print(f\"Option 2: {reconstructed_sample['option2']}\")\n",
    "print(f\"Answer (converted): {reconstructed_sample['answer']}\")\n",
    "\n",
    "# Show more examples to understand the format\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MORE EXAMPLES:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i in range(1, 6):\n",
    "    sample = datasets['winogrande_train'][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"Sentence: {sample['sentence']}\")\n",
    "    print(f\"Options:\")\n",
    "    for j in range(1, 3):\n",
    "        marker = \"✓\" if sample['answer'] == str(j) else \" \"\n",
    "        option_text = sample['option1'] if j == 1 else sample['option2']\n",
    "        print(f\"  {marker} {j}: {option_text}\")\n",
    "    print(f\"Correct answer: {sample['answer']}\")\n",
    "\n",
    "# Show how the blank filling works\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UNDERSTANDING THE TASK:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "sample = datasets['winogrande_train'][0]\n",
    "print(f\"Original sentence: {sample['sentence']}\")\n",
    "print(f\"This is a fill-in-the-blank task where '_' needs to be filled with one of the options:\")\n",
    "print(f\"Option 1: {sample['option1']}\")\n",
    "print(f\"Option 2: {sample['option2']}\")\n",
    "\n",
    "# Replace the blank with each option to show the difference\n",
    "sentence_with_option1 = sample['sentence'].replace('_', sample['option1'])\n",
    "sentence_with_option2 = sample['sentence'].replace('_', sample['option2'])\n",
    "print(f\"\\nWith Option 1: {sentence_with_option1}\")\n",
    "print(f\"With Option 2: {sentence_with_option2}\")\n",
    "print(f\"Correct choice: Option {sample['answer']}\")\n",
    "\n",
    "# Dataset statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATASET STATISTICS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"WinoGrande is a commonsense reasoning dataset\")\n",
    "print(f\"Task: Fill-in-the-blank with binary choice\")\n",
    "print(f\"Total training samples: {len(datasets['winogrande_train'])}\")\n",
    "print(f\"Each sample has exactly 2 options (binary choice)\")\n",
    "print(f\"Requires commonsense reasoning to determine the correct answer\")\n",
    "\n",
    "# Count answer distribution\n",
    "answer_counts = {'1': 0, '2': 0}\n",
    "for sample in datasets['winogrande_train'][:1000]:  # Check first 1000 samples\n",
    "    if sample['answer'] in answer_counts:\n",
    "        answer_counts[sample['answer']] += 1\n",
    "\n",
    "print(f\"\\nAnswer distribution (first 1000 samples):\")\n",
    "print(f\"Option 1: {answer_counts['1']} samples\")\n",
    "print(f\"Option 2: {answer_counts['2']} samples\")\n",
    "print(f\"Balance: {answer_counts['1']/(answer_counts['1']+answer_counts['2'])*100:.1f}% vs {answer_counts['2']/(answer_counts['1']+answer_counts['2'])*100:.1f}%\")\n",
    "\n",
    "print(\"\\nAll functions working correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e745bda-0029-4fe6-bde1-ff9640812e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
