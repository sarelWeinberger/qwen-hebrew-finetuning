{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:25:50.265877Z",
     "start_time": "2025-08-28T08:25:44.587078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 1: Install dependencies and imports (unchanged)\n",
    "!pip install datasets\n",
    "!pip install openpyxl\n",
    "!pip install -q -U google-genai\n",
    "!pip install google-generativeai\n",
    "\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import pandas as pd\n",
    "from langdetect import detect_langs\n",
    "\n",
    "# Block 2: Load Alpaca dataset as stream (unchanged)\n",
    "dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\", streaming=True)\n",
    "print(\"Loaded Alpaca dataset as stream\")\n"
   ],
   "id": "2c79d6897c21a95d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (4.0.0)\r\n",
      "Requirement already satisfied: filelock in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (3.18.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (2.0.2)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (20.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (2.3.1)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (4.67.1)\r\n",
      "Requirement already satisfied: xxhash in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (0.33.4)\r\n",
      "Requirement already satisfied: packaging in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\r\n",
      "Requirement already satisfied: idna>=2.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests>=2.32.2->datasets) (2025.7.14)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Requirement already satisfied: openpyxl in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (3.1.5)\r\n",
      "Requirement already satisfied: et-xmlfile in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from openpyxl) (2.0.0)\r\n",
      "Requirement already satisfied: google-generativeai in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (0.8.5)\r\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (0.6.15)\r\n",
      "Requirement already satisfied: google-api-core in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (2.25.1)\r\n",
      "Requirement already satisfied: google-api-python-client in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (2.179.0)\r\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (2.40.3)\r\n",
      "Requirement already satisfied: protobuf in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (5.29.5)\r\n",
      "Requirement already satisfied: pydantic in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (2.11.7)\r\n",
      "Requirement already satisfied: tqdm in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-generativeai) (4.14.1)\r\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-core->google-generativeai) (1.70.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-core->google-generativeai) (2.32.4)\r\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\r\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.20)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.7.14)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\r\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from google-api-python-client->google-generativeai) (4.2.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pydantic->google-generativeai) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/oribar-joseph/PycharmProjects/qwen-hebrew-finetuning1/.venv/lib/python3.9/site-packages (from pydantic->google-generativeai) (0.4.1)\r\n",
      "Loaded Alpaca dataset as stream\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:26:06.793295Z",
     "start_time": "2025-08-28T08:26:04.379001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_qa_from_alpaca(item):\n",
    "    \"\"\"Extract question and answer from Alpaca dataset item\"\"\"\n",
    "    try:\n",
    "        instruction = item.get('instruction', '').strip()\n",
    "        input_text = item.get('input', '').strip()\n",
    "        output = item.get('output', '').strip()\n",
    "\n",
    "        if input_text:\n",
    "            question = f\"{instruction}\\n\\n{input_text}\"\n",
    "        else:\n",
    "            question = instruction\n",
    "\n",
    "        return question, output\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting Q&A: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Extract Q&A pairs from stream\n",
    "all_examples = []\n",
    "print(\"Extracting Q&A pairs from stream...\")\n",
    "\n",
    "count = 0\n",
    "for item in dataset:\n",
    "    if count >= 10000:\n",
    "        break\n",
    "\n",
    "    if count % 1000 == 0:\n",
    "        print(f\"Processed {count} examples, found {len(all_examples)} valid examples\")\n",
    "\n",
    "    question, answer = extract_qa_from_alpaca(item)\n",
    "\n",
    "    if question and answer and len(question.strip()) > 10 and len(answer.strip()) > 10:\n",
    "        all_examples.append((question, answer))\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print(f\"Found {len(all_examples)} valid Q&A pairs from {count} processed examples\")"
   ],
   "id": "ac2e1c20c31f85d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Q&A pairs from stream...\n",
      "Processed 0 examples, found 0 valid examples\n",
      "Processed 1000 examples, found 932 valid examples\n",
      "Processed 2000 examples, found 1877 valid examples\n",
      "Processed 3000 examples, found 2822 valid examples\n",
      "Processed 4000 examples, found 3759 valid examples\n",
      "Processed 5000 examples, found 4705 valid examples\n",
      "Processed 6000 examples, found 5644 valid examples\n",
      "Processed 7000 examples, found 6570 valid examples\n",
      "Processed 8000 examples, found 7501 valid examples\n",
      "Processed 9000 examples, found 8443 valid examples\n",
      "Found 9395 valid Q&A pairs from 10000 processed examples\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:26:24.448701Z",
     "start_time": "2025-08-28T08:26:24.436783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 3: Sample diverse examples for few-shot learning (unchanged)\n",
    "def get_diverse_alpaca_examples(examples, n_samples=5):\n",
    "    \"\"\"Get diverse examples from Alpaca dataset for few-shot learning\"\"\"\n",
    "\n",
    "    buckets = {\n",
    "        'short': [],   # 0-300 chars\n",
    "        'medium': [],  # 300-1000 chars\n",
    "        'long': [],    # 1000+ chars\n",
    "    }\n",
    "\n",
    "    for question, answer in examples:\n",
    "        content_length = len(question) + len(answer)\n",
    "\n",
    "        if content_length < 300:\n",
    "            bucket_name = 'short'\n",
    "        elif content_length < 1000:\n",
    "            bucket_name = 'medium'\n",
    "        else:\n",
    "            bucket_name = 'long'\n",
    "\n",
    "        buckets[bucket_name].append((question, answer))\n",
    "\n",
    "    diverse_examples = []\n",
    "    for bucket_name in ['short', 'medium', 'long']:\n",
    "        if buckets[bucket_name]:\n",
    "            samples_from_bucket = min(len(buckets[bucket_name]), max(1, n_samples // 3))\n",
    "            diverse_examples.extend(random.sample(buckets[bucket_name], samples_from_bucket))\n",
    "\n",
    "    all_examples_list = [ex for bucket in buckets.values() for ex in bucket]\n",
    "    while len(diverse_examples) < n_samples and all_examples_list:\n",
    "        remaining = [ex for ex in all_examples_list if ex not in diverse_examples]\n",
    "        if remaining:\n",
    "            diverse_examples.append(random.choice(remaining))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return diverse_examples[:n_samples]\n",
    "\n",
    "few_shot_examples = get_diverse_alpaca_examples(all_examples, n_samples=5)\n",
    "print(f\"Selected {len(few_shot_examples)} diverse examples for few-shot learning\")\n"
   ],
   "id": "a35d1b2e03e3da35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5 diverse examples for few-shot learning\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:26:45.112223Z",
     "start_time": "2025-08-28T08:26:45.109062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 4: Setup Gemini API\n",
    "GEMINI_API_KEY = \"AIzaSyCtsfF_f6isWzN3B5wrUEDhaE1IujdoOnQ\"  # Replace with your actual API key\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-2.5-pro')"
   ],
   "id": "af08fd0fb2f8c215",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:26:57.949186Z",
     "start_time": "2025-08-28T08:26:57.944480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 5: Enhanced translation function\n",
    "def translate_to_hebrew(text, text_type=\"text\"):\n",
    "    \"\"\"Translate text to Hebrew using Gemini API with enhanced prompts\"\"\"\n",
    "    try:\n",
    "        if text_type == \"question\":\n",
    "            prompt = f\"\"\"You are a professional Hebrew translator specializing in educational content.\n",
    "\n",
    "Translate the following question to Hebrew while maintaining:\n",
    "- Natural Hebrew flow and readability\n",
    "- Technical accuracy for any domain-specific terms\n",
    "- Proper Hebrew sentence structure and grammar\n",
    "- Mathematical expressions, code snippets, formulas, and technical identifiers should remain unchanged\n",
    "- Use appropriate Hebrew academic/educational terminology where applicable\n",
    "- Maintain the original question's intent and clarity\n",
    "\n",
    "Question to translate:\n",
    "{text}\n",
    "\n",
    "Provide only the Hebrew translation:\"\"\"\n",
    "\n",
    "        elif text_type == \"answer\":\n",
    "            prompt = f\"\"\"You are a professional Hebrew translator specializing in educational content.\n",
    "\n",
    "Translate the following answer to Hebrew while ensuring:\n",
    "- Clear, natural Hebrew expression that maintains the original meaning\n",
    "- Technical terms are appropriately translated or kept in original form when standard practice\n",
    "- Mathematical expressions, code, formulas, URLs, and technical identifiers remain unchanged\n",
    "- Proper Hebrew academic/educational writing style\n",
    "- Logical flow and coherence in Hebrew\n",
    "- Appropriate use of Hebrew punctuation and formatting\n",
    "\n",
    "Answer to translate:\n",
    "{text}\n",
    "\n",
    "Provide only the Hebrew translation:\"\"\"\n",
    "\n",
    "        else:\n",
    "            prompt = f\"\"\"Translate the following text to Hebrew while maintaining natural flow and accuracy:\n",
    "\n",
    "{text}\n",
    "\n",
    "Provide only the Hebrew translation:\"\"\"\n",
    "\n",
    "        response = model.generate_content(prompt)\n",
    "        time.sleep(0.5)  # Rate limiting\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Translation error: {e}\")\n",
    "        return text"
   ],
   "id": "5ace5eac5b82fd94",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:27:16.318090Z",
     "start_time": "2025-08-28T08:27:16.314285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 6: Hebrew answer generation function (replaces CoT)\n",
    "def create_hebrew_answer_prompt(few_shot_examples, new_english_question):\n",
    "    \"\"\"Create prompt for generating comprehensive Hebrew answers\"\"\"\n",
    "\n",
    "    prompt = \"\"\"You are an expert educational assistant who provides clear, comprehensive, and well-structured answers in Hebrew. You have deep knowledge across various domains and can explain complex concepts in an accessible way.\n",
    "\n",
    "Your Hebrew answers should be:\n",
    "- Clear, precise, and comprehensive\n",
    "- Well-structured with logical flow\n",
    "- Accurate and informative\n",
    "- Use proper Hebrew terminology and academic language\n",
    "- Keep mathematical expressions, code, formulas, and technical identifiers in their original form\n",
    "- Include relevant examples or explanations when helpful\n",
    "- Be appropriately detailed for the question's complexity\n",
    "- Maintain educational value and clarity\n",
    "\n",
    "Here are examples of the style and quality expected:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    # Add few-shot examples\n",
    "    for i, (question, answer) in enumerate(few_shot_examples):\n",
    "        prompt += f\"\"\"Example {i+1}:\n",
    "English Question: {question}\n",
    "\n",
    "English Answer: {answer}\n",
    "\n",
    "Expected Hebrew Answer Style: [A clear, comprehensive Hebrew response that thoroughly addresses the question with proper structure and terminology]\n",
    "\n",
    "---\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    prompt += f\"\"\"Now provide a comprehensive, well-structured Hebrew answer for this question:\n",
    "\n",
    "English Question: {new_english_question}\n",
    "\n",
    "Hebrew Answer:\"\"\"\n",
    "\n",
    "    return prompt"
   ],
   "id": "96684be1c90a316e",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:33:35.458538Z",
     "start_time": "2025-08-28T08:27:28.742904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 7: Generate Hebrew dataset function\n",
    "def generate_alpaca_hebrew_dataset(few_shot_examples, num_questions=10):\n",
    "    \"\"\"Generate Hebrew answer dataset from Alpaca examples\"\"\"\n",
    "\n",
    "    results = []\n",
    "    processed = 0\n",
    "\n",
    "    print(f\"Processing {num_questions} questions from Alpaca dataset...\")\n",
    "\n",
    "    # Sample from our examples, avoiding few-shot duplicates\n",
    "    few_shot_questions = [ex[0] for ex in few_shot_examples]\n",
    "    sample_examples = random.sample(all_examples, min(num_questions * 2, len(all_examples)))\n",
    "\n",
    "    for question, answer in sample_examples:\n",
    "        if processed >= num_questions:\n",
    "            break\n",
    "\n",
    "        # Skip if this question is already in our few-shot examples\n",
    "        if question in few_shot_questions:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            print(f\"Processing question {processed+1}/{num_questions}\")\n",
    "            print(f\"Question preview: {question[:100]}...\")\n",
    "\n",
    "            # Generate Hebrew answer using few-shot learning\n",
    "            answer_prompt = create_hebrew_answer_prompt(few_shot_examples, question)\n",
    "            response = model.generate_content(answer_prompt)\n",
    "            hebrew_answer_generated = response.text.strip()\n",
    "\n",
    "            # Store result\n",
    "            result = {\n",
    "                'question_english': question,\n",
    "                'answer_english': answer,\n",
    "                'question_hebrew': '',  # Will fill later\n",
    "                'answer_hebrew_generated': hebrew_answer_generated,\n",
    "                'answer_hebrew_translated': ''  # Will fill later\n",
    "            }\n",
    "\n",
    "            results.append(result)\n",
    "            print(f\"Generated Hebrew answer for question {processed+1}\")\n",
    "\n",
    "            processed += 1\n",
    "            time.sleep(1)  # Rate limiting\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing question {processed+1}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Block 8: Generate the dataset\n",
    "hebrew_dataset = generate_alpaca_hebrew_dataset(\n",
    "    few_shot_examples=few_shot_examples,\n",
    "    num_questions=10\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(hebrew_dataset)} Hebrew answer examples\")"
   ],
   "id": "3a73ad55970fb843",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 questions from Alpaca dataset...\n",
      "Processing question 1/10\n",
      "Question preview: Brainstorm a relevant title for the following article.\n",
      "\n",
      "The Benefits of Utilizing Recycled Materials...\n",
      "Generated Hebrew answer for question 1\n",
      "Processing question 2/10\n",
      "Question preview: What do you think are the major causes of poverty in developing countries?\n",
      "\n",
      "No input required....\n",
      "Generated Hebrew answer for question 2\n",
      "Processing question 3/10\n",
      "Question preview: Generate a wish for someone's birthday.\n",
      "\n",
      "Recipient: My Best Friend...\n",
      "Generated Hebrew answer for question 3\n",
      "Processing question 4/10\n",
      "Question preview: Name three cities in the United States with population over 1 million....\n",
      "Generated Hebrew answer for question 4\n",
      "Processing question 5/10\n",
      "Question preview: What are the methods available for sentiment analysis?...\n",
      "Generated Hebrew answer for question 5\n",
      "Processing question 6/10\n",
      "Question preview: Describe the basic principles of thermodynamics....\n",
      "Generated Hebrew answer for question 6\n",
      "Processing question 7/10\n",
      "Question preview: Generate an appropriate pick up line\n",
      "\n",
      "No input...\n",
      "Generated Hebrew answer for question 7\n",
      "Processing question 8/10\n",
      "Question preview: How many paragraphs does the text have?\n",
      "\n",
      "This is the first paragraph.\n",
      "\n",
      "This is the second one.\n",
      "\n",
      "And ...\n",
      "Generated Hebrew answer for question 8\n",
      "Processing question 9/10\n",
      "Question preview: Edit the passage by replacing the adjective with a suitable synonym.\n",
      "\n",
      "The students discovered the an...\n",
      "Generated Hebrew answer for question 9\n",
      "Processing question 10/10\n",
      "Question preview: Describe the pros and cons of the following policy\n",
      "\n",
      "Providing free college education...\n",
      "Generated Hebrew answer for question 10\n",
      "Generated 10 Hebrew answer examples\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T08:44:57.100100Z",
     "start_time": "2025-08-28T08:35:31.543869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Block 9: Translate questions and answers to Hebrew\n",
    "print(\"Translating questions to Hebrew...\")\n",
    "hebrew_questions = []\n",
    "for i, question in enumerate(hebrew_dataset['question_english']):\n",
    "    print(f\"Translating question {i+1}/{len(hebrew_dataset)}\")\n",
    "    hebrew_questions.append(translate_to_hebrew(question, \"question\"))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(\"Translating answers to Hebrew...\")\n",
    "hebrew_answers_translated = []\n",
    "for i, answer in enumerate(hebrew_dataset['answer_english']):\n",
    "    print(f\"Translating answer {i+1}/{len(hebrew_dataset)}\")\n",
    "    hebrew_answers_translated.append(translate_to_hebrew(answer, \"answer\"))\n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Add translations to dataset\n",
    "hebrew_dataset['question_hebrew'] = hebrew_questions\n",
    "hebrew_dataset['answer_hebrew_translated'] = hebrew_answers_translated\n",
    "\n",
    "# Block 10: Create final dataset and save\n",
    "final_dataset = hebrew_dataset[[\n",
    "    'question_english',\n",
    "    'answer_english',\n",
    "    'question_hebrew',\n",
    "    'answer_hebrew_generated',\n",
    "    'answer_hebrew_translated'\n",
    "]]\n",
    "\n",
    "print(\"Final dataset structure:\")\n",
    "print(final_dataset.head())\n",
    "print(f\"\\nDataset shape: {final_dataset.shape}\")\n",
    "print(f\"Columns: {list(final_dataset.columns)}\")\n",
    "\n",
    "# Save to CSV\n",
    "final_dataset.to_csv('/Users/oribar-joseph/Downloads/alpaca_hebrew_answers_dataset.csv', index=False)\n",
    "print(\"Dataset saved to 'alpaca_hebrew_answers_dataset.csv'\")\n",
    "\n",
    "# Display sample\n",
    "print(\"\\nSample from final dataset:\")\n",
    "for i, row in final_dataset.head(2).iterrows():\n",
    "    print(f\"\\n--- Example {i+1} ---\")\n",
    "    print(f\"English Question: {row['question_english'][:150]}...\")\n",
    "    print(f\"English Answer: {row['answer_english'][:150]}...\")\n",
    "    print(f\"Hebrew Question: {row['question_hebrew'][:150]}...\")\n",
    "    print(f\"Hebrew Generated Answer: {row['answer_hebrew_generated'][:150]}...\")\n",
    "    print(f\"Hebrew Translated Answer: {row['answer_hebrew_translated'][:150]}...\")\n"
   ],
   "id": "4a8fc8ec5db05d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating questions to Hebrew...\n",
      "Translating question 1/10\n",
      "Translating question 2/10\n",
      "Translating question 3/10\n",
      "Translating question 4/10\n",
      "Translating question 5/10\n",
      "Translating question 6/10\n",
      "Translating question 7/10\n",
      "Translating question 8/10\n",
      "Translating question 9/10\n",
      "Translating question 10/10\n",
      "Translating answers to Hebrew...\n",
      "Translating answer 1/10\n",
      "Translating answer 2/10\n",
      "Translating answer 3/10\n",
      "Translating answer 4/10\n",
      "Translating answer 5/10\n",
      "Translating answer 6/10\n",
      "Translating answer 7/10\n",
      "Translating answer 8/10\n",
      "Translating answer 9/10\n",
      "Translating answer 10/10\n",
      "Final dataset structure:\n",
      "                                    question_english  \\\n",
      "0  Brainstorm a relevant title for the following ...   \n",
      "1  What do you think are the major causes of pove...   \n",
      "2  Generate a wish for someone's birthday.\\n\\nRec...   \n",
      "3  Name three cities in the United States with po...   \n",
      "4  What are the methods available for sentiment a...   \n",
      "\n",
      "                                      answer_english  \\\n",
      "0  \"Giving New Life to Pre-Loved Materials: The B...   \n",
      "1  The major causes of poverty in developing coun...   \n",
      "2  My dearest best friend, may your birthday be f...   \n",
      "3  The three cities in the United States with pop...   \n",
      "4  Sentiment analysis can be performed using seve...   \n",
      "\n",
      "                                     question_hebrew  \\\n",
      "0  הציעו כותרת רלוונטית למאמר הבא.\\n\\nהיתרונות שב...   \n",
      "1  מהם לדעתך הגורמים המרכזיים לעוני במדינות מתפתחות?   \n",
      "2     צור ברכה ליום הולדת.\\n\\nנמען: החבר הכי טוב שלי   \n",
      "3  ציינו שלוש ערים בארצות הברית שאוכלוסייתן עולה ...   \n",
      "4                 מהן השיטות הקיימות לניתוח סנטימנט?   \n",
      "\n",
      "                             answer_hebrew_generated  \\\n",
      "0  בטח, בשמחה. להלן רשימה מקיפה ומגוונת של כותרות...   \n",
      "1  בהחלט. להלן תשובה מקיפה ומובנית היטב בנושא הגו...   \n",
      "2  בטח, בשמחה. ברכה ליום הולדת של חבר/ה טוב/ה היא...   \n",
      "3  בטח, הנה תשובה מפורטת ומובנית היטב.\\n\\nבארצות ...   \n",
      "4  בטח, בשמחה. להלן תשובה מקיפה, ברורה ומובנית בנ...   \n",
      "\n",
      "                            answer_hebrew_translated  \n",
      "0  הענקת חיים חדשים לחומרים משומשים: יתרונות השימ...  \n",
      "1  הגורמים העיקריים לעוני במדינות מתפתחות כוללים ...  \n",
      "2  חברתי הטובה והיקרה,\\nשיהיה לך יום הולדת מלא בה...  \n",
      "3  שלוש הערים בארצות הברית שאוכלוסייתן מונה למעלה...  \n",
      "4  ניתן לבצע ניתוח סנטימנט באמצעות כמה שיטות שונו...  \n",
      "\n",
      "Dataset shape: (10, 5)\n",
      "Columns: ['question_english', 'answer_english', 'question_hebrew', 'answer_hebrew_generated', 'answer_hebrew_translated']\n",
      "Dataset saved to 'alpaca_hebrew_answers_dataset.csv'\n",
      "\n",
      "Sample from final dataset:\n",
      "\n",
      "--- Example 1 ---\n",
      "English Question: Brainstorm a relevant title for the following article.\n",
      "\n",
      "The Benefits of Utilizing Recycled Materials...\n",
      "English Answer: \"Giving New Life to Pre-Loved Materials: The Benefits of Reusing and Recycling\"...\n",
      "Hebrew Question: הציעו כותרת רלוונטית למאמר הבא.\n",
      "\n",
      "היתרונות שבשימוש בחומרים ממוחזרים...\n",
      "Hebrew Generated Answer: בטח, בשמחה. להלן רשימה מקיפה ומגוונת של כותרות אפשריות למאמר העוסק ביתרונות השימוש בחומרים ממוחזרים. הכותרות מאורגנות בקטגוריות שונות כדי להתאים לסגנו...\n",
      "Hebrew Translated Answer: הענקת חיים חדשים לחומרים משומשים: יתרונות השימוש החוזר והמִחזור...\n",
      "\n",
      "--- Example 2 ---\n",
      "English Question: What do you think are the major causes of poverty in developing countries?\n",
      "\n",
      "No input required....\n",
      "English Answer: The major causes of poverty in developing countries include lack of access to basic services such as education and healthcare, limited job opportuniti...\n",
      "Hebrew Question: מהם לדעתך הגורמים המרכזיים לעוני במדינות מתפתחות?...\n",
      "Hebrew Generated Answer: בהחלט. להלן תשובה מקיפה ומובנית היטב בנושא הגורמים המרכזיים לעוני במדינות מתפתחות.\n",
      "\n",
      "---\n",
      "\n",
      "עוני במדינות מתפתחות הוא תופעה מורכבת ורב-ממדית, הנובעת משילו...\n",
      "Hebrew Translated Answer: הגורמים העיקריים לעוני במדינות מתפתחות כוללים חוסר גישה לשירותים בסיסיים כגון חינוך ובריאות, הזדמנויות תעסוקה מוגבלות, חוסר יציבות פוליטית ושחיתות, חל...\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ed03c3614befc18"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
